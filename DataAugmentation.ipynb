{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only goal of this notebook is to visualize what happens when we do data augmentation on the signals\n",
    "\n",
    "\n",
    "After doing this data augmentation, I will need to extract features again with tsfresh... Hopefully it will work, but I think it was taking 2 days to extract.\n",
    "\n",
    "* [Linear Combination](#linear-combination)\n",
    "* [Rotation](#rotation)\n",
    "* [Resampling - Stretching / Shrinking](#Stretching-/-Shrinking)\n",
    "* [Add Noise](#Generate-Noise-Data-Augmentation)\n",
    "* [Making a more balanced dataset](#Making-more-balanced-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Imports for the high pass signal\n",
    "from scipy.signal import butter, freqz, lfilter\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import required modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os.path\n",
    "\n",
    "# To write WAV File\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# To make derivative work on multiple CPUs\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# 3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scipy.signal as sg \n",
    "\n",
    "from create_graphs import *\n",
    "from transform_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "training_or_ancillary='training_data'\n",
    "path_save_accelerometer_plots = \"/export/b19/mpgill/BeatPD_data_aug_plots/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Combination on the signal level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear combination code is not completed because it is actually done at the feature level, and not at the signal level like the code here. It was started, but not completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "\n",
    "all_subjects = df_train_label['subject_id'].unique()\n",
    "\n",
    "columns_to_exclude = ['measurement_id','subject_id', 'Timestamp']\n",
    "lambda_value = 0.5\n",
    "linear_combination_path = \"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.lamb_\"+str(lambda_value)\n",
    "\n",
    "for subject in all_subjects: \n",
    "    df_train_label_subject = df_train_label.loc[df_train_label['subject_id'] == subject]\n",
    "\n",
    "    df_data_aug = []\n",
    "    # First loop to go over the rows\n",
    "    for index, measurement1 in df_train_label_subject.iterrows():\n",
    "        df_train_data_1 = pd.read_csv(path_train_data + measurement1[0] + \".csv\")\n",
    "\n",
    "        # Second rows to go over the loop except the same two rows\n",
    "        for index2, measurement2 in df_train_label_subject.iterrows():\n",
    "            df_train_data_2 = pd.read_csv(path_train_data + measurement2[0] + \".csv\")\n",
    "\n",
    "            if index == index2:\n",
    "                continue\n",
    "                \n",
    "            print(len(df_train_data_1))\n",
    "            print(len(df_train_data_2))\n",
    "            modDfObj1 = df_train_data_1[df_train_data_1.columns.difference(columns_to_exclude)].apply(lambda x: x * lambda_value, axis=1, result_type='broadcast')\n",
    "            modDfObj2 = df_train_data_2[df_train_data_2.columns.difference(columns_to_exclude)].apply(lambda x: x * (1-lambda_value), axis=1, result_type='broadcast')\n",
    "            \n",
    "            print()\n",
    "            # maybe i should add timestamp back \n",
    "            df_data_aug = pd.DataFrame(modDfObj1.add(modDfObj2), columns=modDfObj1.columns)\n",
    "\n",
    "            print(df_data_aug)\n",
    "            raise KeyboardInterrupt\n",
    "        # If the high_pass folder doesn't exists, we need to create it \n",
    "        if not os.path.exists(rotation_path):\n",
    "            os.makedirs(rotation_path)\n",
    "            print('The rotate folder was created : ', rotation_path)\n",
    "\n",
    "        # Save to a folder \n",
    "        df_data_aug.to_csv(\n",
    "            rotation_path + measurement_id + \".csv\",\n",
    "            index=False\n",
    "        )\n",
    "        raise KeyboardInterrupt\n",
    "            \n",
    "            \n",
    "print(df_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def rotate_signal(measurement_id, path_train_data, params, rotation_path, mask_path=None, verbose=0):\n",
    "    \"\"\"\n",
    "    measurement_id: speficic measurement_id to apply rotation \n",
    "    path_train_data: path to the training data to use \n",
    "    params: add_rotation: 'True' or 'False' if we want to do rotation or not \n",
    "            rotation_path: path where to save the rotated signals\n",
    "            add_bounds_rotation: 'True' or 'False': if we want to do rotation between ]0,-5[ , and [0, 5[\n",
    "            add_jump_rotation: 'True' if we want to rotate only part of the signals \n",
    "                                'False' to rotate the whole signal \n",
    "    mask_path: path to the mask if we want to remove inactivity\n",
    "    verbose: can be 0 or 1, level of details to log \n",
    "    \"\"\"\n",
    "    add_rotation = params[\"add_rotation\"]\n",
    "    add_jump_rotation = params[\"add_jump_rotation\"]\n",
    "\n",
    "    # bounds rotation is if we do rotation between ]0,-5[ , and [0, 5[ \n",
    "    add_bounds_rotation = params[\"add_bounds_rotation\"]\n",
    "\n",
    "    min_len = params.get('min_len',1000)\n",
    "    max_len = params.get('max_len',10000)\n",
    "    rot_ang = params.get('rot_ang',45)\n",
    "    \n",
    "    temp_train_X_orig = pd.read_csv(path_train_data + measurement_id + '.csv')\n",
    "    \n",
    "    if verbose == 1:\n",
    "        temp_train_X_orig.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"Before\")\n",
    "    \n",
    "    temp_train_X = temp_train_X_orig.values[:,-3:]\n",
    "\n",
    "    if mask_path is not None:\n",
    "        print('Removing Inactivity')\n",
    "        temp_train_X = apply_mask(path_train_data,\n",
    "                                  measurement_id,\n",
    "                                  mask_path)\n",
    "        temp_train_X = temp_train_X.values[:,1:]\n",
    "    sig_len = temp_train_X.shape[0]\n",
    "    if add_bounds_rotation == 'True':\n",
    "        print('Adding bounds rotation between [', -rot_ang, ', ', -(rot_ang-5), '[ and [', rot_ang-5, ', ', rot_ang, '[')\n",
    "        rot1 = np.random.randint(-rot_ang,-(rot_ang-5),size=1)[0]\n",
    "        rot2 = np.random.randint(rot_ang-5,rot_ang,size=1)[0]\n",
    "        print('Two suggested angles between both bounds are : ', rot1, ' and ', rot2)\n",
    "        # Choose a rotation angle between the two intervals \n",
    "        rot = np.random.choice([rot1, rot2])\n",
    "        print('BOUND ROTATION ENDED UP BEING : ', rot)\n",
    "        r = R.from_euler('xyz', [rot]*3, degrees=True)\n",
    "        rot_mat = r.as_dcm()\n",
    "        temp_train_X = np.dot(temp_train_X, rot_mat)\n",
    "    elif add_rotation == 'True':\n",
    "        print('Adding rotation')\n",
    "        print('rot_ang : ', rot_ang)\n",
    "        rot = np.random.randint(-rot_ang,rot_ang,size=1)[0]\n",
    "        print('ROTATION IS : ', rot)\n",
    "        r = R.from_euler('xyz', [rot]*3, degrees=True)\n",
    "        rot_mat = r.as_dcm()\n",
    "        temp_train_X = np.dot(temp_train_X, rot_mat)\n",
    "    elif add_jump_rotation == 'True':\n",
    "        print('Adding Jump Rotation')\n",
    "        s_ind = 0\n",
    "        while (s_ind < sig_len):\n",
    "            # We rotate at random increments \n",
    "            jump = np.random.randint(min_len,max_len,1)[0]\n",
    "\n",
    "            rot = np.random.randint(-rot_ang,rot_ang,size=1)[0]\n",
    "            r = R.from_euler('xyz', [rot]*3, degrees=True)\n",
    "            rot_mat = r.as_dcm()\n",
    "            temp_train_X[s_ind:s_ind+jump,:] = np.dot(temp_train_X[s_ind:s_ind+jump,:],rot_mat)\n",
    "            s_ind = s_ind + jump\n",
    "\n",
    "    temp_train_X = pd.concat([temp_train_X_orig.Timestamp, pd.DataFrame(temp_train_X, columns=[\"X\",\"Y\",\"Z\"])], axis=1)\n",
    "\n",
    "    if verbose == 1:\n",
    "        pd.DataFrame(temp_train_X).plot(x=\"Timestamp\", legend=True, subplots=True, title=\"After rotation\")\n",
    "    \n",
    "    # If the high_pass folder doesn't exists, we need to create it \n",
    "    if not os.path.exists(rotation_path):\n",
    "        os.makedirs(rotation_path)\n",
    "        print('The rotate folder was created : ', rotation_path)\n",
    "    \n",
    "    # Save to a folder \n",
    "    temp_train_X.to_csv(\n",
    "        rotation_path + measurement_id + \"_ang_\"+str(rot)+\".csv\",\n",
    "        index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Rotation for Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to change the value of `rotation_path` to choose the folder where to save the new data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label[(df_train_label.dyskinesia >= 2.0) | (df_train_label.on_off >= 2.0) | (df_train_label.tremor >= 2.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "# list_measurement_id = [\"3cf49c01-0499-4bad-9167-67691711204a\"]\n",
    "\n",
    "# df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "#                                       list_measurement_id=list_measurement_id)\n",
    "\n",
    "angle=45\n",
    "\n",
    "# Original \n",
    "do_work = partial(\n",
    "        rotate_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "        params={'add_bounds_rotation': 'False', 'rot_ang': angle, 'add_rotation': 'True', 'add_jump_rotation': 'False'},\n",
    "        rotation_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_thesis/\",\n",
    "        mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotations with bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to only create 1 new file with rotation\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"3cf49c01-0499-4bad-9167-67691711204a\"]\n",
    "\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "for repetition_no in [1]:\n",
    "    for angle in [30]:\n",
    "#         !mkdir /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_bound_{angle}_{repetition_no}/\n",
    "        # combhpfnoinact \n",
    "        do_work = partial(\n",
    "                rotate_signal, \n",
    "                path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "                params={'add_bounds_rotation': 'True', 'rot_ang': angle, 'add_rotation': 'False', 'add_jump_rotation': 'False'},\n",
    "                rotation_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_thesis/\",\n",
    "                mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "                verbose=0,\n",
    "            )\n",
    "\n",
    "        num_jobs = 8\n",
    "        with ProcessPoolExecutor(num_jobs) as ex:\n",
    "            results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "\n",
    "for repetition_no in [2, 3, 4, 5]:\n",
    "    for angle in [5, 10, 15, 20, 25, 30, 35, 40, 45]:\n",
    "        !mkdir /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_bound_{angle}_{repetition_no}/\n",
    "        # combhpfnoinact \n",
    "        do_work = partial(\n",
    "                rotate_signal, \n",
    "                path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "                params={'add_bounds_rotation': 'True', 'rot_ang': angle, 'add_rotation': 'False'},\n",
    "                rotation_path=\"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_bound_\"+str(angle)+\"_\"+str(repetition_no)+\"/\",\n",
    "                mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "                verbose=0,\n",
    "            )\n",
    "\n",
    "        num_jobs = 8\n",
    "        with ProcessPoolExecutor(num_jobs) as ex:\n",
    "            results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repetition_no in [2, 3, 4, 5]:\n",
    "    for angle in [5, 10, 15, 20, 25, 30, 35, 40, 45]:\n",
    "        !ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_bound_{angle}_{repetition_no}/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "        !./tsfresh/submit/create_scp_files.sh combhpfnoinact.rotate_bound_{angle}_{repetition_no}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Rotation for Comb HPF Noinact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "# Original \n",
    "do_work = partial(\n",
    "        rotate_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "        params={'add_rotation': 'True'},\n",
    "        rotation_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_5/\",\n",
    "        mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making more balanced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "df_train_label_1 = df_train_label[((df_train_label.dyskinesia >= 1.0) | (df_train_label.on_off >= 1.0) | (df_train_label.tremor >= 1.0)) & (df_train_label.on_off != 0)]\n",
    "\n",
    "# combhpfnoinact \n",
    "do_work = partial(\n",
    "        rotate_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "        params={'add_rotation': 'True'},\n",
    "        rotation_path=\"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_balance_1/\",\n",
    "        mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label_1['measurement_id']))\n",
    "\n",
    "print('NEXT FOLDER')\n",
    "\n",
    "df_train_label_3 = df_train_label[((df_train_label.dyskinesia >= 3.0) | (df_train_label.on_off >= 3.0) | (df_train_label.tremor >= 3.0)) & (df_train_label.on_off != 0)]\n",
    "\n",
    "# combhpfnoinact \n",
    "do_work = partial(\n",
    "        rotate_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "        params={'add_rotation': 'True'},\n",
    "        rotation_path=\"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_balance_3/\",\n",
    "        mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label_3['measurement_id']))\n",
    "    \n",
    "print('LAST FOLDER')\n",
    "df_train_label_4 = df_train_label[((df_train_label.dyskinesia >= 3.0) | (df_train_label.on_off >= 3.0) | (df_train_label.tremor >= 3.0)) & (df_train_label.on_off != 0)]\n",
    "\n",
    "do_work = partial(\n",
    "        rotate_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\",\n",
    "        params={'add_rotation': 'True'},\n",
    "        rotation_path=\"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_balance_4/\",\n",
    "        mask_path=None,#\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label_4['measurement_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of measurements before and after rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "list_measurement_id = [\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "]\n",
    "\n",
    "list_measurement_id = [\"db2e053a-0fb8-4206-891a-6f079fb14e3a\"]\n",
    "\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "load_data(measurement_id, path_train_data, params, rotation_path, factor, mask_path=None, verbose=0)\n",
    "    \n",
    "# df_train_data = load_data_all(df_train_label, params={'add_rotation': 'True', 'my_data_path': path_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretching / Shrinking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Manual\" low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutOff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normalCutoff = cutOff / nyq # makes cutoff between 0 and 1\n",
    "#     print('normal cutoff : ', normalCutoff)\n",
    "    b, a = butter(order, normalCutoff, btype='low', analog = False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutOff, fs, order=4):\n",
    "    b, a = butter_lowpass(cutOff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# FIXME: Not sure how to choose between filtfilt and lfilter.\n",
    "# def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "#     normal_cutoff = cutoff / nyq\n",
    "#     # Get the filter coefficients \n",
    "#     b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "#     y = filtfilt(b, a, data)\n",
    "#     return y\n",
    "\n",
    "def apply_lowpass_filter(df_train_data):\n",
    "    # Filter requirements.\n",
    "    order = 10\n",
    "    fs = 50.0  # sample rate, Hz\n",
    "    # FIXME 0.9 should not be hardcoded. It's supposed to be the factor \n",
    "    cutoff = 25 * 0.9  # desired cutoff frequency of the filter, Hz \n",
    "    \n",
    "    # Filter the data\n",
    "    # X = [:,-3], Y = [:,-2], Z = [:,-1]\n",
    "    X_filtered_data = butter_lowpass_filter(df_train_data.iloc[:,-3], cutoff, fs, order)\n",
    "    Y_filtered_data = butter_lowpass_filter(df_train_data.iloc[:,-2], cutoff, fs, order)\n",
    "    Z_filtered_data = butter_lowpass_filter(df_train_data.iloc[:,-1], cutoff, fs, order)\n",
    "\n",
    "    return X_filtered_data, Y_filtered_data, Z_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_signal(measurement_id, path_train_data, resample_path, factor, mask_path=None, verbose=0): \n",
    "    \"\"\"\n",
    "    Function to stretch or shrink a signal  \n",
    "    \n",
    "    Keyword arguments: \n",
    "    - df_train_label: \n",
    "    - path_train_data: path to the data to load. Can provide original data or high_pass data\n",
    "    - factor: use 0.90 to reduce the length of the recording of 10%. Use 1.10 to make the recording 10% longer.\n",
    "    - mask_path: if provided, inactivity will be removed. \n",
    "    - verbose: default 0. If 1, plots will be printed. \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading \" + path_train_data + measurement_id + \".csv\")\n",
    "    df_train_data = pd.read_csv(path_train_data + measurement_id + \".csv\")\n",
    "    \n",
    "#         print('Y max orig: ', df_train_data.iloc[:,-2].max())\n",
    "#         print('Y min orig: ', df_train_data.iloc[:,-2].min())\n",
    "\n",
    "    if (verbose == 1) and (mask_path is not None):\n",
    "        df_train_data.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"Before inactivity removal {0}\".format(get_plot_title(idx, df_train_label)))\n",
    "        plt.show()\n",
    "\n",
    "    if mask_path is not None:\n",
    "        df_train_data = apply_mask(path_train_data, measurement_id, mask_path)\n",
    "#             print('Y max after inactivity removal: ', df_train_data.iloc[:,-2].max())\n",
    "#             print('Y min after inactivity removal: ', df_train_data.iloc[:,-2].min())\n",
    "    if factor < 1:\n",
    "        X_filtered_data, Y_filtered_data, Z_filtered_data = apply_lowpass_filter(df_train_data)\n",
    "    else:\n",
    "        X_filtered_data = df_train_data.iloc[:,-3]\n",
    "        Y_filtered_data = df_train_data.iloc[:,-2]\n",
    "        Z_filtered_data = df_train_data.iloc[:,-1]\n",
    "\n",
    "#         print('X len : ', int(len(X_filtered_data)*factor))\n",
    "#         print('Y len : ', int(len(Y_filtered_data)*factor))\n",
    "#         print('Z len : ', int(len(Z_filtered_data)*factor))\n",
    "\n",
    "#         x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "#         time = df_train_data[x_axis_data_type]\n",
    "\n",
    "#         df_allo =  pd.DataFrame(np.vstack([time,\n",
    "#                                                 X_filtered_data,\n",
    "#                                                 Y_filtered_data,\n",
    "#                                                 Z_filtered_data]).T,columns= [x_axis_data_type, \"X\", \"Y\", \"Z\"])\n",
    "\n",
    "#         print('AAAAAAAAAAAAAAAAAAAa')\n",
    "#         df_allo.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"Shrink/Stretch of factor {0} on {1}\".format(factor, get_plot_title(idx, df_train_label)))\n",
    "#         plt.show()\n",
    "#         print('bbbb')\n",
    "#         print('Y max after lowpass : ', Y_filtered_data.max())\n",
    "#         print('Y min after lowpass: ', Y_filtered_data.min())\n",
    "    X_filtered_data = sg.resample(X_filtered_data, int(len(X_filtered_data)*factor))\n",
    "    Y_filtered_data = sg.resample(Y_filtered_data, int(len(Y_filtered_data)*factor))\n",
    "    Z_filtered_data = sg.resample(Z_filtered_data, int(len(Z_filtered_data)*factor))\n",
    "\n",
    "\n",
    "#         print('Y max after resample: ', Y_filtered_data.max())\n",
    "#         print('Y min after resample: ', Y_filtered_data.min())\n",
    "\n",
    "    # Set the time axis. It's not the same name for the two databases\n",
    "    x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "    time = df_train_data[x_axis_data_type]\n",
    "    if factor <= 1:\n",
    "        time = time[:len(X_filtered_data)]\n",
    "    else:\n",
    "        stop = time.iloc[len(time)-1] + ((len(X_filtered_data) - len(time)) * 0.02)\n",
    "        array_time_add = np.arange(time.iloc[len(time)-1], stop, 0.02)\n",
    "        if len(X_filtered_data) != (len(array_time_add) + len(time)):\n",
    "            array_time_add = array_time_add[:-1]\n",
    "#                 print('not equal')\n",
    "#                 print('len(time) : ', len(time))\n",
    "#                 print('len(array_time_add) : ', len(array_time_add))\n",
    "#                 print('len(X_filtered_data) : ', len(X_filtered_data))\n",
    "#             if len(X_filtered_data) % 2:\n",
    "#                 array_time_add = array_time_add[:-1]\n",
    "        time = time.append(pd.Series(array_time_add))\n",
    "\n",
    "#             while len(time) != len(X_filtered_data):\n",
    "#                 time = time.append(pd.Series([time.iloc[len(time)-1] + 0.02]))\n",
    "#                 print(len(time))\n",
    "\n",
    "#         print('len(time) : ', len(time))\n",
    "#         print('len(X_filtered_data) : ', len(X_filtered_data))\n",
    "#         print('len(Y_filtered_data) : ', len(Y_filtered_data))\n",
    "#         print('len(Z_filtered_data) : ', len(Z_filtered_data))\n",
    "    # Merge the dataframes together \n",
    "    df_low_pass =  pd.DataFrame(np.vstack([time,\n",
    "                                            X_filtered_data,\n",
    "                                            Y_filtered_data,\n",
    "                                            Z_filtered_data]).T,columns= [x_axis_data_type, \"X\", \"Y\", \"Z\"])\n",
    "\n",
    "    # If the high_pass folder doesn't exists, we need to create it \n",
    "    if not os.path.exists(resample_path):\n",
    "        os.makedirs(resample_path)\n",
    "        print('The resample folder was created : ', resample_path)\n",
    "    \n",
    "    # Save to a folder \n",
    "    df_low_pass.to_csv(\n",
    "        resample_path + measurement_id + \".csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "#         if verbose == 1:\n",
    "#             df_train_data.plot(x=\"Timestamp\", legend=True, subplots=True, title=get_plot_title(idx, df_train_label))\n",
    "#             plt.show()\n",
    "\n",
    "#             df_low_pass.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"Shrink/Stretch of factor {0} on {1}\".format(factor, get_plot_title(idx, df_train_label)))\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the HPF + Inactivity Removed data augmentation: shrinking with a 0.9 factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_train_data, df_train_label = define_data_type(data_type,\n",
    "#                                                    data_dir,\n",
    "#                                                    training_or_ancillary)\n",
    "\n",
    "# path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\"\n",
    "# mask_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\"\n",
    "# factor = 0.9\n",
    "# number = 2\n",
    "# resample_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask.resample_{0}_{1}/\".format(factor, number)\n",
    "\n",
    "# resample_signal(df_train_label, path_train_data, resample_path, factor, mask_path, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "print(df_train_label['measurement_id'])\n",
    "path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\"\n",
    "mask_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\"\n",
    "factor = 1.1\n",
    "resample_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask.resample_{0}/\".format(factor)\n",
    "\n",
    "# resample_signal(df_train_label, path_train_data, resample_path, factor, mask_path, verbose=0)\n",
    "\n",
    "number = 1\n",
    "\n",
    "do_work = partial(\n",
    "        resample_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\",\n",
    "        resample_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_{0}_{1}/\".format(factor, number),\n",
    "        factor=1.15, \n",
    "        mask_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "factor = 0.95\n",
    "number = 1\n",
    "\n",
    "do_work = partial(\n",
    "        resample_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\",\n",
    "        resample_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_{0}_{1}/\".format(factor, number),\n",
    "        factor=0.95, \n",
    "        mask_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "factor = 1.05\n",
    "number = 1\n",
    "\n",
    "do_work = partial(\n",
    "        resample_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\",\n",
    "        resample_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_{0}_{1}/\".format(factor, number),\n",
    "        factor=1.05, \n",
    "        mask_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\",\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data/' | egrep -c '^-'\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/' | egrep -c '^-'\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_0.85_1/' | egrep -c '^-'\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_1.15_1/' | egrep -c '^-'\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_0.95_1/' | egrep -c '^-'\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.resample_1.05_1/' | egrep -c '^-'\n",
    "\n",
    "\n",
    "!ls -l '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.1/' | egrep -c '^-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "do_work = partial(\n",
    "        resample_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data/\",\n",
    "        resample_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.resample_{0}/\".format(0.9),\n",
    "        factor=0.9, \n",
    "        mask_path=None,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "do_work = partial(\n",
    "        resample_signal, \n",
    "        path_train_data=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data/\",\n",
    "        resample_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.resample_{0}/\".format(1.1),\n",
    "        factor=1.1, \n",
    "        mask_path=None,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with stretching/shrinking on specific measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import up sound alert dependencies\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time domain to frequency + Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch04.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "df_train_data = pd.read_csv(path_train_data + \"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\" + \".csv\")\n",
    "x = df_train_data.iloc[:,-3]\n",
    "f_s = 50\n",
    "X = fftpack.fft(df_train_data.iloc[:,-3])\n",
    "print(df_train_data.iloc[:,-3])\n",
    "\n",
    "freqs = fftpack.fftfreq(len(x)) * f_s\n",
    "print(len(freqs))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.stem(freqs, np.abs(X))\n",
    "ax.set_xlabel('Frequency in Hertz [Hz]')\n",
    "ax.set_ylabel('Frequency Domain (Spectrum) Magnitude')\n",
    "ax.set_xlim(-f_s / 2, f_s / 2)\n",
    "ax.set_ylim(-5, 110)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "\n",
    "# list_measurement_id = [\n",
    "#     \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "#     \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "#     \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "# ]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "plot_accelerometer(df_train_label=df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots)\n",
    "\n",
    "\n",
    "for idx in df_train_label.index:\n",
    "    #y = librosa.core.resample(x, 4000, 16000)\n",
    "    df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "    \n",
    "    display(df_train_data)\n",
    "    \n",
    "    df_train_data[\"Timestamp\"] = pd.to_datetime(df_train_data[\"Timestamp\"], unit='s')\n",
    "    display(df_train_data)\n",
    "    df_train_data = df_train_data.set_index(df_train_data.Timestamp)\n",
    "    print(type(df_train_data[\"Timestamp\"]))\n",
    "    #df_train_data_minute = df_train_data.resample('S').sum()\n",
    "    df_train_data_minute = df_train_data.resample('S').mean()\n",
    "    display(df_train_data_minute)\n",
    "    \n",
    "    df_train_data_minute.index = np.arange(0,len(df_train_data_minute))\n",
    "    df_train_data_minute.plot(subplots=True)#(x=\"Timestamp\", legend=True, subplots=True, title=\"Noise added\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data_minute.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(0,1200))\n",
    "df_train_data_minute.index = np.arange(0,1200)\n",
    "df_train_data_minute\n",
    "df_train_data_minute.plot()#(x=\"Timestamp\", legend=True, subplots=True, title=\"Noise added\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Noise Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Does adding noise also act as an offset removal? \n",
    "  * I guess it adds a noise centered at 0 so it kind of does \n",
    "  \n",
    "We also have two new hyperparameters here:\n",
    "* `mu` (mean) : Centre of the distribution\n",
    "* `sigma` (variance) : Strandard deviation (spread, or width or the distribution)\n",
    "\n",
    "\n",
    "Sources:\n",
    "* https://stackoverflow.com/questions/46093073/adding-gaussian-noise-to-a-dataset-of-floating-points-and-save-it-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df_train_label, noise_path, path_train_data, data_type, mask_path=None, mu=0, sigma=0.1):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    - mask_path: Provide if you want to remove inactivity \n",
    "    \"\"\"\n",
    "\n",
    "    for idx in df_train_label.index:\n",
    "        print(df_train_label[\"measurement_id\"][idx])\n",
    "        df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "        \n",
    "        if mask_path is not None:\n",
    "            df_train_data = apply_mask(path_train_data, df_train_label[\"measurement_id\"][idx], mask_path)\n",
    "        # creating a noise with the same dimension as the recording\n",
    "        df_noise = np.random.normal(mu, sigma, df_train_data.iloc[:,-3:].shape)#[59805,3]) \n",
    "\n",
    "        df_signal = df_train_data.iloc[:,-3:] + df_noise\n",
    "        df_signal = pd.concat([df_train_data.iloc[:, 0], df_signal], axis=1)\n",
    "\n",
    "        # If the high_pass folder doesn't exists, we need to create it \n",
    "        if not os.path.exists(noise_path):\n",
    "            os.makedirs(noise_path)\n",
    "            print('The noise folder was created : ', noise_path)\n",
    "\n",
    "        # Save to a folder \n",
    "        df_signal.to_csv(\n",
    "            noise_path + df_train_label[\"measurement_id\"][idx] + \".csv\",\n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create noise augmented csv files (on original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "noise_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.1/\"\n",
    "data_type = \"cis\"\n",
    "\n",
    "add_noise(df_train_label, noise_path, path_train_data, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create noise augmented csv (on high pass filtered + inactivity removed data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sigma in [0.01,0.001]:#[0.1, 0.2, 0.3, 0.4, 0.5]: \n",
    "    path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                       data_dir,\n",
    "                                                       training_or_ancillary)\n",
    "\n",
    "    # Redefine manually the path because we want the data where high pass was already applied\n",
    "    path_train_data = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data/'\n",
    "    noise_path = \"/export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_{0}_1/\".format(sigma)\n",
    "    data_type = \"cis\"\n",
    "\n",
    "    add_noise(df_train_label, noise_path, path_train_data, data_type, mu=0, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.1_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.2_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.3_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.4_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.noise_mu_0_sig_0.5_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!./tsfresh/submit/create_scp_files.sh noise_mu_0_sig_0.1_1\n",
    "!./tsfresh/submit/create_scp_files.sh noise_mu_0_sig_0.2_1\n",
    "!./tsfresh/submit/create_scp_files.sh noise_mu_0_sig_0.3_1\n",
    "!./tsfresh/submit/create_scp_files.sh noise_mu_0_sig_0.4_1\n",
    "!./tsfresh/submit/create_scp_files.sh noise_mu_0_sig_0.5_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Combhpfnoinact data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.4_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.5_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sigma in [0.01, 0.001]:#[0.4, 0.5]: #missing 0.2 and 0.3\n",
    "    path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                       data_dir,\n",
    "                                                       training_or_ancillary)\n",
    "\n",
    "    # Redefine manually the path because we want the data where high pass was already applied\n",
    "    path_train_data = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/'\n",
    "    mask_path = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/'\n",
    "    noise_path = \"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_{0}_1/\".format(sigma)\n",
    "    data_type = \"cis\"\n",
    "\n",
    "    add_noise(df_train_label, noise_path, path_train_data, data_type, mask_path, mu=0, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.01_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.001_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For curiosity, what happens if mu=0.1, sigma=0.1? That's a lot more noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                       data_dir,\n",
    "                                                       training_or_ancillary)\n",
    "\n",
    "# Redefine manually the path because we want the data where high pass was already applied\n",
    "path_train_data = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/'\n",
    "mask_path = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/'\n",
    "noise_path = \"/export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0.1_sig_0.1_1/\".format(sigma)\n",
    "data_type = \"cis\"\n",
    "\n",
    "add_noise(df_train_label, noise_path, path_train_data, data_type, mask_path, mu=0.1, sigma=0.1)\n",
    "\n",
    "!ln -s /export/fs02/mpgill/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0.1_sig_0.1_1/ /home/sjoshi/codes/python/BeatPD/data/BeatPD/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat 5 times mu = 0, sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no in [1, 2, 3, 4, 5]:\n",
    "    path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                       data_dir,\n",
    "                                                       training_or_ancillary)\n",
    "\n",
    "    # Redefine manually the path because we want the data where high pass was already applied\n",
    "    path_train_data = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/'\n",
    "    mask_path = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/'\n",
    "    noise_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.1_{0}/\".format(no)\n",
    "    data_type = \"cis\"\n",
    "\n",
    "    add_noise(df_train_label, noise_path, path_train_data, data_type, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added noise visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path_5 = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.1_5/\"\n",
    "noise_path_2 = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.1_2/\"\n",
    "path_train_comb = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\"\n",
    "df_train_data = pd.read_csv(path_train_comb + \"2d852742-10a9-4c56-9f38-779f2cd66879\" + \".csv\")\n",
    "df_train_data_5 = pd.read_csv(noise_path_5 + \"2d852742-10a9-4c56-9f38-779f2cd66879\" + \".csv\")\n",
    "df_train_data_2 = pd.read_csv(noise_path_2 + \"2d852742-10a9-4c56-9f38-779f2cd66879\" + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data_5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def plot_data_aug(df_train_label, path, aug_type, title=None, path_accelerometer_plots=None):\n",
    "    for idx in df_train_label.index:\n",
    "        df_train_data = pd.read_csv(path + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "        display(df_train_data.describe())\n",
    "        if aug_type == \"noise\":\n",
    "            m = re.search('(?<=mu_)[\\d+.]+', path)\n",
    "            mu = m.group(0)\n",
    "            m = re.search('(?<=sig_)[\\d+.]+', path)\n",
    "            sigma = m.group(0)\n",
    "            plot_title = \"Noise added. Mean=\"+mu+\", sigma = \"+sigma\n",
    "        elif aug_type == \"rotation\":\n",
    "            plot_title = title\n",
    "        elif aug_type == \"resampling\":\n",
    "            m = re.search('(?<=resample_)[\\d+.]+', path)\n",
    "            factor = m.group(0)\n",
    "            plot_title = \"Resampling with factor \"+factor\n",
    "        df_train_data.plot(x=\"Timestamp\", legend=True, subplots=True, title=plot_title)\n",
    "        # Save plotted graph with the measurement_id as name of the file\n",
    "        if path_accelerometer_plots is not None:\n",
    "            plt.savefig(path_accelerometer_plots + plot_title.replace(\" \", \"_\").replace(\",\",\"\").replace(\".\",\"\").replace(\"=\",\"_\")+\"_\"+df_train_label[\"measurement_id\"][idx] + \".png\")\n",
    "            plt.savefig(path_accelerometer_plots + plot_title.replace(\" \", \"_\").replace(\",\",\"\").replace(\".\",\"\").replace(\"=\",\"_\")+\"_\"+df_train_label[\"measurement_id\"][idx]+ \".pdf\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "\n",
    "list_measurement_id = [\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "]\n",
    "\n",
    "list_measurement_id = [\n",
    "    \"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\",\n",
    "    \"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\",\n",
    "    \"5163afe8-a6b0-4ea4-b2ba-9b4501dd5912\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d\",  # no inactivity should be removed\n",
    "    \"3cf49c01-0499-4bad-9167-67691711204a\",  # no inactivity should be removed PAS LA??\n",
    "    \"3d0f965c-9d72-43d1-9369-1ea3acf963cc\",  # PAS LA ???\n",
    "    \"4b269cc2-8f0c-4816-adbf-10c0069b8833\",\n",
    "    \"4bc51b90-bfce-4231-85e1-5de3b4bc0745\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "]\n",
    "\n",
    "list_measurement_id = [\"3cf49c01-0499-4bad-9167-67691711204a\"]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "path_train_data = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/'\n",
    "\n",
    "plot_accelerometer(df_train_label=df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/\")\n",
    "\n",
    "data_path=\"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "\n",
    "# Noise\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.1/\", \"noise\",\n",
    "#               path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/noise/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.2_1/\", \"noise\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/noise/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.3_1/\", \"noise\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/noise/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.4_1/\", \"noise\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/noise/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.noise_mu_0_sig_0.5_1/\", \"noise\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/noise/\")\n",
    "\n",
    "# # Rotation \n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.rotate_1/\", \"rotation\", \"Rotation 1 [-45,45[\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/rotation/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.rotate_2/\", \"rotation\", \"Rotation 2 [-45,45[\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/rotation/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.rotate_3/\", \"rotation\", \"Rotation 3 [-45,45[\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/rotation/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.rotate_bound_30/\", \"rotation\", \"Rotation Bounds [-30, -25[, [25, 30[\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/rotation/\")\n",
    "\n",
    "# # Resample \n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_0.85_1/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_0.9/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_0.95_1/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_1.05_1/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_1.1/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")\n",
    "# plot_data_aug(df_train_label, data_path+\"cis-pd.training_data.combhpfnoinact.resample_1.15_1/\", \"resampling\",\n",
    "#              path_accelerometer_plots=\"/export/b19/mpgill/BeatPD_data_aug_plots/resampling/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This measurement didn't have any high pass for some reason "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "path_train_data, df_train_label = define_data_type(data_type, data_dir, 'training_data')\n",
    "\n",
    "list_measurement_id = [\"dc90dc36-b4e5-43ec-b3e8-47c39c763c71\"]\n",
    "high_pass_path = '/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/'\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "print(df_train_label)\n",
    "\n",
    "high_pass_filter(df_train_label, high_pass_path, path_train_data, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on how to do rotation on only one measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train_label['measurement_id'])\n",
    "# path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\"\n",
    "# mask_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/\"\n",
    "# factor = 1.1\n",
    "# resample_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask.resample_{0}/\".format(factor)\n",
    "\n",
    "\n",
    "# rotate_signal(measurement_id, path_train_data, params, rotation_path, factor, mask_path=None, verbose=0):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using decimate of scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "for idx in df_train_label.index:\n",
    "    df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "    x = df_train_data.iloc[:,-3]\n",
    "    print(df_train_data.shape)\n",
    "    z = sg.decimate(x, 2, zero_phase=True)\n",
    "    print((z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
