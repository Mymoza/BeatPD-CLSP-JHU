{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEAT-PD Challenge\n",
    "\n",
    "Challenge website : https://www.synapse.org/#!Synapse:syn20825169/wiki/596118\n",
    "\n",
    "Data information : https://www.synapse.org/#!Synapse:syn20825169/wiki/600405\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas/Doubts [Laureano]\n",
    "\n",
    "VAD like thing to remove unwanted data?\n",
    "modified MFCC?\n",
    "X,Y,Z = relative positions or acceleration?\n",
    "\n",
    "Imp: Predict per person. Maybe UBM like thing and adapt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Imports for the high pass signal\n",
    "from scipy.signal import butter, freqz, lfilter\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import required modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os.path\n",
    "\n",
    "# To write WAV File\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "# FIXME : Move this to data?\n",
    "path_save_accelerometer_plots = (\"/home/sjoshi/codes/python/BeatPD/code/accelerometer_plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_data_type(data_type):\n",
    "    \"\"\"\n",
    "    Setup file names\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data_type = {cis , real}\n",
    "\n",
    "    If data_type is real, data_real_subtype will have to be declared as well \n",
    "    data_real_subtype={smartphone_accelerometer, smartwatch_accelerometer, smartwatch_gyroscope}\n",
    "    \"\"\"\n",
    "    if data_type == \"cis\":\n",
    "        path_train_labels = (\n",
    "            data_dir\n",
    "            + data_type\n",
    "            + \"-pd.data_labels/\"\n",
    "            + data_type.upper()\n",
    "            + \"-PD_Training_Data_IDs_Labels.csv\"\n",
    "        )\n",
    "        path_train_data = data_dir + data_type + \"-pd.training_data/\"\n",
    "\n",
    "    if data_type == \"real\":\n",
    "        path_train_labels = (\n",
    "            data_dir\n",
    "            + data_type\n",
    "            + \"-pd.data_labels/\"\n",
    "            + data_type.upper()\n",
    "            + \"-PD_Training_Data_IDs_Labels.csv\"\n",
    "        )\n",
    "        path_train_data = (\n",
    "            data_dir + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "        )\n",
    "\n",
    "    # Display labels\n",
    "    df_train_label = pd.read_csv(path_train_labels)\n",
    "    return path_train_data, df_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_title(idx, df_train_label):\n",
    "    \"\"\"\n",
    "    Create a title that identifies the plotted graph with the measurement_id, \n",
    "    subject_id, on_off label, dyskinesia and tremor labels.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    - idx: \n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \n",
    "    Returns: A string concatenating all the values mentioned \n",
    "    \"\"\"\n",
    "    # Following val_* variables are only used to format a cute title for the charts\n",
    "    val_subject_id = df_train_label.loc[[idx]][\"subject_id\"].values[0]\n",
    "    val_on_off = df_train_label.loc[[idx]][\"on_off\"].values[0]\n",
    "    val_dyskinesia = df_train_label.loc[[idx]][\"dyskinesia\"].values[0]\n",
    "    val_tremor = df_train_label.loc[[idx]][\"tremor\"].values[0]\n",
    "    return \"{0} = on_off: {1}, dyskinesia: {2}, tremor: {3}\".format(\n",
    "        val_subject_id, val_on_off, val_dyskinesia, val_tremor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accelerometer(data_type, path_accelerometer_plots, path_inactivity=None):\n",
    "    \"\"\"\n",
    "    Plots the accelerometer data. There will be 3 subplots for each axis (X, Y, Z)\n",
    "    \n",
    "    Keyword arguments: \n",
    "    - data_type={cis , real} : It depends on which database is used \n",
    "    - path_accelerometer_plots: Path where the accelerometer plots are going to be saved \n",
    "    - path_inactivity: Path where the dataframe with inactivity  removed are \n",
    "    \"\"\"\n",
    "    # Iterating through all the indexes contained in df_train_label\n",
    "    for idx in df_train_label.index:\n",
    "        if path_inactivity is None:\n",
    "            df_train_data = pd.read_csv(\n",
    "                path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "            )\n",
    "        else:\n",
    "            df_train_data = pd.read_csv(\n",
    "                path_inactivity + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "            )\n",
    "\n",
    "        # FIXME: BUG ?  why the following goes to 1000xxx sometimes? It should be max 59xxx\n",
    "        print(\"measurement_id : \", df_train_label[\"measurement_id\"][idx])\n",
    "        # Following val_* variables are only used to format a cute title for the charts\n",
    "        great_title = get_plot_title(idx, df_train_label)\n",
    "\n",
    "        # The time doesn't have the same name depending on the data_type\n",
    "        x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "\n",
    "        # Normalize the data\n",
    "        cols_to_norm = [\"x\", \"y\", \"z\"] if data_type == \"real\" else [\"X\", \"Y\", \"Z\"]\n",
    "        df_train_data[cols_to_norm] = df_train_data[cols_to_norm].apply(\n",
    "            lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "        )\n",
    "\n",
    "        df_train_data.plot(\n",
    "            x=x_axis_data_type, legend=True, subplots=True, title=great_title\n",
    "        )\n",
    "\n",
    "        # Save plotted graph with the measurement_id as name of the file\n",
    "        plt.savefig(\n",
    "            path_accelerometer_plots + df_train_label[\"measurement_id\"][idx] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_missing_values(df_train_label):\n",
    "    \"\"\"\n",
    "    Filling NaN values with -1. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    # Replace NaN values with -1.0 because otherwise plotting triggers an error\n",
    "    df_train_label = df_train_label.fillna(value=-1.0)\n",
    "    return df_train_label\n",
    "\n",
    "\n",
    "def compute_symptoms_occurences_dataframe(df_train_label):\n",
    "    \"\"\"\n",
    "    Computes how many times the symptoms are occuring for a single subject_id \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    df_train_label = prepro_missing_values(df_train_label=df_train_label)\n",
    "\n",
    "    # Group data by subject_id\n",
    "    df_train_label_subject_id = df_train_label.groupby(\"subject_id\")\n",
    "\n",
    "    df_occurences = []\n",
    "    symptoms = [\"on_off\", \"dyskinesia\", \"tremor\"]\n",
    "\n",
    "    for key, value in df_train_label_subject_id:\n",
    "        for symptom in symptoms:\n",
    "            # Pour un patient, prendre les 3 dernieres colonnes, et pour 1 symptome, calculer le nb d'occurences\n",
    "            counter = (\n",
    "                df_train_label_subject_id.get_group(key)\n",
    "                .iloc[:, -3:][symptom]\n",
    "                .value_counts()\n",
    "            )\n",
    "\n",
    "            for symptom_value, symptom_occurence in counter.items():\n",
    "                df_occurences.append(\n",
    "                    (\n",
    "                        {\n",
    "                            \"subject_id\": key,\n",
    "                            \"symptom\": symptom,\n",
    "                            \"symptom_value\": symptom_value,\n",
    "                            \"occurence\": symptom_occurence,\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    df_occurences = pd.DataFrame(\n",
    "        df_occurences, columns=(\"subject_id\", \"symptom\", \"symptom_value\", \"occurence\")\n",
    "    )\n",
    "\n",
    "    return df_occurences, df_train_label_subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_symptoms_occurences(df_occurences, df_train_label_subject_id):\n",
    "    \"\"\"\n",
    "    This function plots the occurences of symptoms according to subject_id \n",
    "\n",
    "    Keyword Arguments: \n",
    "    - df_occurences: contains the df with occurences computed in compute_symptoms_occurences_dataframe\n",
    "    - df_train_label_subject_id: contains df_train_label grouped by subject_id \n",
    "    \"\"\"\n",
    "    # There will be one graph plotted for each patient, for each of the 3 symptoms\n",
    "    nb_subjects_id = (\n",
    "        df_occurences.subject_id.nunique()\n",
    "    )  # nb of unique patients in the label file\n",
    "    print(\"Nb subject_id : \", nb_subjects_id)\n",
    "    height = 30 if nb_subjects_id > 10 else 10\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nb_subjects_id, ncols=3, figsize=(10, height), sharey=True\n",
    "    )  # 3 cols for the 3 symptoms\n",
    "\n",
    "    # Quick fix to plot the graphs at the right place. Starts at -1 because in the first for loop\n",
    "    # it is incremented\n",
    "    patient = -1\n",
    "\n",
    "    # Plot for all subject_id 3 bar plots for all the symptoms and their occurences\n",
    "    # Reminder that NaN values (missing values) were replaced with -1 and are shown as such in the plots\n",
    "    symptoms = [\"on_off\", \"dyskinesia\", \"tremor\"]\n",
    "    for key, value in df_train_label_subject_id:\n",
    "        patient = patient + 1  # value used to position the plots (row)\n",
    "        symptom_no = 0  # value only used to position the plots (col)\n",
    "        for symptom in symptoms:\n",
    "            subject_symptom = \" \".join(\n",
    "                [str(key), symptom]\n",
    "            )  # variable used to create a title for each plot\n",
    "            df_train_label_subject_id.get_group(key)[symptom].value_counts().plot(\n",
    "                kind=\"bar\",\n",
    "                x=symptom,\n",
    "                title=subject_symptom,\n",
    "                ax=axes[patient, symptom_no],\n",
    "                sharey=True,\n",
    "            )\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.tight_layout()\n",
    "            symptom_no = symptom_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interesting_patients(df_train_label, list_measurement_id):\n",
    "    \"\"\"\n",
    "    Filters df_train_label according to a list of measurement_id we are interested in analyzing\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - df_train_label: Labels DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    - list_measurement_id: list of measurement_id \n",
    "\n",
    "    Returns:\n",
    "    - df_train_label: filtered df_train_label containing only the measurements_id we are interested in \n",
    "    \"\"\"\n",
    "    filter_measurement_id = df_train_label.measurement_id.isin(list_measurement_id)\n",
    "\n",
    "    df_train_label = df_train_label[filter_measurement_id]\n",
    "    # display(df_train_label)\n",
    "    return df_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possible to have participant characteristics from additional db data? ex https://ieeexplore.ieee.org/abstract/document/7911257"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP : Function to remove silence (inactivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_threshold(threshold_energy, max_values):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe of shape (3,1) containing what is the treshold for each X,Y,Z axis \n",
    "    depending on threshold_energy. \n",
    "\n",
    "    For example if threshold_energy=10, the function is going to return what is 10% of the max_values\n",
    "\n",
    "    Arguments:\n",
    "    - threshold_energy: Percentage of the max values we want to use as treshold \n",
    "    - max_values: Dataframe of the max values \n",
    "    \"\"\"\n",
    "    return (max_values * threshold_energy) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean offset removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactivity_mean_offset(df_train_label):\n",
    "    \"\"\"\n",
    "    Removal of inactivity segments detected with a threshold after the energy is centered over the mean\n",
    "    This function is expected to be less efficient than removal of inactivity with the highpass threshold \n",
    "    \n",
    "    Keyword arguments: \n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    for idx in df_train_label.index:\n",
    "        df_train_data = pd.read_csv(\n",
    "            path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "        )\n",
    "\n",
    "        ### Following section works on removing offset with mean\n",
    "        inputData_DCRemoved = df_train_data.iloc[:, -3:] - df_train_data.iloc[\n",
    "            :, -3:\n",
    "        ].mean(axis=0)\n",
    "\n",
    "        # inputData with DC Removed only has NaN for the Timestamp values, so we are adding them\n",
    "        inputData_DCRemoved.insert(0, \"Timestamp\", df_train_data[\"Timestamp\"])\n",
    "\n",
    "        # Plot the graph\n",
    "        great_title = get_plot_title(idx, df_train_label)\n",
    "        print(df_train_label[\"measurement_id\"][idx])\n",
    "        inputData_DCRemoved.plot(\n",
    "            x=\"Timestamp\", legend=True, subplots=True, title=great_title\n",
    "        )\n",
    "\n",
    "        ### Following section works on removing inactivity following a treshold\n",
    "        # Get the absolute max values for X, Y, Z\n",
    "        max_values = inputData_DCRemoved.iloc[:, -3:].abs().max()\n",
    "\n",
    "        # Compute what is X% of that max\n",
    "        df_treshold = get_df_threshold(10, max_values)\n",
    "\n",
    "        df_candidates = inputData_DCRemoved[\n",
    "            (inputData_DCRemoved.X.abs() <= df_treshold[\"X\"])\n",
    "            & (inputData_DCRemoved.Y.abs() <= df_treshold[\"Y\"])\n",
    "            & (inputData_DCRemoved.Z.abs() <= df_treshold[\"Z\"])\n",
    "        ]\n",
    "\n",
    "        print(\"Candidates to be removed:\")\n",
    "        display(df_candidates)\n",
    "\n",
    "        filter_df = inputData_DCRemoved[\n",
    "            ~inputData_DCRemoved.isin(df_candidates)\n",
    "        ].dropna(how=\"all\")\n",
    "        great_title = \"filter_df for : \" + great_title\n",
    "        filter_df.plot(x=\"Timestamp\", legend=True, subplots=True, title=great_title)\n",
    "\n",
    "        # FIXME: This function is not done. As it's not the priority, i'm switching to work on highpass filter\n",
    "        # It doesn't remove the identified candidates or save the 0/1 vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High pass filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source of the code about the highpass: https://gist.github.com/junzis/e06eca03747fc194e322\n",
    "# A bit more explanation here: https://medium.com/analytics-vidhya/how-to-filter-noise-with-a-low-pass-filter-python-885223e5e9b7\n",
    "\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype=\"high\", analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def remove_inactivity_highpass(\n",
    "    df_train_label,\n",
    "    energy_threshold,\n",
    "    duration_threshold,\n",
    "    mask_path,\n",
    "    plot_frequency_response=False,\n",
    "    plot_accelerometer_after_removal=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Removes inactivity according to a high pass filter. It will only be applied to the measurement_id provided\n",
    "    in the df_train_label variable. A first condition for a measurement to be removed at a certain timestamp\n",
    "    is that first, the energy is less than the energy_treshold. After that, we identify candidates with a vector\n",
    "    where 0 represents a timestamp we want to keep, and 1 represents timestamps we detected as below the minimum \n",
    "    energy threshold. \n",
    "    \n",
    "    The second threshold, called duration_threshold, represents the condition that there must be a minimum \n",
    "    number of consecutives candidates to be removed befoer the candidates will be indeed removed and confirmed\n",
    "    as inactivity. For example, we could decide to only remove sections that are at least 1 minute long of \n",
    "    inactivity detected.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    - energy_threshold: what percentage of the max energy do we consider as inactivity?\n",
    "        For example, 1 of the max is considered as inactivity\n",
    "    - duration_threshold: how long do we want to have inactivity before we remove it? \n",
    "        For example 3000x0.02ms=1min of inactivity minimum before those candidates are removed\n",
    "    - mask_path: Path where to save the mask \n",
    "    - plot_frequency_response: Optional. {True, False}. \n",
    "                               Flag to determine if we want to plot the frequency response or not\n",
    "    -plot_accelerometer_after_removal: Optinal. {True, False}.\n",
    "                                Flag to determine if we want to plot the accelerometer after the inactivity\n",
    "                                is removed\n",
    "    \"\"\"\n",
    "    # Filter requirements.\n",
    "    order = 10\n",
    "    fs = 50.0  # sample rate, Hz\n",
    "    cutoff = 0.5  # 3.667  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "    # Get the filter coefficients so we can check its frequency response.\n",
    "    b, a = butter_highpass(cutoff, fs, order)\n",
    "\n",
    "    # Load every training file for each \"row of labels\" we have loaded in df_train_label\n",
    "    for idx in df_train_label.index:\n",
    "        print('Working on ', df_train_label[\"measurement_id\"][idx])\n",
    "        # Load the training data\n",
    "        df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "\n",
    "        # Set the time axis. It's not the same name for the two databases\n",
    "        x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "        t = df_train_data[x_axis_data_type]\n",
    "\n",
    "        # Filter the data\n",
    "        X_filtered_data = butter_highpass_filter(df_train_data[\"X\"], cutoff, fs, order)\n",
    "        Y_filtered_data = butter_highpass_filter(df_train_data[\"Y\"], cutoff, fs, order)\n",
    "        Z_filtered_data = butter_highpass_filter(df_train_data[\"Z\"], cutoff, fs, order)\n",
    "\n",
    "        ### Following section works on removing inactivity following a treshold\n",
    "        # Get the absolute max values for X, Y, Z\n",
    "        # FIXME: This could be made better but I won't lose time on this now\n",
    "        # Get in a Series format because that's what the threshold function is expecting\n",
    "        max_values = pd.Series(np.array([\n",
    "                    np.abs(X_filtered_data).max(),\n",
    "                    np.abs(Y_filtered_data).max(),\n",
    "                    np.abs(Z_filtered_data).max(),\n",
    "                ]))\n",
    "\n",
    "        # Get the threshold of the filtered data\n",
    "        df_treshold = get_df_threshold(energy_threshold, max_values)\n",
    "        print('df threshold : ', df_treshold)\n",
    "        # Get 0/1 candidates\n",
    "        X_zeros = np.abs(X_filtered_data) <= df_treshold[0]\n",
    "        Y_zeros = np.abs(Y_filtered_data) <= df_treshold[1]\n",
    "        Z_zeros = np.abs(Z_filtered_data) <= df_treshold[2]\n",
    "        \n",
    "        display(X_zeros)\n",
    "        display(Y_zeros)\n",
    "        display(Z_zeros)\n",
    "        \n",
    "        # Change data from boolean to 0 and 1s (int)\n",
    "        X_zeros = X_zeros.astype(int)\n",
    "        Y_zeros = Y_zeros.astype(int)\n",
    "        Z_zeros = Z_zeros.astype(int)\n",
    "        # AND operand to identify candidates across all axis\n",
    "        # FIXME: change name of variable bc it's not a df\n",
    "        df_zeros = X_zeros & Y_zeros & Z_zeros\n",
    "\n",
    "\n",
    "        # Check if it reaches the time treshold (like minimum 1 minute long to be removed)\n",
    "        start = 0  # Start and end of the series of 1\n",
    "        end = 0\n",
    "        indices_list = []  # List of tuples\n",
    "        howmany = 0  # How many groups we identified (not required, just nice metric)\n",
    "        count = 0  # How many 1 in a row we found\n",
    "\n",
    "        # Counts the number of 0s and 1s in the original data before we apply the threshold\n",
    "#         unique, counts = np.unique(df_zeros, return_counts=True)\n",
    "#         print(dict(zip(unique, counts)))\n",
    "\n",
    "        # Change the candidates for removal (1) to 0 if there are not enough 1s in a row to reach the\n",
    "        # threshold. For example there needs to be 3000 times 1s in a row for 1 minute of \"inactivity\"\n",
    "        # to be removed\n",
    "        for i in range(0, len(df_zeros)):\n",
    "            if df_zeros[i] == 1:\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if count >= duration_threshold:\n",
    "                    start = i - count\n",
    "                    end = i - 1\n",
    "                    indices_list.append((start, end))\n",
    "                    howmany = howmany + 1\n",
    "                    count = 0\n",
    "                elif (\n",
    "                    count >= 1\n",
    "                ):  # if it doesn't reach the threshold, we change the 1 for 0 because we don't want to remove those\n",
    "                    start = i - count\n",
    "                    end = i\n",
    "                    df_zeros[start:end] = [0] * (end - start)\n",
    "                    count = 0\n",
    "\n",
    "        #print(\"There are \"+ str(howmany) + \" groups identified as candidates to be removed\")\n",
    "\n",
    "        # Counts the number of 0s and 1s in the data after we applied the threshold\n",
    "#         unique, counts = np.unique(df_zeros, return_counts=True)\n",
    "#         print(dict(zip(unique, counts)))\n",
    "\n",
    "        # Save 0/1 candidates to csv\n",
    "        # I use 1-df_zeros to swap the 0s and 1s.\n",
    "        # 1: we want to keep this measure\n",
    "        # 0: detected as inactivity so we want to remove it\n",
    "        # Previously, it was the opposite, as 1s were considered inactivity\n",
    "        df_mask_highpass = pd.DataFrame(1 - df_zeros)\n",
    "        df_mask_highpass.to_csv(\n",
    "            mask_path + df_train_label[\"measurement_id\"][idx] + \".csv\",\n",
    "            index=False,\n",
    "            header=False,\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "        # Plot the accelerometer with the removed sections\n",
    "        # The [0] is used to get a pandas.Series instead of a DataFrame\n",
    "        # We insert Timestamp again as it was removed for the filtering\n",
    "        # BUG : Should I use df_train_data or the filtered high pass dataframe?\n",
    "        if plot_accelerometer_after_removal:\n",
    "            filtered_df = df_train_data.iloc[:, -3:].multiply(df_mask_highpass[0], axis=0)\n",
    "            print('LEN FILTERED DF : ', len(filtered_df))\n",
    "            filtered_df.insert(0, x_axis_data_type, df_train_data[x_axis_data_type])\n",
    "            great_title = get_plot_title(idx, df_train_label)\n",
    "            filtered_df.plot(\n",
    "                x=x_axis_data_type, legend=True, subplots=True, title=great_title\n",
    "            )\n",
    "            display(filtered_df)\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "            plt.close()\n",
    "\n",
    "        # Plot the frequency response, and plot both the original and filtered signals for X, Y and Z.\n",
    "        if plot_frequency_response:\n",
    "            # TODO: Make the graphs bigger\n",
    "            w, h = freqz(b, a, worN=8000)\n",
    "            plt.subplot(4, 1, 1)\n",
    "            plt.plot(0.5 * fs * w / np.pi, np.abs(h), \"b\")\n",
    "            plt.plot(cutoff, 0.5 * np.sqrt(2), \"ko\")\n",
    "            plt.axvline(cutoff, color=\"k\")\n",
    "            plt.xlim(0, 0.5 * fs)\n",
    "            plt.title(\"Highpass Filter Frequency Response\")\n",
    "            plt.xlabel(\"Frequency [Hz]\")\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(4, 1, 2)\n",
    "            plt.plot(t, df_train_data[\"X\"], \"b-\", label=\"X\")\n",
    "            plt.plot(t, X_filtered_data, \"g-\", linewidth=2, label=\"filtered X\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(4, 1, 3)\n",
    "            plt.plot(t, df_train_data[\"Y\"], \"b-\", label=\"Y\")\n",
    "            plt.plot(t, Y_filtered_data, \"g-\", linewidth=2, label=\"filtered Y\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(4, 1, 4)\n",
    "            plt.plot(t, df_train_data[\"Z\"], \"b-\", label=\"Z\")\n",
    "            plt.plot(t, Z_filtered_data, \"g-\", linewidth=2, label=\"filtered Z\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.xlabel(\"Time [sec]\")\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplots_adjust(hspace=0.7)\n",
    "            plt.show()\n",
    "\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(measurement_id, mask_path):\n",
    "    \"\"\"\n",
    "    Apply a mask on the list of measurement_ids provided through df_train_label \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    # Load the training data\n",
    "    print('measurement_id ', measurement_id)\n",
    "    df_train_data = pd.read_csv(path_train_data + measurement_id + \".csv\")\n",
    "    df_mask = pd.read_csv(mask_path + measurement_id + \".csv\", header=None)\n",
    "\n",
    "    # multiply df_train_data by mask so the values to be removed are at 0\n",
    "    #         np.multiply(df2.iloc[:,-3:],df_mask.iloc[:,-1:])\n",
    "    df_train_data.iloc[:, -3:] = np.multiply(df_train_data.iloc[:, -3:], df_mask)#[:, -1:])\n",
    "\n",
    "    #         display(df_train_data)\n",
    "\n",
    "    # Drop the 0 values from the training DataFrame\n",
    "    df_train_data = df_train_data[(df_train_data.iloc[:, -3:].T != 0).any()]\n",
    "    df_train_data.reset_index(drop=True, inplace=True)\n",
    "    return df_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get velocity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivative_value(df_train_data_context, m):\n",
    "    \"\"\"\n",
    "    TODO \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_data_context: TODO\n",
    "    - m: TODO \n",
    "    \"\"\"\n",
    "    # Dot Product is the sum of the point wise multiplications between a and m\n",
    "    cij = np.dot(df_train_data_context, m)\n",
    "    denum = np.dot(m, m)\n",
    "    return cij / denum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_derivative(measurement_id, derivative_path, n_zero=3, padding=False, mask_path=None):\n",
    "    \"\"\"\n",
    "    TODO \n",
    "    \n",
    "    cis-pd.training_data.velocity_original_data: Original data, which means the inactivity is untouched \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: TODO\n",
    "    - derivative_path: TODO\n",
    "    - n_zero: TODO\n",
    "    - Padding: [False, True] \n",
    "      - If True, it will add a padding of [0,0,0] at the beginning and at the end of the training data\n",
    "      - If False, it will just use the existing values of the training data to have a (7,) vector from the\n",
    "        training data\n",
    "    - mask_path: Optinal. If provided, it will apply the high pass mask on the training data \n",
    "    \"\"\"\n",
    "    # m is a vector. For n_zero, it will be [-3, -2, -1, 0, 1, 2, 3]\n",
    "    m = np.linspace(-n_zero, n_zero, num=2 * n_zero + 1)\n",
    "\n",
    "    file_path= data_dir+derivative_path+ measurement_id + '.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print (\"File exist : \", file_path)\n",
    "        return\n",
    "\n",
    "    # Load the training data\n",
    "    if mask_path is not None:\n",
    "        df_train_data = apply_mask(measurement_id, mask_path)\n",
    "    else: # Going to get the first derivative from the original data \n",
    "        df_train_data = pd.read_csv(path_train_data + measurement_id + \".csv\")\n",
    "\n",
    "    df_velocity= []\n",
    "#         df_velocity_X = []\n",
    "#         df_velocity_Y = []\n",
    "#         df_velocity_Z = []\n",
    "\n",
    "    if padding:\n",
    "        # Padding DataFrame to add 3 empty rows at the beginning and at the end of the training data\n",
    "        df_padding = []\n",
    "\n",
    "        # FIXME: This could probably be made faster but I won't lose time on this\n",
    "        df_padding.insert(0, {\"Timestamp\": -1, \"X\": 0, \"Y\": 0, \"Z\": 0})\n",
    "        df_padding.insert(0, {\"Timestamp\": -1, \"X\": 0, \"Y\": 0, \"Z\": 0})\n",
    "        df_padding.insert(0, {\"Timestamp\": -1, \"X\": 0, \"Y\": 0, \"Z\": 0})\n",
    "\n",
    "        df_train_data = pd.concat(\n",
    "            [pd.DataFrame(df_padding), df_train_data], ignore_index=True\n",
    "        )\n",
    "        df_padding = pd.DataFrame({\"Timestamp\": [-1, -1, -1],\n",
    "                                    \"X\": [0, 0, 0],\n",
    "                                    \"Y\": [0, 0, 0],\n",
    "                                    \"Z\": [0, 0, 0]})\n",
    "\n",
    "        df_train_data_padding = df_train_data.append(df_padding, ignore_index=True)\n",
    "    else:  # FIXME remove this it's just a quickfix because there is the option with or without padding\n",
    "        # and the next loop has to be on the original dataframe withtout padding\n",
    "        df_train_data_padding = df_train_data\n",
    "\n",
    "    # BUG : This df_velocity contains 3 extra rows. I'm not sure where they come from \n",
    "    for row in df_train_data[[\"X\", \"Y\", \"Z\"]].itertuples():\n",
    "        end = row.Index + n_zero\n",
    "\n",
    "        start = row.Index - n_zero\n",
    "\n",
    "        # QUICKFIX to the padding and pointers issue \n",
    "        if start == -3:\n",
    "            start = 0\n",
    "            end = 6\n",
    "        elif start == -2:\n",
    "            start = 1\n",
    "            end = 7\n",
    "        elif start == -1:\n",
    "            start = 2\n",
    "            end = 8\n",
    "        elif end > len(df_train_data) - 1 and not padding:\n",
    "            end = len(df_train_data)\n",
    "            start = len(df_train_data) - (2 * n_zero)\n",
    "\n",
    "        df_velocity.append([get_derivative_value(df_train_data_padding.loc[start:end, \"X\"], m),\n",
    "                             get_derivative_value(df_train_data_padding.loc[start:end, \"Y\"], m),\n",
    "                             get_derivative_value(df_train_data_padding.loc[start:end, \"Z\"], m)])\n",
    "\n",
    "    # Build the DataFrame with all the columns together so we can save it to CSV\n",
    "    df_velocity = pd.DataFrame(df_velocity, columns=['X','Y','Z'])\n",
    "\n",
    "    df_velocity.to_csv(\n",
    "        data_dir + derivative_path + measurement_id + \".csv\",\n",
    "        index=False,\n",
    "        header=[\"X_velocity\", \"Y_velocity\", \"Z_velocity\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to save one file to WAV to test with kaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_wav(measurement_id, wav_path, mask_path):\n",
    "    file_path= wav_path + measurement_id + '.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print (\"File exist : \", file_path)\n",
    "        return\n",
    "    \n",
    "    df_train_data = apply_mask(measurement_id,\n",
    "                               mask_path)\n",
    "    # Save to WAV\n",
    "    samplerate = 8000 # Hz, we need 8kHz for Kaldi to be happy \n",
    "\n",
    "    # We're only writing to WAV file the X axis which is located at [:,1:2]\n",
    "    write(wav_path +\n",
    "          measurement_id + '.wav', samplerate, df_train_data.iloc[:,1:2].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement_id  cc7b822c-e310-46f0-a8ea-98c95fdb67a1\n",
      "measurement_id  5163afe8-a6b0-4ea4-b2ba-9b4501dd5912\n",
      "measurement_id  5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\n",
      "measurement_id  0c579a72-bac5-46a2-8671-1a50620723bf\n",
      "measurement_id  19a3e9ea-fce1-40b7-9457-2618970beb7b\n",
      "measurement_id  fb188ae2-2173-4137-9236-19a137a402c2\n",
      "measurement_id  e2973da8-1250-4a7c-98d5-b165570a8aeb\n",
      "measurement_id  8548d34c-4771-4ca4-bee4-d47bde435bdc\n",
      "measurement_id  bb59d008-25fe-43cc-bf05-6bd6b874eea3\n",
      "measurement_id  4a1ca52c-2895-4094-bade-246fd474762f\n",
      "measurement_id  f53cfd9b-8c52-4d22-a35c-504542170ed3\n",
      "measurement_id  dc90dc36-b4e5-43ec-b3e8-47c39c763c71\n",
      "measurement_id  e31db4f8-f9a5-4273-a874-4bdbc6fcae2c\n",
      "measurement_id  d1a9294c-05ad-4eac-9915-7052c2ad98a3\n",
      "measurement_id  cc0d147f-94ea-4637-91d7-d4ceceaf1728\n",
      "measurement_id  20f1dbcd-0954-4bfd-ad92-9bac1b15beb0\n",
      "measurement_id  c05991ea-ed30-45ee-96a2-8a44d6ac0916\n",
      "measurement_id  3cf49c01-0499-4bad-9167-67691711204a\n",
      "measurement_id  ac449a51-1819-4944-b5c3-ef42be404541\n",
      "measurement_id  8b7abdf9-5aad-4edc-9bc4-078e29f134d6\n",
      "measurement_id  6110744d-3f5c-4f2e-9586-f2722352606f\n",
      "measurement_id  68bf2103-4211-45e9-82d7-8b4e713b2e3b\n",
      "measurement_id  e93b52ca-83af-46fb-baad-46c934ab4edf\n",
      "measurement_id  0b5f2f06-e73c-4838-9f4c-d68b909a9356\n",
      "measurement_id  278a1441-2e3a-467d-81c5-143e0298454b\n",
      "measurement_id  18cdf618-e263-4843-9640-f41ad8ff4bde\n",
      "measurement_id  610face1-43e9-4a7c-b1f2-20deba03d587\n",
      "measurement_id  f59c374f-b39d-48d6-aef9-2f42ca3a67e4\n",
      "measurement_id  66a44bdc-b216-4be1-90aa-d5d05f64ba01\n",
      "measurement_id  dde97977-d155-4f07-8a47-6a318bd530eb\n",
      "measurement_id  979c5c53-30c7-4e9c-87f0-261ea0d79ffe\n",
      "measurement_id  e630e9fd-6518-43c0-9312-3254bcf9a8a0\n",
      "measurement_id  85fee6b9-b3d9-4506-833b-ce5ca3a8d94f\n",
      "measurement_id  29103438-8d6c-41f8-a3b9-89fff8074b6a\n",
      "measurement_id  9230106e-5dcf-4034-bd54-c016f49294d8\n",
      "measurement_id  73dee9e5-9bec-4dd2-967b-e1bd59b0629d\n",
      "measurement_id  4b269cc2-8f0c-4816-adbf-10c0069b8833\n",
      "measurement_id  1a90e8a3-dd3f-440a-9161-7886737e9d87\n",
      "measurement_id  f4728921-8a52-468b-b6af-523108a1285f\n",
      "measurement_id  daf11494-e6fa-4376-a78a-86c683885764\n",
      "measurement_id  3444e818-0ee3-4a2b-953a-f4dbc43b5d13\n",
      "measurement_id  f76830fe-e0b0-463a-9162-63b00478067e\n",
      "measurement_id  5f9347a1-bf84-48ee-b3cc-c357401780cf\n",
      "measurement_id  9152519b-4b57-43be-963c-dd7218495001\n",
      "measurement_id  c7312d73-cb34-4025-b8b8-5299b4033e2f\n",
      "measurement_id  cc730391-146b-420f-9255-c3185061f178\n",
      "measurement_id  7fa0d4ab-c159-4335-ad91-6dc3ec812686\n",
      "measurement_id  50fd9915-06d1-4871-9103-ed125ea75764\n",
      "measurement_id  11dfbcf2-cd03-4b10-83b4-ad428153b200\n",
      "measurement_id  476d6522-cd73-43e9-81c6-66980c575453\n",
      "measurement_id  4e996f6e-4979-4ffb-a017-112100675eed\n",
      "measurement_id  e5f4f2d3-9842-462f-8b91-6ccaa6c30a33\n",
      "measurement_id  ef4b3a31-2744-4bec-996f-5c1861478c30\n",
      "measurement_id  631b2ad6-1b00-46f5-8d74-c0b47a2419f0\n",
      "measurement_id  1c3dda9b-984c-43b2-9686-0316e2254393\n",
      "measurement_id  ef0da5f7-79e5-45bc-bd12-d70137054762\n",
      "measurement_id  e49db734-9ccf-4581-ae15-cbda39262bbf\n",
      "measurement_id  cf15d497-b4d7-4bd4-9ba4-ae3bf0ed38b7\n",
      "measurement_id  b34c12f1-1927-4d6b-b936-d0328aed05a7\n",
      "measurement_id  12513701-85b5-4278-bd15-dafae072d599\n",
      "measurement_id  c4babc3e-cf11-42c5-93e9-7c0ccb2f2507\n",
      "measurement_id  a65ac7f5-e28d-4009-9cfb-05a06e8fa1a5\n",
      "measurement_id  1e0f16d8-3303-4c39-930b-ab3fff2c55cc\n",
      "measurement_id  0a439836-acf1-475b-a4dc-103e8fd5ecbc\n",
      "measurement_id  c5f6bee5-4f02-4761-a848-d68f513e697e\n",
      "measurement_id  6983d20c-94b3-4694-b1f1-06931c71ef1c\n",
      "measurement_id  32184eb0-2e4c-49a2-8d63-c1a67f9e17a3\n",
      "measurement_id  63a65c00-7d4d-4ee2-909c-84cd2d50d805\n",
      "measurement_id  855cdaf2-e00a-402d-b76b-0a3a4a10ff84\n",
      "measurement_id  184ffe2e-f6c6-414d-ae43-d01bcd5568d9\n",
      "measurement_id  1e051b85-eca9-4831-b1e3-444a4cb18269\n",
      "measurement_id  4d38808c-a2e2-40bf-9804-6cc0ad9b7383\n",
      "measurement_id  74e7102c-8a25-43e5-8f23-f0cfb6a9a58f\n",
      "measurement_id  49202934-d5f5-4e83-8c61-c04ed0ae4a35\n",
      "measurement_id  8340ba3e-2a36-4bcc-bf6f-bfdc852538d0\n",
      "measurement_id  7259459c-3242-474e-89ad-28c4bae46b87\n",
      "measurement_id  adaecec4-fb45-4fcb-8056-8f5ab6116c49\n",
      "measurement_id  a47b5b1d-34b1-40ae-b03e-d1c75e054d49\n",
      "measurement_id  9312d505-c3c9-4d2a-88ba-2ce1d3d451a8\n",
      "measurement_id  1d624788-41fd-4c7d-b2c3-2fed920457f6\n",
      "measurement_id  ff0e52c1-b449-4bb4-8465-e35535c1c667\n",
      "measurement_id  a373e8f0-8c0f-4660-b4ba-ea87bea012fe\n",
      "measurement_id  0dfd3d96-7b99-4522-9bf5-c39046fcf096\n",
      "measurement_id  f8946f25-022a-47ba-9868-69120c94b0f2\n",
      "measurement_id  27c0e5f5-d68f-4c42-a327-1bce67d5d394\n",
      "measurement_id  eed7c640-e9a9-4c1f-a5f2-36385c73b0ea\n",
      "measurement_id  9d41900e-9a38-4a4c-9963-8fc6a54dd24c\n",
      "measurement_id  432acdf1-9802-4508-8a33-b75cee3636e7\n",
      "measurement_id  ec3a340a-1ce0-42be-912d-6a537474facf\n",
      "measurement_id  ef25ea20-65f6-4cf6-9065-6fddcbd8c165\n",
      "measurement_id  932197a8-dca4-4a3e-8ea6-413369bbc08d\n",
      "measurement_id  5022980a-ccea-452f-887a-c67b58c82c22\n",
      "measurement_id  3f638137-e1ef-4173-8d95-f1be574cc5c4\n",
      "measurement_id  62b06ad2-44ce-4ff3-8738-0229dcfcf0f8\n",
      "measurement_id  19139e4f-0281-4b8c-8fdf-16df5d9e6e11\n",
      "measurement_id  0ca76d3f-ef24-4b60-9dc1-d6d092c65f71\n",
      "measurement_id  35a66db9-732d-426c-8ff9-0fc3e8464eef\n",
      "measurement_id  e6433883-51c5-4892-9a0f-6bb45824d03c\n",
      "measurement_id  9ddc336b-1c09-40ec-ba48-ca3872e9a8c8\n",
      "measurement_id  0d348560-5e96-4066-83f5-bf7420d01141\n",
      "measurement_id  437da5ec-c6e7-4151-91a1-29f46328b465\n",
      "measurement_id  a6d798cd-fa82-4c9b-a109-42ef181c6630\n",
      "measurement_id  00bbb4c4-bb9a-4c3a-9c1b-3bf5f079d336\n",
      "measurement_id  851c6c57-1bfc-4294-bdee-a29d8781d1cc\n",
      "measurement_id  9168bde2-364f-4805-abcf-82908a2800c6\n",
      "measurement_id  ce244565-bd09-4e45-8af2-521c8bbe27ce\n",
      "measurement_id  29457aec-ab0a-43e7-a1ea-d0ee2600b73a\n",
      "measurement_id  0514cc23-74af-4624-8f4b-33c92e98a2f6\n",
      "measurement_id  5703c24d-5adb-45ae-a01d-c7ed2efec6ba\n",
      "measurement_id  e99ca464-11dd-46ba-83db-af554d046aac\n",
      "measurement_id  5d8b5847-e01f-43c6-bdea-f164ba581a22\n",
      "measurement_id  28611db5-55a6-44c1-8a52-fe1ac200a2c0\n",
      "measurement_id  3f14f15b-52c9-4e64-8067-10ae2ef949aa\n",
      "measurement_id  eae51aee-8157-4e3e-bddf-c89562da438e\n",
      "measurement_id  2a60e30a-1b88-43ab-8a0e-7d8cbd1daf82\n",
      "measurement_id  76d625ac-2cf3-4ea6-bd80-65f2f3874355\n",
      "measurement_id  1d19c55e-d460-430d-98ee-73ad4a6d8268\n",
      "measurement_id  4a0e5d1b-9a28-4b17-8d41-37c24a0cc6ae\n",
      "measurement_id  0fb89752-d513-4500-8753-d4d2fdc29907\n",
      "measurement_id  46d9dd72-5372-44e2-929c-52d13b9874b4\n",
      "measurement_id  5f8d4735-f48b-48c4-90fe-870c17e40a8f\n",
      "measurement_id  d9d41941-df97-42db-be98-50fb4304b482\n",
      "measurement_id  5effef31-2e59-4626-a1a9-612513cfedbd\n",
      "measurement_id  9b1e4fe6-32ad-4b42-b8c0-3b368154763b\n",
      "measurement_id  79f34b92-483d-45b9-82cc-5e7db0ed68c2\n",
      "measurement_id  bea3e480-aa8d-4d0c-ab56-8620dca0415f\n",
      "measurement_id  829f4bab-393a-4614-bc6f-8205314ce09d\n",
      "measurement_id  121bc9e5-863b-4561-9aaf-18dc23bd1ff1\n",
      "measurement_id  28fbb634-2cc5-40ed-8d26-3bc1fa951f69\n",
      "measurement_id  1a39d1bd-d1d1-4133-a3d2-678212729e2f\n",
      "measurement_id  fbf4f6d0-fe7e-4629-8275-95234ead58a7\n",
      "measurement_id  a18f4894-3ba5-4606-86a9-83693e9763fd\n",
      "measurement_id  89455dd3-3345-4d6f-b0bf-fe0feeb59f9e\n",
      "measurement_id  31a6ecd7-9941-44a2-9067-4c0b67eb89b6\n",
      "measurement_id  4bc51b90-bfce-4231-85e1-5de3b4bc0745\n",
      "measurement_id  5a1ce6dd-45a1-4bae-9777-65ed867c44cd\n",
      "measurement_id  8230f859-9ac4-44f4-a2a1-6dfb05503b28\n",
      "measurement_id  8aecd65f-5fba-4374-8705-1cc2dd078182\n",
      "measurement_id  2da0ddb6-8c82-4960-9a90-a16d5fba6742\n",
      "measurement_id  e14ad8a5-6a4b-4aa7-806e-89c0761c85ae\n",
      "measurement_id  e7e0edaa-0b81-4087-8c14-eff58313218b\n",
      "measurement_id  26c87488-28d7-4f25-8a8d-a6363a09b92a\n",
      "measurement_id  41440dba-2717-4c5e-b383-463888bd4a43\n",
      "measurement_id  b33c911b-a09e-4937-8e17-fb242b0fa589\n",
      "measurement_id  5c331966-4bc0-40e9-a414-0dca02af2a50\n",
      "measurement_id  ce1b6de8-fa7f-4051-9549-391178456fd1\n",
      "measurement_id  5e5fbd98-571d-4a64-86ce-59f695d24ce3\n",
      "measurement_id  9dc1f406-5d99-492c-aba5-d5c3ed938755\n",
      "measurement_id  472201aa-effc-42a8-8f2b-11024eb5e913\n",
      "measurement_id  79aca45e-ed46-4a12-829c-f98464604fbd\n",
      "measurement_id  92a43430-c3b2-442e-8d60-688048bb2ea0\n",
      "measurement_id  996aa23a-15a7-48d9-b511-9ff5499595b7\n",
      "measurement_id  dcd5955e-3e94-40f2-818b-eda0fd33a76d\n",
      "measurement_id  6dc8e615-1807-4738-a131-e73e12fc3b42\n",
      "measurement_id  96582310-7914-4c80-9caf-557e8ecc3297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement_id  4ca00b70-b929-4a75-a990-494b915aa88b\n",
      "measurement_id  43b147ad-6eef-4d2d-83ea-bca3b1cd0a77\n",
      "measurement_id  4b08e275-50ae-4e00-90da-b64c15ccfb49\n",
      "measurement_id  b6eedea1-4bcb-4942-8a62-9026aedfa699\n",
      "measurement_id  89bc35c8-23d6-419e-a0a5-f3597e9e4931\n",
      "measurement_id  dacc9306-457f-4c0f-b901-7e38d1130ec5\n",
      "measurement_id  987115e5-f14c-4590-9ef7-b14169c25c1c\n",
      "measurement_id  623b9e4b-a86b-46df-8304-fb5000f01cd5\n",
      "measurement_id  08048b02-e033-46f4-a74f-b108d0530c2e\n",
      "measurement_id  2ece7820-359e-4e81-a624-9e8dace9a584\n",
      "measurement_id  f7b180d9-77ff-40c8-b718-28b12670c247\n",
      "measurement_id  f946ec6a-74d3-4297-a3a4-b165f2d72f13\n",
      "measurement_id  5f2d1332-846c-48f6-a6ab-188d3737dcef\n",
      "measurement_id  622a3d54-f542-4f3f-8a31-df0bbfc929ad\n",
      "measurement_id  3d0f965c-9d72-43d1-9369-1ea3acf963cc\n",
      "measurement_id  4553b646-092b-4d8b-aee4-c4a074059541\n",
      "measurement_id  a235ba27-a9a5-4d9a-931c-554950de9105\n",
      "measurement_id  b0c7435a-5963-4ad4-a5e4-b0e17d5223cf\n",
      "measurement_id  13239e7a-1c09-4bfe-a041-d739da36dff1\n",
      "measurement_id  1e5738bf-e918-4025-9d84-8df71e8d4810\n",
      "measurement_id  fb394080-2cba-454c-ad45-120fed0086e6\n",
      "measurement_id  aee216fc-15d6-42ee-8e91-c8db3b16f0f6\n",
      "measurement_id  b467614e-a297-4780-aec5-003fa5e8416f\n",
      "measurement_id  b6f6ea11-7815-4c26-b8b0-1ce444327b5a\n",
      "measurement_id  c722ebb1-d798-41ae-adeb-b4a57bd41172\n",
      "measurement_id  0159954c-1bd2-47a6-9e6f-94f8d179b712\n",
      "measurement_id  3b0ee95f-d87b-4699-b34f-74e7dc20ab01\n",
      "measurement_id  6867bf10-f489-4c7f-abd1-06a47dd2cdd9\n",
      "measurement_id  02389c9e-8821-4c54-a1a7-912f0b66dd95\n",
      "measurement_id  6fc11b99-5d79-4c68-a400-4327721b1025\n",
      "measurement_id  9ac46426-d5f0-4a5b-9c18-90fe544973d7\n",
      "measurement_id  1f260e98-4e0b-4bce-ae4b-f09129a279ef\n",
      "measurement_id  6b70e1d7-e2a1-4a29-8ba9-841f7aee3d25\n",
      "measurement_id  33ec24ca-a4d0-48a1-8f1a-282ad9b4f084\n",
      "measurement_id  95d7b4b3-5b3c-47d2-aff2-05fce6a2cc56\n",
      "measurement_id  233838f8-c430-429e-82e9-5b41a55ae86d\n",
      "measurement_id  2d852742-10a9-4c56-9f38-779f2cd66879\n",
      "measurement_id  226829d3-f889-460a-95bb-3835db5c83fa\n",
      "measurement_id  8b756127-e00b-433e-a86c-60d90c8de809\n",
      "measurement_id  16223cff-4a1b-427c-b635-4b7ff0100c8f\n",
      "measurement_id  ff5e4e8f-dace-4913-9ea9-e7f4f80a9233\n",
      "measurement_id  b0eabbe3-e7f0-4677-85f7-107ca84ab9a0\n",
      "measurement_id  178e8ab6-fa12-45d6-bc3b-f1ce7ccf6a77\n",
      "measurement_id  b1fac9c3-5f9c-4464-8ad4-152a63eb4f48\n",
      "measurement_id  5b540079-abd3-444a-ad9e-45267afa026d\n",
      "measurement_id  58e358f6-ae96-4c29-8178-e82278263af4\n",
      "measurement_id  78f9c3a3-64a3-4b8c-b8b2-1a91c84ed995\n",
      "measurement_id  9a44ee78-2408-4116-bcc8-533a0a6708e6\n",
      "measurement_id  ccf7e0e7-a3fc-48fb-88ce-529d2c882f22\n",
      "measurement_id  3ed7e465-d3fb-4673-89cb-a78f23f0b887\n",
      "measurement_id  79ca56ea-6538-4808-a163-6a1ddb562879\n",
      "measurement_id  a0b9a464-b1a9-42b9-ad60-6ba222179be3\n",
      "measurement_id  520a3d56-2689-4036-84e9-059b4ebf9a89\n",
      "measurement_id  8c39ee63-0fb7-4a56-a9a5-eda3a70069a5\n",
      "measurement_id  4dacabef-fcc4-49c9-b994-325027e5df13\n",
      "measurement_id  ff404d2a-3896-4a6a-ae75-4b9d3c86cae3\n",
      "measurement_id  b9356dbc-a3a7-4bdf-be2b-705e462f524e\n",
      "measurement_id  3839d639-5418-4696-905f-56e28bc4b523\n",
      "measurement_id  990b26e9-1836-4c1b-af94-4964ddabd418\n",
      "measurement_id  bc89cf9a-1070-46d0-a30c-e0fbf3b39345\n",
      "measurement_id  eea9aca1-77da-4990-b8fa-7065902c7f58\n",
      "measurement_id  7d759341-68cd-4e7a-a47e-32031d85081d\n",
      "measurement_id  4195f059-861b-4785-abcd-686696bb86ac\n",
      "measurement_id  9e3fa515-6478-492c-8555-96a9400945e1\n",
      "measurement_id  ca71e75c-c9aa-4d52-8570-6d9d4d405889\n",
      "measurement_id  7ae4f371-e804-4d36-9e90-b10edf30d1c8\n",
      "measurement_id  9cd72be6-3f5d-4dea-8949-e7ad74d7e8ef\n",
      "measurement_id  8ec48f56-7807-4636-b697-173e0deee6a4\n",
      "measurement_id  b7d6c320-9ba8-46c1-a85d-9750478c157d\n",
      "measurement_id  69bc1257-4d33-4b3a-8dae-475c9bf23852\n",
      "measurement_id  2cd7708b-4b7a-4b14-8417-541956167342\n",
      "measurement_id  a881b1f9-c117-4702-89e8-4581ea76f66b\n",
      "measurement_id  154f44c3-d5bb-4179-af2b-41075cc67492\n",
      "measurement_id  4e2f8120-10c0-4813-afa0-b1af71a01f11\n",
      "measurement_id  86545220-c044-4eb6-baa7-7d74152e0634\n",
      "measurement_id  2031b796-ee5e-4516-840a-b439d9d4088d\n",
      "measurement_id  9ee5a9d6-29b4-457d-96a8-2685ef263c9e\n",
      "measurement_id  66b8e105-c0d3-4cb0-a0b9-36543547c49d\n",
      "measurement_id  fafaa28b-fb4c-481b-b33d-ce7dfdd04c63\n",
      "measurement_id  a00d94a9-c6dd-4847-9d03-f5ee06cbfe8e\n",
      "measurement_id  99e984d3-c67e-4ab3-8540-ecabee635fdc\n",
      "measurement_id  c549935b-49cd-446c-93a7-794377d5c7f4\n",
      "measurement_id  27e74c69-855c-4cee-8f77-80312e2eefb9\n",
      "measurement_id  342556fc-2043-4247-b564-d6a8d1becdf6\n",
      "measurement_id  ff3602fe-711e-48e7-a4c5-d1d9432caa4c\n",
      "measurement_id  701b7765-59f1-4cd0-a7c7-3e8f3f6ddbea\n",
      "measurement_id  48a4a73e-a77c-4876-ab26-19bc6eaa1005\n",
      "measurement_id  c7b82d35-63a8-429f-a038-cc6c7b5e6f4a\n",
      "measurement_id  8739535b-de18-4189-b458-dc906ea1eac4\n",
      "measurement_id  283085d2-f25c-47c1-a568-d1d045ac9e38\n",
      "measurement_id  dd43a092-65bb-4c24-853a-9c0770da4a6c\n",
      "measurement_id  72fb058d-56ec-4b85-bcd7-4f8a0894570d\n",
      "measurement_id  7d0482b4-d768-4e37-9375-5a3a95bcd7ed\n",
      "measurement_id  8a0c1b07-9b03-4091-b484-3f47f5c644a9\n",
      "measurement_id  deaef85d-7d3b-4382-b2b2-dee755b94592\n",
      "measurement_id  8e12e211-5ec8-4ff1-bdee-10ce82afb4dd\n",
      "measurement_id  0d1076d0-6bb0-4914-a7bc-855cbd272ad3\n",
      "measurement_id  fd1c988b-3928-4b8c-8f77-40311b49643f\n",
      "measurement_id  dd2b95c0-3b9e-4644-9870-d696f24f0582\n",
      "measurement_id  97f693e8-3b15-4207-93e8-54cee43b243f\n",
      "measurement_id  2a91e324-0a19-48ad-972a-592bdb4cc50e\n",
      "measurement_id  15f8ae14-42de-4726-977c-1227bac332a9\n",
      "measurement_id  61ffc084-9e6e-49f2-b235-8c6cf1bc2bae\n",
      "measurement_id  4a557eb6-6cac-4408-93f5-f8c35a8e8cd0\n",
      "measurement_id  e774603c-5a3c-4f72-8095-4a2162da6538\n",
      "measurement_id  759df848-e067-459f-be65-61fef277d75e\n",
      "measurement_id  93c3ac1b-777f-4c64-9e2a-b2c3528e2110\n",
      "measurement_id  645eda3d-3e16-4c64-8599-327136bab767\n",
      "measurement_id  53e173dd-3ceb-40ed-bdcc-ac08a31b48ce\n",
      "measurement_id  ecbb1910-d235-4692-a389-096187cf0b5c\n",
      "measurement_id  cbeefe93-b74d-4753-bf0d-eb464ff33d63\n",
      "measurement_id  dfac884e-4363-4c16-ad1e-fcdc3faf8a3e\n",
      "measurement_id  2a72fb3e-89a1-41cc-a2bd-c8d110fd4b2d\n",
      "measurement_id  4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\n",
      "measurement_id  03fd95e1-6d36-4a1e-942b-d9adeb2750e5\n",
      "measurement_id  a8c97fec-2adb-44c6-a7c0-c3f4078d2b49\n",
      "measurement_id  55e8446f-07fe-4bc3-aa59-e736d2955dcd\n",
      "measurement_id  c97b5a40-5f28-491b-a12b-e7e30fd4cd79\n",
      "measurement_id  14aaada9-e4cb-47c1-92ef-4059f2201d6f\n",
      "measurement_id  017b6193-e0b7-4fb9-8312-97db38f8fb28\n",
      "measurement_id  d96c3ffb-5d16-482e-bd9b-91b26aa87033\n",
      "measurement_id  b8c1673b-a831-4055-9747-04128ed6aa20\n",
      "measurement_id  76df3a6c-62f3-4b04-a61e-0783aab179c6\n",
      "measurement_id  da03a34a-5e53-48d1-8d30-2e477154bc38\n",
      "measurement_id  3b8b01bf-6995-4f3b-acd6-b6f416cf1a49\n",
      "measurement_id  0d1e04c5-c663-467b-b13e-fa66ba0b123f\n",
      "measurement_id  dc5bdffc-9632-49f8-b0a4-66ade3fa2e33\n",
      "measurement_id  2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d\n",
      "measurement_id  ecdcfdb7-adb0-4cac-b790-cc692134cab0\n",
      "measurement_id  675fe53a-74be-4bf9-966f-b4aa29ca1875\n",
      "measurement_id  e75a743d-188a-42cd-a0f4-72a9bbafe73d\n",
      "measurement_id  131cb7c4-3df4-4cc8-bfcd-a93ef5a6c29b\n",
      "measurement_id  c24d5930-a277-4780-951d-5cc26ec4ce5a\n",
      "measurement_id  d9e4b47b-5eb6-4887-a39e-4d1ab8be5ff6\n",
      "measurement_id  c2e2b686-6edc-4137-a851-27f0189c6990\n",
      "measurement_id  da8bad50-109e-471e-a1d7-768b30745bd4\n",
      "measurement_id  1152d443-ea4d-467e-beca-d8a26675aaee\n",
      "measurement_id  55e5c67f-bae7-4a70-b65c-64995e1bf606\n",
      "measurement_id  94f30da8-525c-4a2a-93ba-044b0e99ff0d\n",
      "measurement_id  ee24c57c-88f7-4f96-a063-05522913449e\n",
      "measurement_id  a90bb304-e913-4134-b03b-ec753d746513\n",
      "measurement_id  1d065c00-51a4-434e-8864-17af7d6383b0\n",
      "measurement_id  2c93a5ce-8a5f-467b-9c0a-28b5c957c1c4\n",
      "measurement_id  0e1a425d-4c98-4d5c-9c7a-65af5c3c9a85\n",
      "measurement_id  ad20b937-6cbd-433b-8fc3-6a1a9ceb2372\n",
      "measurement_id  cf7858e0-1049-42ed-b0ab-4df011357a72\n",
      "measurement_id  8866665e-023c-4797-bd26-96de926de488\n",
      "measurement_id  8c22c463-ee4a-4a07-85f3-aca9ac888c7e\n",
      "measurement_id  41efbb2d-899e-41f8-8c4b-144dfab08517\n",
      "measurement_id  c1f866ae-b8d6-4f9a-abbc-07e2a264e562\n",
      "measurement_id  1cc72a5b-5cd0-482e-91ee-365c1d118790\n",
      "measurement_id  bc495ea1-cb98-463a-8c0e-0f5feccfa81a\n",
      "measurement_id  8e967260-4fa4-4406-bb28-90f41feae786\n",
      "measurement_id  5bdece70-2806-4e58-8bf6-0141c3cb71c7\n",
      "measurement_id  aa689eaf-d601-4ff3-881c-91d7c5e4d3b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement_id  19868ae3-5beb-4a86-89c5-8eff71e352fb\n",
      "measurement_id  321e0987-b8a7-4fe0-984f-638badab72dc\n",
      "measurement_id  2f39717a-554c-44dc-ae9e-ff98d77c5943\n",
      "measurement_id  a7173b98-b7e0-4756-b172-c681e7432302\n",
      "measurement_id  f8bf28f8-224b-474e-afe4-7a5392e11c87\n",
      "measurement_id  39501c5a-1ff5-499f-93df-3bd4aa1e3d98\n",
      "measurement_id  df088ad5-4ab2-43c2-b9a2-7f7c09784f8e\n",
      "measurement_id  589bea23-ae1a-4d8b-9da0-c44537850d12\n",
      "measurement_id  0e0bf9aa-a296-4456-87b3-cc67a46c752f\n",
      "measurement_id  9d7dee51-3852-49f7-8fce-198fa4200b9b\n",
      "measurement_id  7764c2f4-ae43-420e-8924-c1777281c514\n",
      "measurement_id  fc3a9f83-3022-4bad-9e86-3055fa467a1d\n",
      "measurement_id  08d3e583-587e-4616-8144-f4f847ef29b7\n",
      "measurement_id  7bb248d3-765f-4a64-bdb9-c3f1f5150bb9\n",
      "measurement_id  ee5a0967-a645-49b4-a70b-842c5985ce52\n",
      "measurement_id  9a46cc72-41b9-4549-90bb-36a79e406447\n",
      "measurement_id  3859007f-8d21-4d12-b294-9b69672cb687\n",
      "measurement_id  f5b7c267-9bcb-4575-bc93-66f74fe6bdf7\n",
      "measurement_id  35cdd5f6-afa5-4261-b9b6-0ebe5d4ac793\n",
      "measurement_id  7af335f3-dea0-4c8d-a143-04ec6da85343\n",
      "measurement_id  72c9db1e-9ea4-454e-b381-3f8c83720b7d\n",
      "measurement_id  8095fb1f-e406-4348-b405-c4479c87ad6d\n",
      "measurement_id  05a3b9dd-bbe4-4c4d-8571-1c692640aead\n",
      "measurement_id  7ec2bf09-a4a9-45e6-b2e3-296327177a7b\n",
      "measurement_id  b91a582c-d54d-4975-b2bd-15f2c194a4b8\n",
      "measurement_id  ee9656df-4384-48de-8832-9dec7a255f8d\n",
      "measurement_id  38392387-d09a-40a4-afa7-9f3654066f28\n",
      "measurement_id  2a96609a-48dc-4d3d-918b-da84d3d166ca\n",
      "measurement_id  eb63512f-b1df-4c35-bfad-417f7c230f86\n",
      "measurement_id  4679db13-6ca0-4a40-971b-06d537cb65cf\n",
      "measurement_id  6f48272b-3843-49bc-a41e-13fc6a4b2aed\n",
      "measurement_id  a62d64ec-d1da-40bf-a86f-d7cd15f1a7dd\n",
      "measurement_id  a2b0d14d-2f55-4e66-a187-37e2ef15f116\n",
      "measurement_id  b5c4f79b-409a-455d-b9ad-0999274ca110\n",
      "measurement_id  9873444a-c5be-4975-9ba6-4f0e209b82bc\n",
      "measurement_id  300ca6f5-70d1-4928-8330-a9a86c3681f5\n",
      "measurement_id  2da6f0c2-274a-4bfe-b386-5ca925000351\n",
      "measurement_id  ced67e0d-1743-406f-9f5d-10aeb9c1f1fc\n",
      "measurement_id  45419562-4d6f-44fe-ab6c-be92d90b1d4a\n",
      "measurement_id  95051425-36e8-46c6-ad8a-2e91a6c71ffd\n",
      "measurement_id  7d00f2f8-d21e-4985-b992-b3400f71b294\n",
      "measurement_id  6b2d9f57-dd46-42ba-8365-f50d5cc9db62\n",
      "measurement_id  b2ebe3ce-3d5f-45a0-80c3-4cb5d4291d5d\n",
      "measurement_id  3774a40c-4544-45f0-8878-fcf7b1c724ae\n",
      "measurement_id  8a7a1b7d-2012-4960-a8ad-4ab834bdfc16\n",
      "measurement_id  40a4dedc-1de0-4c26-bad5-f680f72de30f\n",
      "measurement_id  a565cb99-6ca2-4bd5-8b1d-546bc5a8966a\n",
      "measurement_id  82941468-9f7b-4112-8426-443ae704b1f1\n",
      "measurement_id  ce171451-559e-4924-9136-940fec31766f\n",
      "measurement_id  c78dd269-37a5-4ced-a236-90312926011a\n",
      "measurement_id  8b933d47-4eaa-40f4-9391-b182d1c07b67\n",
      "measurement_id  924a0da8-ca40-49e8-9e83-ac52f2ca2483\n",
      "measurement_id  b8607390-96d5-4bb3-ab4a-60dc48382690\n",
      "measurement_id  fbf5934c-abc3-46f0-b3f1-04252957f839\n",
      "measurement_id  136aa28b-6b4c-416a-bd7d-a2ba6102c301\n",
      "measurement_id  5e710876-203b-4ea4-8f56-591ec1efbeab\n",
      "measurement_id  38bfb614-a05c-439c-a811-7d1a96b80067\n",
      "measurement_id  4412adc6-00f7-41dd-9470-d53d56f8d504\n",
      "measurement_id  4343b50e-e012-4357-a8da-7e5638a530f7\n",
      "measurement_id  2c15c8fc-a405-41ae-9494-347513a0140c\n",
      "measurement_id  34339f9e-4ca1-4255-a60f-d34fcd4f184a\n",
      "measurement_id  6c903c0b-9c1c-4b78-ba12-e2099a5d1659\n",
      "measurement_id  d832378a-b302-4d2a-b84f-60692767d784\n",
      "measurement_id  c55f27cc-88c8-46e5-90ce-0868e9fb78a2\n",
      "measurement_id  4ccb64c4-012e-4974-b3ff-44ca99f7e304\n",
      "measurement_id  c01292a8-cb3c-4f43-9f22-da6272deb3db\n",
      "measurement_id  91013366-f703-49cb-9842-fecc311eabdb\n",
      "measurement_id  5fb42d13-698b-4c7d-adf6-6a73007ae012\n",
      "measurement_id  6e21c03f-50b5-419f-9da1-08ce3b9efd4f\n",
      "measurement_id  c5f522ab-3af5-4767-bcda-1022820897ec\n",
      "measurement_id  18a5ec87-02d2-408e-a955-481939c5eea2\n",
      "measurement_id  24ab1574-6c4b-4e75-8267-7f54aa7e8f20\n",
      "measurement_id  3fda084d-03b7-4baf-81fc-87a82641e186\n",
      "measurement_id  951c1c6a-de66-4b4a-8fb5-f31015fdc35d\n",
      "measurement_id  9b896497-7b52-4c90-98bc-53bf82b86331\n",
      "measurement_id  13e18906-795e-4e1b-bac6-9838d8426ae4\n",
      "measurement_id  95c8461a-432f-45bb-a549-9243b4dc07f3\n",
      "measurement_id  7af6a1f0-906b-4bfe-ade1-ed05cdd10824\n",
      "measurement_id  ffd64945-4be2-47d1-a706-bf3e03cbf3b3\n",
      "measurement_id  c20f96b0-fdbb-40e9-8fcc-58a8a88a45c2\n",
      "measurement_id  12ea1758-8b6e-4867-8d00-b6ebe0c7a626\n",
      "measurement_id  2ff97448-e9e1-4530-a660-cf1b3f31c1ae\n",
      "measurement_id  cc7b73aa-90b0-4ec3-8c7b-2f7e54f7806e\n",
      "measurement_id  f311613f-abd2-4f2c-9e90-be103a5c7e4d\n",
      "measurement_id  982ddbcc-fbe4-430d-af2e-c5b1b8074d39\n",
      "measurement_id  ab5287f4-8261-47ad-8ff2-22b5fe5d246e\n",
      "measurement_id  b7e1d247-d033-407d-82cc-9c36e81b949b\n",
      "measurement_id  5131b2bd-e44c-4190-90aa-f3a9b9efa6fa\n",
      "measurement_id  02b6250d-b2f6-4ea3-8e40-a37c7076b13b\n",
      "measurement_id  1eca09bf-427d-4b1e-985f-952cf94b7628\n",
      "measurement_id  14d55233-667b-4a9c-b12f-1ae4f72b0268\n",
      "measurement_id  2905dc20-04f0-4293-b9af-a4a7f564b5dc\n",
      "measurement_id  4731d55d-9e68-472b-a415-a7a9de6776fa\n",
      "measurement_id  dd0f4d3e-8f39-4c27-a875-8c35f5206e5c\n",
      "measurement_id  f03348c5-b599-4e99-9d8c-fff7da880d5c\n",
      "measurement_id  104bbb2e-4f10-4b0c-a0d4-e60839487c68\n",
      "measurement_id  e3a99230-2187-4469-947b-448f3f51aaa0\n",
      "measurement_id  82c3da1b-e33b-4755-a707-60cf5e4c6416\n",
      "measurement_id  bacea5ad-87cd-41ab-8b94-7b36ba6c523d\n",
      "measurement_id  852ea89b-e058-4b64-8283-92d9f3eb2eca\n",
      "measurement_id  e1da348a-eb67-4a37-bfb7-1deb3ca5a741\n",
      "measurement_id  284fef0c-4921-41c4-a094-97ed884b28f4\n",
      "measurement_id  d4e5bda7-fbb9-417f-a2ca-844432f22855\n",
      "measurement_id  ae8d93f3-8539-45dd-93b0-49d1ff9c637d\n",
      "measurement_id  0e8897fe-15be-4171-b5c0-43930ff77b75\n",
      "measurement_id  814785f0-4b6c-4e46-bcf3-f1f1c46ddbbb\n",
      "measurement_id  e6c53864-8117-4182-b80f-df0a57eacd51\n",
      "measurement_id  26fd6b7c-65bd-44d0-8854-e154243f906a\n",
      "measurement_id  13bdf856-0f08-4920-936d-fd6ec54ad9ff\n",
      "measurement_id  09557102-1f36-43b2-9c6a-9d38f6cc927c\n",
      "measurement_id  3a39533e-8760-4ab9-906f-88df14e1c214\n",
      "measurement_id  1d3701c1-4b23-4dfa-81d4-f6ca98692333\n",
      "measurement_id  74cae0f7-8d66-429b-9aa7-10484355de97\n",
      "measurement_id  ce0fd58a-e635-4e4d-af48-a46dc886a687\n",
      "measurement_id  5d182120-edfd-42cb-9492-4005f44ab2b3\n",
      "measurement_id  708f35f0-4072-4f1f-a87c-cc294af34ece\n",
      "measurement_id  8f0510f4-f985-487f-85a1-76dce2989172\n",
      "measurement_id  fec2c7d2-c800-47cf-bbe0-de2352330075\n",
      "measurement_id  2fed1b68-5b37-45e1-9113-98318f8b4802\n",
      "measurement_id  706274aa-92dc-4d43-8d6c-f8301091a8c2\n",
      "measurement_id  697e3e73-7006-46b4-8894-122d75f83b12\n",
      "measurement_id  b8aa4e03-51df-4e0a-81cd-527f6d82dad3\n",
      "measurement_id  aefde7e7-18f4-46a3-81d9-cfdb4137594b\n",
      "measurement_id  ce6a3646-ea4f-48c4-86b2-e9cddc2ae0b1\n",
      "measurement_id  b79aa59c-fa50-41a8-ae80-997db4e67eef\n",
      "measurement_id  f663bf31-97e8-4bdf-a297-5feb074039f9\n",
      "measurement_id  e3f274c8-7813-4b4c-bc7f-92d703fa9153\n",
      "measurement_id  13161f03-7f8b-4365-9f5d-14add153e61c\n",
      "measurement_id  5e0e213f-2533-4929-b6b3-4af04489180c\n",
      "measurement_id  211a99c1-bd08-4c97-9b95-2d8dc4da1fc4\n",
      "measurement_id  9476fb16-7028-4e77-9dff-acbaf8d742ad\n",
      "measurement_id  0fe9fcf9-ef86-4c44-9f37-bef00828d3de\n",
      "measurement_id  33928414-f322-43ca-b2b1-9152c2c72906\n",
      "measurement_id  445c13a7-54aa-41ca-825b-ecc13512445f\n",
      "measurement_id  ff2dd563-e9aa-4e67-a663-01497751973c\n",
      "measurement_id  0345af44-acb5-4338-86b3-20e51ac98258\n"
     ]
    }
   ],
   "source": [
    "data_type = \"cis\"\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "do_work = partial(\n",
    "    write_wav, \n",
    "    wav_path=data_dir+'cis-pd.training_data.wav/',\n",
    "    mask_path=data_dir+'cis-pd.training_data.high_pass_mask/'\n",
    ")\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to print accelerometers before/after and write a wav file for 1 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement_id  cc7b822c-e310-46f0-a8ea-98c95fdb67a1\n",
      "measurement_id  5163afe8-a6b0-4ea4-b2ba-9b4501dd5912\n",
      "measurement_id  5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\n",
      "measurement_id  fb188ae2-2173-4137-9236-19a137a402c2\n",
      "measurement_id  19a3e9ea-fce1-40b7-9457-2618970beb7b\n",
      "measurement_id  e2973da8-1250-4a7c-98d5-b165570a8aeb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c5cd833c7fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_train_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     df_train_data = apply_mask(df_train_label[\"measurement_id\"][idx],\n\u001b[0;32m---> 29\u001b[0;31m                                mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#     print('len : ', len(df_train_data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#     great_title = get_plot_title(idx, df_train_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e737adb1d6e5>\u001b[0m in \u001b[0;36mapply_mask\u001b[0;34m(measurement_id, mask_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Drop the 0 values from the training DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdf_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdf_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_train_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2106\u001b[0m             \u001b[0;31m# straight boolean comparisons we want to allow all columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m             \u001b[0;31m# (regardless of dtype to pass thru) See #4537 for discussion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_const\u001b[0;34m(self, other, func)\u001b[0m\n\u001b[1;32m   5118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5119\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mdispatch_to_series\u001b[0;34m(left, right, func, str_rep, axis)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mcolumn_op\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             return {i: func(a.iloc[:, i], b)\n\u001b[0;32m-> 1128\u001b[0;31m                     for i in range(len(a.columns))}\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             return {i: func(a.iloc[:, i], b)\n\u001b[0;32m-> 1128\u001b[0;31m                     for i in range(len(a.columns))}\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetimelike_v_numeric\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0mis_datetimelike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     return ((is_datetimelike(a) and is_numeric(b)) or\n\u001b[0;32m-> 1375\u001b[0;31m             (is_datetimelike(b) and is_numeric(a)))\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mneeds_i8_conversion\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     return (is_datetime_or_timedelta_dtype(arr_or_dtype) or\n\u001b[0;32m-> 1468\u001b[0;31m             \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m             is_period_dtype(arr_or_dtype))\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64tz_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \"\"\"\n\u001b[1;32m    436\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDatetimeTZDtype\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_type = \"cis\"\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "list_measurement_id = ['db2e053a-0fb8-4206-891a-6f079fb14e3a']\n",
    "\n",
    "\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(data_type=data_type, path_accelerometer_plots=path_save_accelerometer_plots)\n",
    "\n",
    "remove_inactivity_highpass(\n",
    "    df_train_label,\n",
    "    energy_threshold=10,\n",
    "    duration_threshold=3000,\n",
    "    plot_frequency_response=True,\n",
    "    plot_accelerometer_after_removal=True,\n",
    "    mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "\n",
    "\n",
    "# Apply filter \n",
    "for idx in df_train_label.index:\n",
    "    df_train_data = apply_mask(df_train_label[\"measurement_id\"][idx],\n",
    "                               mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "    print('len : ', len(df_train_data))\n",
    "    great_title = get_plot_title(idx, df_train_label)\n",
    "    \n",
    "    print('AFTER REMOVAL')\n",
    "    Plot accelerometer \n",
    "    print('len : ', len(df_train_data))\n",
    "    x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "    df_train_data.plot(\n",
    "                    x=x_axis_data_type, legend=True, subplots=True, title=great_title\n",
    "                )\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exist :  0\n",
      "File exist :  1\n",
      "File exist :  2\n",
      "File exist :  3\n",
      "File exist :  4\n",
      "File exist :  5\n",
      "File exist :  6\n",
      "File exist :  7\n",
      "File exist :  8\n",
      "File exist :  9\n",
      "File exist :  10\n",
      "File exist :  11\n",
      "File exist :  12\n",
      "File exist :  13\n",
      "File exist :  14\n",
      "File exist :  15\n",
      "File exist :  16\n",
      "File exist :  17\n",
      "File exist :  18\n",
      "File exist :  19\n",
      "File exist :  20\n",
      "File exist :  21\n",
      "File exist :  22\n",
      "File exist :  23\n",
      "File exist :  24\n",
      "File exist :  25\n",
      "File exist :  26\n",
      "File exist :  27\n",
      "File exist :  28\n",
      "File exist :  29\n",
      "File exist :  30\n",
      "File exist :  31\n",
      "File exist :  32\n",
      "File exist :  33\n",
      "File exist :  34\n",
      "File exist :  35\n",
      "File exist :  36\n",
      "File exist :  37\n",
      "File exist :  38\n",
      "File exist :  39\n",
      "File exist :  40\n",
      "File exist :  41\n",
      "File exist :  42\n",
      "File exist :  43\n",
      "File exist :  44\n",
      "File exist :  45\n",
      "File exist :  46\n",
      "File exist :  47\n",
      "File exist :  48\n",
      "File exist :  49\n",
      "File exist :  50\n",
      "File exist :  51\n",
      "File exist :  52\n",
      "File exist :  53\n",
      "File exist :  54\n",
      "File exist :  55\n",
      "File exist :  56\n",
      "File exist :  57\n",
      "File exist :  58\n",
      "File exist :  59\n",
      "File exist :  60\n",
      "File exist :  61\n",
      "File exist :  62\n",
      "File exist :  63\n",
      "File exist :  64\n",
      "File exist :  65\n",
      "File exist :  66\n",
      "File exist :  67\n",
      "File exist :  68\n",
      "File exist :  69\n",
      "File exist :  70\n",
      "File exist :  71\n",
      "File exist :  72\n",
      "File exist :  73\n",
      "File exist :  74\n",
      "File exist :  75\n",
      "File exist :  76\n",
      "File exist :  77\n",
      "File exist :  78\n",
      "File exist :  79\n",
      "File exist :  80\n",
      "File exist :  81\n",
      "File exist :  82\n",
      "File exist :  83\n",
      "File exist :  84\n",
      "File exist :  85\n",
      "File exist :  86\n",
      "File exist :  87\n",
      "File exist :  88\n",
      "File exist :  89\n",
      "File exist :  90\n",
      "File exist :  91\n",
      "File exist :  92\n",
      "File exist :  93\n",
      "File exist :  94\n",
      "File exist :  95\n",
      "File exist :  96\n",
      "File exist :  97\n",
      "File exist :  98\n",
      "File exist :  99\n",
      "File exist :  100\n",
      "File exist :  101\n",
      "File exist :  102\n",
      "File exist :  103\n",
      "File exist :  104\n",
      "File exist :  105\n",
      "File exist :  106\n",
      "File exist :  107\n",
      "File exist :  108\n",
      "File exist :  109\n",
      "File exist :  110\n",
      "File exist :  111\n",
      "File exist :  112\n",
      "File exist :  113\n",
      "File exist :  114\n",
      "File exist :  115\n",
      "File exist :  116\n",
      "File exist :  117\n",
      "File exist :  118\n",
      "File exist :  119\n",
      "File exist :  120\n",
      "File exist :  121\n",
      "File exist :  122\n",
      "File exist :  123\n",
      "File exist :  124\n",
      "File exist :  125\n",
      "File exist :  126\n",
      "File exist :  127\n",
      "File exist :  128\n",
      "File exist :  129\n",
      "File exist :  130\n",
      "File exist :  131\n",
      "File exist :  132\n",
      "File exist :  133\n",
      "File exist :  134\n",
      "File exist :  135\n",
      "File exist :  136\n",
      "File exist :  137\n",
      "File exist :  138\n",
      "File exist :  139\n",
      "File exist :  140\n",
      "File exist :  141\n",
      "File exist :  142\n",
      "File exist :  143\n",
      "File exist :  144\n",
      "File exist :  145\n",
      "File exist :  146\n",
      "File exist :  147\n",
      "File exist :  148\n",
      "File exist :  149\n",
      "File exist :  150\n",
      "File exist :  151\n",
      "File exist :  152\n",
      "File exist :  153\n",
      "File exist :  154\n",
      "File exist :  155\n",
      "File exist :  156\n",
      "File exist :  157\n",
      "File exist :  158\n",
      "File exist :  159\n",
      "File exist :  160\n",
      "File exist :  161\n",
      "File exist :  162\n",
      "File exist :  163\n",
      "File exist :  164\n",
      "File exist :  165\n",
      "File exist :  166\n",
      "File exist :  167\n",
      "File exist :  168\n",
      "File exist :  169\n",
      "File exist :  170\n",
      "File exist :  171\n",
      "File exist :  172\n",
      "File exist :  173\n",
      "File exist :  174\n",
      "File exist :  175\n",
      "File exist :  176\n",
      "File exist :  177\n",
      "File exist :  178\n",
      "File exist :  179\n",
      "File exist :  180\n",
      "File exist :  181\n",
      "File exist :  182\n",
      "File exist :  183\n",
      "File exist :  184\n",
      "File exist :  185\n",
      "File exist :  186\n",
      "File exist :  187\n",
      "File exist :  188\n",
      "File exist :  189\n",
      "File exist :  190\n",
      "File exist :  191\n",
      "File exist :  192\n",
      "File exist :  193\n",
      "File exist :  194\n",
      "File exist :  195\n",
      "File exist :  196\n",
      "File exist :  197\n",
      "File exist :  198\n",
      "File exist :  199\n",
      "File exist :  200\n",
      "File exist :  201\n",
      "File exist :  202\n",
      "File exist :  203\n",
      "File exist :  204\n",
      "File exist :  205\n",
      "File exist :  206\n",
      "File exist :  207\n",
      "File exist :  208\n",
      "File exist :  209\n",
      "File exist :  210\n",
      "File exist :  211\n",
      "File exist :  212\n",
      "File exist :  213\n",
      "File exist :  214\n",
      "File exist :  215\n",
      "File exist :  216\n",
      "File exist :  217\n",
      "File exist :  218\n",
      "File exist :  219\n",
      "File exist :  220\n",
      "File exist :  221\n",
      "File exist :  222\n",
      "File exist :  223\n",
      "File exist :  224\n",
      "File exist :  225\n",
      "File exist :  226\n",
      "File exist :  227\n",
      "File exist :  228\n",
      "File exist :  229\n",
      "File exist :  230\n",
      "File exist :  231\n",
      "File exist :  232\n",
      "File exist :  233\n",
      "File exist :  234\n",
      "File exist :  235\n",
      "File exist :  236\n",
      "File exist :  237\n",
      "File exist :  238\n",
      "File exist :  239\n",
      "File exist :  240\n",
      "File exist :  241\n",
      "File exist :  242\n",
      "File exist :  243\n",
      "File exist :  244\n",
      "File exist :  245\n",
      "File exist :  246\n",
      "File exist :  247\n",
      "File exist :  248\n",
      "File exist :  249\n",
      "File exist :  250\n",
      "File exist :  251\n",
      "File exist :  252\n",
      "File exist :  253\n",
      "File exist :  254\n",
      "File exist :  255\n",
      "File exist :  256\n",
      "File exist :  257\n",
      "File exist :  258\n",
      "File exist :  259\n",
      "File exist :  260\n",
      "File exist :  261\n",
      "File exist :  262\n",
      "File exist :  263\n",
      "File exist :  264\n",
      "File exist :  265\n",
      "File exist :  266\n",
      "File exist :  267\n",
      "File exist :  268\n",
      "File exist :  269\n",
      "File exist :  270\n",
      "File exist :  271\n",
      "File exist :  272\n",
      "File exist :  273\n",
      "File exist :  274\n",
      "File exist :  275\n",
      "File exist :  276\n",
      "File exist :  277\n",
      "File exist :  278\n",
      "File exist :  279\n",
      "File exist :  280\n",
      "File exist :  281\n",
      "File exist :  282\n",
      "File exist :  283\n",
      "File exist :  284\n",
      "File exist :  285\n",
      "File exist :  286\n",
      "File exist :  287\n",
      "File exist :  288\n",
      "File exist :  289\n",
      "File exist :  290\n",
      "File exist :  291\n",
      "File exist :  292\n",
      "File exist :  293\n",
      "File exist :  294\n",
      "File exist :  295\n",
      "File exist :  296\n",
      "File exist :  297\n",
      "File exist :  298\n",
      "File exist :  299\n",
      "File exist :  300\n",
      "File exist :  301\n",
      "File exist :  302\n",
      "File exist :  303\n",
      "File exist :  304\n",
      "File exist :  305\n",
      "File exist :  306\n",
      "File exist :  307\n",
      "File exist :  308\n",
      "File exist :  309\n",
      "File exist :  310\n",
      "File exist :  311\n",
      "File exist :  312\n",
      "File exist :  313\n",
      "File exist :  314\n",
      "File exist :  315\n",
      "File exist :  316\n",
      "File exist :  317\n",
      "File exist :  318\n",
      "File exist :  319\n",
      "File exist :  320\n",
      "File exist :  321\n",
      "File exist :  322\n",
      "File exist :  323\n",
      "File exist :  324\n",
      "File exist :  325\n",
      "File exist :  326\n",
      "File exist :  327\n",
      "File exist :  328\n",
      "File exist :  329\n",
      "File exist :  330\n",
      "File exist :  331\n",
      "File exist :  332\n",
      "File exist :  333\n",
      "File exist :  334\n",
      "File exist :  335\n",
      "File exist :  336\n",
      "File exist :  337\n",
      "File exist :  338\n",
      "File exist :  339\n",
      "File exist :  340\n",
      "File exist :  341\n",
      "File exist :  342\n",
      "File exist :  343\n",
      "File exist :  344\n",
      "File exist :  345\n",
      "File exist :  346\n",
      "File exist :  347\n",
      "File exist :  348\n",
      "File exist :  349\n",
      "File exist :  350\n",
      "File exist :  351\n",
      "File exist :  352\n",
      "File exist :  353\n",
      "File exist :  354\n",
      "File exist :  355\n",
      "File exist :  356\n",
      "File exist :  357\n",
      "File exist :  358\n",
      "File exist :  359\n",
      "File exist :  360\n",
      "File exist :  361\n",
      "File exist :  362\n",
      "File exist :  363\n",
      "File exist :  364\n",
      "File exist :  365\n",
      "File exist :  366\n",
      "File exist :  367\n",
      "File exist :  368\n",
      "File exist :  369\n",
      "File exist :  370\n",
      "File exist :  371\n",
      "File exist :  372\n",
      "File exist :  373\n",
      "File exist :  374\n",
      "File exist :  375\n",
      "File exist :  376\n",
      "File exist :  377\n",
      "File exist :  378\n",
      "File exist :  379\n",
      "File exist :  380\n",
      "File exist :  381\n",
      "File exist :  382\n",
      "File exist :  383\n",
      "File exist :  384\n",
      "File exist :  385\n",
      "File exist :  386\n",
      "File exist :  387\n",
      "File exist :  388\n",
      "File exist :  389\n",
      "File exist :  390\n",
      "measurement_id  2ff97448-e9e1-4530-a660-cf1b3f31c1ae\n",
      "measurement_id  cc7b73aa-90b0-4ec3-8c7b-2f7e54f7806e\n"
     ]
    }
   ],
   "source": [
    "data_type = \"cis\"\n",
    "\n",
    "# TODO: explain\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "#list_measurement_id=['2d852742-10a9-4c56-9f38-779f2cd66879']\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "#df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "do_work = partial(\n",
    "    get_first_derivative, \n",
    "    derivative_path=\"cis-pd.training_data.velocity_original_data/\",\n",
    "    padding=True, \n",
    "    mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/'\n",
    ")\n",
    "\n",
    "num_jobs = 8\n",
    "with ProcessPoolExecutor(num_jobs) as ex:\n",
    "    results = list(ex.map(do_work, df_train_label['measurement_id']))\n",
    "\n",
    "# TODO Get first derivative of the data with high pass\n",
    "#get_first_derivative(df_train_label, \n",
    "#                     #\"cis-pd.training_data.velocity_original_data_test/\", \n",
    "#                     \"velocity_original_data_test/\",\n",
    "#                     padding=True, \n",
    "#                     mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "\n",
    "# n zero vector / k\n",
    "# k = convolution of the whole signal with v\n",
    "# dont have to separate the signal in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS-PD Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains 16 subject_id (patients) for the training set \n",
    "\n",
    "- Gender: 11 Male, 5 Female \n",
    "- Race: 15 White, 1 NA\n",
    "- Ethnicity: 15 Not Hispanic or Latino, 1 Unknown\n",
    "- Age average (standard deviation) : 62.8125 (10.8579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "\n",
    "# TODO: explain\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "# display(df_train_label)\n",
    "# List of interesting measurement id we want to look at\n",
    "# list_measurement_id=[#'ab5287f4-8261-47ad-8ff2-22b5fe5d246e',\n",
    "#'db2e053a-0fb8-4206-891a-6f079fb14e3a']#,\n",
    "# 'ef5b1267-c212-46c5-aab0-4f4437bc6c67',\n",
    "# '4ec74fb9-7347-435d-83dc-79ad74c3bc49',\n",
    "# '8e8539ad-8841-476b-b15c-888ce3461989',\n",
    "# '22b88456-fe8f-4138-af55-be12afca4b81',\n",
    "# 'ad84583d-e5ae-4926-b077-531a0f7d08a9',\n",
    "# 'eef56825-940a-4c3e-aebb-60838d60869e',\n",
    "# 'e0441156-c4b8-467c-8f4f-3b532d594d8f',\n",
    "# '464ac314-6c4b-4c4a-957c-28a2339150d6']\n",
    "\n",
    "list_measurement_id = [\n",
    "    \"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\",\n",
    "    \"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\",\n",
    "    \"5163afe8-a6b0-4ea4-b2ba-9b4501dd5912\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d\",  # no inactivity should be removed\n",
    "    \"3cf49c01-0499-4bad-9167-67691711204a\",  # no inactivity should be removed PAS LA??\n",
    "    \"3d0f965c-9d72-43d1-9369-1ea3acf963cc\",  # PAS LA ???\n",
    "    \"4b269cc2-8f0c-4816-adbf-10c0069b8833\",\n",
    "    \"4bc51b90-bfce-4231-85e1-5de3b4bc0745\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "]  # bit of inactivity in the middle]\n",
    "\n",
    "list_measurement_id = [\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(\n",
    "    df_train_label=df_train_label, list_measurement_id=list_measurement_id\n",
    ")\n",
    "\n",
    "# Display filtered df_train_label\n",
    "display(df_train_label)\n",
    "\n",
    "# path_no_inactivity_data = remove_inactivity_pct_change(df_train_label)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(\n",
    "    data_type=data_type, path_accelerometer_plots=path_save_accelerometer_plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  cc7b822c-e310-46f0-a8ea-98c95fdb67a1\n",
      "X_zeros.shape  (44940,)\n",
      "X_zeros.shape 2  (44940,)\n",
      "df_zeros.shape  (44940,)\n",
      "df_zeros.shape 2 (44940,)\n",
      "df_mask_highpass.shape  (44940, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-19372e25f5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mduration_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplot_frequency_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# remove_inactivity_mean_offset(df_train_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-0c0b02c531ed>\u001b[0m in \u001b[0;36mremove_inactivity_highpass\u001b[0;34m(df_train_label, energy_threshold, duration_threshold, mask_path, plot_frequency_response, plot_accelerometer_after_removal)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;31m#         )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_mask_highpass.shape '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_mask_highpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Plot the accelerometer with the removed sections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# The [0] is used to get a pandas.Series instead of a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "data_type = \"cis\"\n",
    "\n",
    "# TODO: explain\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "# list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "# list_measurement_id = [\"2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d\"]\n",
    "\n",
    "# list_measurement_id = [\n",
    "#     \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "#     \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "#     \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "# ]\n",
    "\n",
    "# list_measurement_id = [\"db2e053a-0fb8-4206-891a-6f079fb14e3a\"]\n",
    "\n",
    "# list_measurement_id=['2d852742-10a9-4c56-9f38-779f2cd66879']\n",
    "# list_measurement_id=['5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a',\n",
    "#                      'cc7b822c-e310-46f0-a8ea-98c95fdb67a1',\n",
    "#                      '5163afe8-a6b0-4ea4-b2ba-9b4501dd5912',\n",
    "#                     'db2e053a-0fb8-4206-891a-6f079fb14e3a',\n",
    "#                     '2d852742-10a9-4c56-9f38-779f2cd66879',\n",
    "#                     '2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d', # no inactivty should be removed\n",
    "#                     '3cf49c01-0499-4bad-9167-67691711204a']\n",
    "\n",
    "# df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "\n",
    "remove_inactivity_highpass(\n",
    "    df_train_label,\n",
    "    energy_threshold=5,\n",
    "    duration_threshold=3000,\n",
    "    plot_frequency_response=False,\n",
    "    mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "\n",
    "# remove_inactivity_mean_offset(df_train_label)\n",
    "# path_no_inactivity_data = remove_inactivity_max(df_train_label)\n",
    "\n",
    "# plot_accelerometer(data_type=data_type, path_accelerometer_plots=path_save_accelerometer_plots, path_inactivity=path_no_inactivity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "\n",
    "# TODO: explain\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "# list_measurement_id=['5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a',\n",
    "#                      'cc7b822c-e310-46f0-a8ea-98c95fdb67a1',\n",
    "#                      '5163afe8-a6b0-4ea4-b2ba-9b4501dd5912',\n",
    "#                     'db2e053a-0fb8-4206-891a-6f079fb14e3a',\n",
    "#                     '2d852742-10a9-4c56-9f38-779f2cd66879',\n",
    "#                     '2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d', # no inactivity should be removed\n",
    "#                     '3cf49c01-0499-4bad-9167-67691711204a',# no inactivty should be removed\n",
    "#                     '3d0f965c-9d72-43d1-9369-1ea3acf963cc',\n",
    "#                     '4b269cc2-8f0c-4816-adbf-10c0069b8833',\n",
    "#                     '4bc51b90-bfce-4231-85e1-5de3b4bc0745',\n",
    "#                     '4fc3c295-857f-4920-8fa5-f21bfdc7ab4f'] #bit of inactivity in the middle]\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "df_train_label = interesting_patients(\n",
    "    df_train_label=df_train_label, list_measurement_id=list_measurement_id\n",
    ")\n",
    "\n",
    "path_no_inactivity_data = remove_inactivity_pct_change(df_train_label)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "# plot_accelerometer(data_type=data_type, path_accelerometer_plots=path_save_accelerometer_plots, path_inactivity=path_no_inactivity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Occurences of each symptoms for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the occurences of each symptoms for each patient\n",
    "df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "    df_train_label=df_train_label\n",
    ")\n",
    "\n",
    "# Plot the graphs\n",
    "plot_symptoms_occurences(\n",
    "    df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold(df_train_label, n_splits=5, subject_id=None, data_real_subtype=\"\"):\n",
    "    \"\"\"\n",
    "    Function that returns a list of X dataframes (X is according to the number of n_splits chosen)\n",
    "\n",
    "    The dataframes are the labels needed according to the split \n",
    "\n",
    "    Keyword Arguments:\n",
    "    df_train_label: Dataframe containing the labels\n",
    "    n_split: Optional. The number of folds. Default: 5\n",
    "    subject_id: Optional. Specify a subject_id to get measurement_id only for that subject_id \n",
    "    data_real_subtype: Only for REAL-PD database\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits)\n",
    "\n",
    "    # Building the dataframe to split\n",
    "    X = []\n",
    "\n",
    "    # if we want the data split for one specific subject_id\n",
    "    if subject_id:\n",
    "        df_train_label_subject_id = df_train_label.groupby(\"subject_id\")\n",
    "        X = df_train_label_subject_id.get_group(subject_id)\n",
    "\n",
    "    # if we want to have all a split for all data no matter the subject_id\n",
    "    # NOTE: I didn't make sure to have one subject_id represented in both train/test\n",
    "    else:\n",
    "        for idx in df_train_label.index:\n",
    "            X.append([df_train_label[\"measurement_id\"][idx]])\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    # Building lists of df_train_label because we have by default 5 splits,\n",
    "    # so the lists will contain 5 DataFrames with different split indices required\n",
    "    list_df_train_label = list()\n",
    "    list_df_test_label = list()\n",
    "    split_idx = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        df_train_label = X.iloc[train_index]\n",
    "        df_test_label = X.iloc[test_index]\n",
    "\n",
    "        list_df_train_label.append(df_train_label)\n",
    "        list_df_test_label.append(df_test_label)\n",
    "\n",
    "        # name of the file according to its database and type\n",
    "        path_save_k_fold_dataframes = (\n",
    "            data_dir + data_type + \"-pd.training_data.k_fold/\" + data_real_subtype + \"/\"\n",
    "        )\n",
    "        df_train_label.to_csv(\n",
    "            path_save_k_fold_dataframes\n",
    "            + str(subject_id)\n",
    "            + \"_train_kfold_\"\n",
    "            + str(split_idx)\n",
    "            + \".csv\",\n",
    "            index=False,\n",
    "            header=[\"measurement_id\", \"subject_id\", \"on_off\", \"dyskinesia\", \"tremor\"],\n",
    "        )\n",
    "        df_test_label.to_csv(\n",
    "            path_save_k_fold_dataframes\n",
    "            + str(subject_id)\n",
    "            + \"_test_kfold_\"\n",
    "            + str(split_idx)\n",
    "            + \".csv\",\n",
    "            index=False,\n",
    "            header=[\"measurement_id\", \"subject_id\", \"on_off\", \"dyskinesia\", \"tremor\"],\n",
    "        )\n",
    "        split_idx = split_idx + 1\n",
    "    return list_df_train_label, list_df_test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the K-Fold files for the CIS database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the data type as we have two databases\n",
    "data_type = \"cis\"\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "display(df_train_label)\n",
    "\n",
    "# Group data by subject_id\n",
    "df_train_label_subject_id = df_train_label.groupby(\"subject_id\")\n",
    "\n",
    "# Go through the subject_id and k-fold their data\n",
    "# FIXME: get_k_fold could me renamed to just create the folds, save them, not return anything\n",
    "for subject_id, value in df_train_label_subject_id:\n",
    "    list_df_train_label, list_df_test_label = get_k_fold(\n",
    "        df_train_label=df_train_label, n_splits=5, subject_id=subject_id\n",
    "    )\n",
    "\n",
    "\n",
    "#### Example on how to read data\n",
    "\n",
    "# TODO\n",
    "# Read data from folders\n",
    "\n",
    "# The following is not a really good example, it would be better to have an example where we read the\n",
    "# data from the folder they're saved at\n",
    "\n",
    "\n",
    "# Iterate through the DataFrame in the list list_df_train_label_train\n",
    "# for df_train_label in list_df_train_label_train:\n",
    "#     # Go through the measurement_id for this df_train_label split to read the training data corresponding\n",
    "#     for idx in df_train_label.index:\n",
    "#         # Read the train data for this specific measurement_id\n",
    "#         # TODO: Do we want to append all of this training data together?\n",
    "#         df_train_data=pd.read_csv(path_train_data+df_train_label[\"measurement_id\"][idx]+'.csv')\n",
    "#         #display(df_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the K-Fold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the K-Fold Files for the REAL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate the files, you have to uncomment one data_real_subtype at a time and\n",
    "# execute this cell 3 times for the 3 subtypes.\n",
    "\n",
    "data_type = \"real\"\n",
    "# data_real_subtype='smartphone_accelerometer'\n",
    "data_real_subtype = \"smartwatch_accelerometer\"\n",
    "# data_real_subtype='smartwatch_gyroscope'\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "# Group data by subject_id\n",
    "df_train_label_subject_id = df_train_label.groupby(\"subject_id\")\n",
    "\n",
    "# Go through the subject_id and k-fold their data\n",
    "for subject_id, value in df_train_label_subject_id:\n",
    "    list_df_train_label, list_df_test_label = get_k_fold(\n",
    "        df_train_label=df_train_label,\n",
    "        n_splits=5,\n",
    "        subject_id=subject_id,\n",
    "        data_real_subtype=data_real_subtype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL-PD Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database, originally named \"Parkinson@Home\" is renamed to \"Real-PD\" for this challenge. The study was made over 2 weeks, with at home monitoring. \n",
    "\n",
    "The devices used are an android phone, a motorolla watch. \n",
    "- `smartwatch_accelerometer` and `smartwatch_gyroscope` : Motorolla Watch\n",
    "- `smartphone_accelerometer` : Android phone \n",
    "\n",
    "-> Question: so is the smartwatch & smartphone accelerometer should measure the same movements? \n",
    "\n",
    "The REAL-PD database has many missing values. \n",
    "\n",
    "The subject_id `hbv013` is the only one without missing data. Other patients all have at least one missing symptom (`diskenisia`, ) or two (`on/off and tremor`, `on_off and dyskinesia`, `dyskinesia and tremor`) missing.\n",
    "\n",
    "Measurements id with no data (`on_off`, `dyskinesia` and `tremor` are all missing):\n",
    "- `b50d1b0c-2cd1-45f8-9097-0742e5cbbcc8`\n",
    "- `b598c177-4e38-4ea8-8543-bd8f7e580f96`\n",
    "- `cf841bf8-0082-4ea3-999f-1f43e39a8dc6`\n",
    "- `b1e15f8a-109f-459b-ba87-46899240ee66`\n",
    "- `6f0e2580-56ec-4743-9356-d3e4d9a0aee5`\n",
    "- `773536f6-9b70-43d0-b099-5d167d74924a`\n",
    "- `54a0e841-ad45-4ba7-ac83-1785c5f7748b`\n",
    "- `cd9ed2e2-7e04-44c7-b041-7788f133c193`\n",
    "- `a6954a91-338b-4523-9e4a-5e69a8fac206`\n",
    "\n",
    "The 3 symptoms are reported as follows in this dataset: \n",
    "- `on_off = {0,1}`\n",
    "  - `Off` : 0 (medication is wearing off) \n",
    "  - `On` : 1 (medication is working)\n",
    "  \n",
    "- `dyskinesia = {0,1,2}`\n",
    "  - Without dyskinesia: 0 \n",
    "  - Non-troublesome dyskinesia: 1 \n",
    "  - Severe dyskinesia: 2 \n",
    "  \n",
    "- `tremor = {0,1,2,3,4}` \n",
    "The description of the database mentions `tremor` is rated from 0 to 4 according to its severity, but from all the data, the maximum value of `tremor` recorded is 3. \n",
    "\n",
    "Data:\n",
    "- ancillary\n",
    "- clinical : UPDRS evaluation score \n",
    "- demographics : #TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"real\"\n",
    "# data_real_subtype='smartphone_accelerometer'\n",
    "data_real_subtype = \"smartwatch_accelerometer\"\n",
    "# data_real_subtype='smartwatch_gyroscope'\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "\n",
    "# List of interesting measurement id we want to look at\n",
    "list_measurement_id = [\n",
    "    \"5b4c7c81-659d-40ea-a1fd-59622074fd10\",\n",
    "    \"ee053d95-c155-400d-ae42-fe24834ad4a9\",\n",
    "    \"ce51ee31-8553-4321-9f83-8cd3dabe2f66\",\n",
    "    \"e07708ff-7b8d-4070-af70-3aa81423ab5b\",\n",
    "    #'7d3f4b7a-167f-4a26-9062-94ce9d8794c1',\n",
    "    \"99af8d14-cd09-4107-9502-355378ba4e08\",\n",
    "    #'7d5ac31a-cb53-40f7-8188-0b13724ea55c',\n",
    "    \"9e43840b-dd89-498b-af1a-a62896a4d5d9\",\n",
    "    \"e391f546-bf8a-46c7-a16c-95bc02f40629\",\n",
    "]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(\n",
    "    df_train_label=df_train_label, list_measurement_id=list_measurement_id\n",
    ")\n",
    "\n",
    "# Display filtered df_train_label\n",
    "# display(df_train_label)\n",
    "\n",
    "###  Plot the accelerometer data\n",
    "# Path example: /home/sjoshi/codes/python/BeatPD/code/accelerometer_plots/real/smartwatch_gyroscope/\n",
    "path = path_save_accelerometer_plots + \"/\" + data_type + \"/\" + data_real_subtype + \"/\"\n",
    "plot_accelerometer(data_type=data_type, path_accelerometer_plots=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the occurences of each symptoms for each patient\n",
    "df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "    df_train_label=df_train_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graphs\n",
    "plot_symptoms_occurences(\n",
    "    df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing both databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\"></th>\n",
    "    <th class=\"tg-0pky\">CIS-PD</th>\n",
    "    <th class=\"tg-0pky\">REAL-PD</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\"># of subject_id training</td>\n",
    "    <td class=\"tg-c3ow\">16</td>\n",
    "    <td class=\"tg-c3ow\">12</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\"># of female training</td>\n",
    "    <td class=\"tg-c3ow\">5</td>\n",
    "    <td class=\"tg-c3ow\">7</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\"># of male training</td>\n",
    "    <td class=\"tg-c3ow\">11</td>\n",
    "    <td class=\"tg-c3ow\">5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">Age average (std deviation)</td>\n",
    "    <td class=\"tg-c3ow\">62.8125 (10.857)</td>\n",
    "    <td class=\"tg-c3ow\">59.833 (5.828)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame for specified subject_id\n",
    "# display(df_train_label_subject_id.get_group('hbv013'))\n",
    "\n",
    "# print(display(df_train_label_subject_id.get_group('hbv013')['tremor'].value_counts()))\n",
    "\n",
    "# Graphs for a specific subject_id the 3 symptoms\n",
    "# df_train_label_subject_id.get_group('hbv014')['tremor'].value_counts().plot(kind='bar', title='tremor')\n",
    "# df_train_label_subject_id.get_group('hbv014')['dyskinesia'].value_counts().plot(kind='bar', title='dys')\n",
    "# df_train_label_subject_id.get_group('hbv014')['on_off'].value_counts().plot(kind='bar', title='on_off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests & Drafts, back-up space that's not important, just notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20 * 60 / 59848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default option to display all row with display(DF)\n",
    "# pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried to do convolution instead of np.multiply and dot product to get the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    np.array(\n",
    "        [\n",
    "            [0.2, 1, 5, 9],\n",
    "            [0.4, 2, 6, 10],\n",
    "            [0.6, 3, 7, 11],\n",
    "            [0.8, 4, 8, 12],\n",
    "            [1, 5, 9, 13],\n",
    "            [1.2, 6, 10, 14],\n",
    "            [1.4, 7, 11, 15],\n",
    "            [1.6, 7, 11, 15],\n",
    "            [1.8, 8, 12, 16],\n",
    "            [2, 9, 13, 16],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"Timestamp\", \"X\", \"Y\", \"Z\"],\n",
    ")\n",
    "display(df2)\n",
    "m = np.linspace(-3, 3, num=2 * 3 + 1)\n",
    "display(m)\n",
    "\n",
    "np.convolve(df2.loc[0:6, \"X\"], m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to filter a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the data to find edge cases\n",
    "\n",
    "\n",
    "# Create variable with TRUE if nationality is USA\n",
    "dys = df_train_label[\"dyskinesia\"] > 1\n",
    "\n",
    "# Create variable with TRUE if age is greater than 50\n",
    "tre = df_train_label[\"on_off\"] > 0\n",
    "\n",
    "# Select all cases where nationality is USA and age is greater than 50\n",
    "df_train_label[dys & tre]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with pct_change function to try and remove_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_pct_change = df_train_data.iloc[:,-3:].pct_change(periods=5)\n",
    "# #df_pct_change = df_train_data['X'].pct_change(periods=5)\n",
    "# df_pct_change.columns = ['X', 'Y','Z']\n",
    "# print('pct_change measurement id : ', df_train_label[\"measurement_id\"][idx])\n",
    "# display(df_pct_change)\n",
    "# df_pct_change = df_pct_change[df_pct_change > 0.01]\n",
    "\n",
    "cars = {\n",
    "    \"Brand\": [\n",
    "        \"Honda Civic\",\n",
    "        \"Toyota Corolla\",\n",
    "        \"Ford Focus\",\n",
    "        \"Audi A4\",\n",
    "        \"Toyota Corolla\",\n",
    "        \"Ford Focus\",\n",
    "        \"Audi A4\",\n",
    "    ],\n",
    "    \"Price\": [1, 1, 2, 3, 4, 5, 6],\n",
    "    \"Price2\": [2, 3, 4, 5, 6, 7, 8],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(cars, columns=[\"Brand\", \"Price\", \"Price2\"])\n",
    "display(df)\n",
    "\n",
    "display(df.iloc[:, -2:])\n",
    "\n",
    "display(df.iloc[:, -2:].pct_change(periods=1))\n",
    "\n",
    "df = df.iloc[:, -2:].pct_change(periods=1, fill_method=\"ffill\")\n",
    "\n",
    "df_pct_change = df[(df[\"Price\"] > 0.25) & (df[\"Price2\"] > 0.3)]\n",
    "print(\"------------\")\n",
    "display(df_pct_change)\n",
    "print(\"------------\")\n",
    "# display(df['Price'].pct_change(periods=1))\n",
    "\n",
    "# display(df['Price','Price2'].pct_change(periods=2))\n",
    "\n",
    "display(df[\"Price\"].pct_change(periods=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = {  #'Brand': ['Honda Civic','Toyota Corolla','Ford Focus','Audi A4','Toyota Corolla','Ford Focus','Audi A4'],\n",
    "    \"Price\": [1, 1, 2, 3, -10, 5, 6],\n",
    "    \"Price2\": [2, 3, 4, 5, 6, 7, 8],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(cars, columns=[\"Brand\", \"Price\", \"Price2\"])\n",
    "display(df)\n",
    "\n",
    "display(df.abs().max())\n",
    "\n",
    "display((df.abs().max() * 5) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactivity_max(df_train_label):\n",
    "    last_filtered_value = pd.Series(np.zeros(3), index=[\"X\", \"Y\", \"Z\"])\n",
    "    filtered_value = pd.Series(np.zeros(3), index=[\"X\", \"Y\", \"Z\"])\n",
    "    display(last_filtered_value)\n",
    "    for idx in df_train_label.index:\n",
    "        df_allo = []\n",
    "        df_train_data = pd.read_csv(\n",
    "            path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "        )\n",
    "\n",
    "        # Get the absolute max value for X, Y, Z\n",
    "        max_values = df_train_data.iloc[:, -3:].abs().max()\n",
    "\n",
    "        # Compute what is 5% of that max\n",
    "        thresold_energy = 5\n",
    "        df_treshold = (max_values * thresold_energy) / 100\n",
    "\n",
    "        # display(df_train_data)\n",
    "        # Candidates are the frames where X, Y, Z are below that treshold (5% of the max)\n",
    "        #         df_candidates = df_train_data[(df_train_data.X.abs() <= df_treshold.X) &\n",
    "        #                                      (df_train_data.Y.abs() <= df_treshold.Y) &\n",
    "        #                                      (df_train_data.Z.abs() <= df_treshold.Z)]\n",
    "        # display(df_candidates)\n",
    "        for idx2 in df_train_data.index:\n",
    "            # print('df_train_data[idx2]')\n",
    "            # display(df_train_data.iloc[idx2,-3:])\n",
    "            last_filtered_value = filtered_value\n",
    "            filtered_value = last_filtered_value + 0.004 * (\n",
    "                df_train_data.iloc[idx2, -3:] - last_filtered_value\n",
    "            )\n",
    "            y = pd.DataFrame(columns=[\"Timestamp\"])\n",
    "            y = pd.concat(\n",
    "                [y, pd.DataFrame([df_train_data.iloc[idx2, 0]], columns=[\"Timestamp\"])],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            #             print('display y :')\n",
    "            #             display(y)\n",
    "            #             print('end display y')\n",
    "\n",
    "            #             print('display filtered value')\n",
    "            #             display(pd.DataFrame(filtered_value).transpose())\n",
    "            #             print('end display filtered value')\n",
    "            df_allo.append(\n",
    "                pd.concat([y, pd.DataFrame(filtered_value).transpose()], axis=1)\n",
    "            )\n",
    "        #             print('display df_allo')\n",
    "        #             display(df_allo)\n",
    "\n",
    "        # FIXME : change the name df_allo\n",
    "        df_allo = pd.DataFrame(df_allo, columns=(\"Timestamp\", \"X\", \"Y\", \"Z\"))\n",
    "\n",
    "        df_allo.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"allo\")\n",
    "        stop()\n",
    "\n",
    "\n",
    "#         v_candidate_x = pd.DataFrame({'Candidate':list(0)})\n",
    "#         v_candidate_x = np.where(df_train_data.X.abs() <= df_treshold.X, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This didn't work because it's using pct_change between X coordinates where coincidences happens\n",
    "\n",
    "\n",
    "def remove_inactivity_pct_change(df_train_label, data_real_subtype=\"\"):\n",
    "    \"\"\"\n",
    "    Save .csv files with silence (inactivity) removed \n",
    "\n",
    "    Path used: \n",
    "    # cis-pd.training_data.no_silence/\n",
    "    # real-pd.training_data.no_silence/smartphone_accelerometer/\n",
    "    # real-pd.training_data.no_silence/smartwatch_accelerometer/\n",
    "    # real-pd.training_data.no_silence/smartwatch_gyroscope/\n",
    "    # data_type = {'cis', 'real'}\n",
    "\n",
    "    Arguments:\n",
    "    df_train_label: Dataframe with training labels\n",
    "\n",
    "    data_real_subtype: Optional. If data_type is real, data_real_subtype needs to be provided\n",
    "        data_real_subtype={smartphone_accelerometer , smartwatch_accelerometer , smartwatch_gyroscope}\n",
    "\n",
    "    Returns: \n",
    "    path_no_inactivity_data: Return the path where the files are saved because it is needed\n",
    "                          if we want to plot the accelerometer, for example\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for idx in df_train_label.index:\n",
    "        df_train_data = pd.read_csv(\n",
    "            path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "        )\n",
    "        # print('measurement id : ', df_train_label[\"measurement_id\"][idx])\n",
    "        # display(df_train_data)\n",
    "        cols_to_norm = [\"x\", \"y\", \"z\"] if data_type == \"real\" else [\"X\", \"Y\", \"Z\"]\n",
    "        df_train_data[cols_to_norm] = df_train_data[cols_to_norm].apply(\n",
    "            lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "        )\n",
    "        periods = 300\n",
    "        df_pct_change = df_train_data.iloc[:, -3:].pct_change(periods=periods)\n",
    "\n",
    "        df_pct_change.columns = [\"X\", \"Y\", \"Z\"]\n",
    "        # print('pct_change measurement id : ', df_train_label[\"measurement_id\"][idx])\n",
    "        # display(df_pct_change)\n",
    "\n",
    "        # Apply the treshold to the DataFrame with an AND condition, so all axis must have at least 1% of change\n",
    "        # between the periods\n",
    "        # pd.options.display.max_rows = 1000\n",
    "        print(\"----------before filter--------\")\n",
    "        display(df_pct_change.abs())\n",
    "\n",
    "        print(\"WHAT IS DETECTED AS INACTIVITY\")\n",
    "        display(\n",
    "            df_pct_change[\n",
    "                (df_pct_change.X.abs() < 0.0002)\n",
    "                | (df_pct_change.Y.abs() < 0.0002)\n",
    "                | (df_pct_change.Z.abs() < 0.0002)\n",
    "            ]\n",
    "        )\n",
    "        print(\"END OF WHAT IS DETECTED AS INACTIVITY\")\n",
    "\n",
    "        df_pct_change = df_pct_change[\n",
    "            (df_pct_change.X.abs() >= 0.0002)\n",
    "            & (df_pct_change.Y.abs() >= 0.0002)\n",
    "            & (df_pct_change.Z.abs() >= 0.0002)\n",
    "        ]\n",
    "        print(\"----------after filter--------\")\n",
    "        display(df_pct_change)\n",
    "\n",
    "        filter_df = df_train_data[\n",
    "            df_train_data.index.isin(df_pct_change.index.to_list())\n",
    "        ]\n",
    "\n",
    "        # Counts the number of time where we had to remove inactivity from a dataframe to know how often\n",
    "        # the inactivity zones appear.\n",
    "        print(\"len(filter_df)+periods \", str(len(filter_df) + periods))\n",
    "        print(\"len(df_train_data) \", str(len(df_train_data)))\n",
    "        if len(filter_df) + periods != len(df_train_data):\n",
    "            count = count + 1\n",
    "\n",
    "        # To provide the name of the header for the Dataframe, we get the name of the x axis as it depends\n",
    "        # on the data_type and then we insert it at the first position before the X,Y,Z axis\n",
    "        x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "        cols_to_norm.insert(0, x_axis_data_type)\n",
    "\n",
    "        # filter_df.plot(x='Timestamp',legend=True, subplots=True,title='allo')\n",
    "\n",
    "        # Save the dataframe in a file with the measurement_id as the name of the file\n",
    "        path_no_inactivity_data = (\n",
    "            data_dir\n",
    "            + data_type\n",
    "            + \"-pd.training_data.no_silence/\"\n",
    "            + data_real_subtype\n",
    "            + \"/\"\n",
    "        )\n",
    "        filter_df.to_csv(\n",
    "            path_no_inactivity_data + df_train_label[\"measurement_id\"][idx] + \".csv\",\n",
    "            index=False,\n",
    "            header=cols_to_norm,\n",
    "        )\n",
    "    print(\n",
    "        \"Inactivity zones were detected \",\n",
    "        str(count),\n",
    "        \" times out of \",\n",
    "        str(len(df_train_label.index)),\n",
    "    )\n",
    "    return path_no_inactivity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zeros = pd.DataFrame([False,True,False,False,False,True,False]).astype(int)\n",
    "\n",
    "df_zeros = np.array([0, 0, 0, 1, 0, 1, 1, 1, 1], dtype=bool)\n",
    "\n",
    "display(df_zeros.astype(int))\n",
    "count = 0\n",
    "duration_threshold = 2\n",
    "indices_list = []  # List of tuples\n",
    "howmany = 0\n",
    "for i in range(0, len(df_zeros)):\n",
    "    if df_zeros[i] == 1:\n",
    "        count = count + 1\n",
    "        print(\"1  lindex\", i)\n",
    "    else:\n",
    "        if count >= duration_threshold:\n",
    "            print(\"threshold atteint start \", start, \" end at \", end)\n",
    "            start = i - count\n",
    "            end = i - 1\n",
    "            indices_list.append((start, end))\n",
    "            howmany = howmany + 1\n",
    "            count = 0\n",
    "        # if it doesn't reach the threshold, we change the 1 for 0 because we don't want to remove those\n",
    "        elif count >= 1:\n",
    "            print(\"Effacer les 1 de \", start, \" a \", end)\n",
    "            df_zeros[i - count : i] = [0] * (end - start)\n",
    "            count = 0\n",
    "\n",
    "display(df_zeros.astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
