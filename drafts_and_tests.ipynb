{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 2 - Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the following code was used in the second submission, but I didn't take the time on making it clear and pretty since it's not in our final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(lFilesPred, sFileLabels, sTypeLabel):\n",
    "    \"\"\"\n",
    "    TODO \n",
    "    \n",
    "    Keyword Arguments: \n",
    "    - lFilesPred: \n",
    "    - sFileLabels: \n",
    "    - sTypeLabels: \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    print(\"sFileLabels : \", sFileLabels)\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dID = {rows[0]:rows[1] for rows in reader} #participant ID\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dOnOff= {rows[0]:rows[2] for rows in reader} #on-off label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dDys={rows[0]:rows[3] for rows in reader} #dyskinesia label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dTrem={rows[0]:rows[4] for rows in reader} #tremor label\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFiles=len(lFilesPred)\n",
    "    #mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "    #mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    vParID=[] # participant ID\n",
    "    lDicts=[] \n",
    "\n",
    "\n",
    "    # We loop over the predictions files from the tsfresh and SVR\n",
    "    # lDicts is a list of measurement_id and the predictions obtained \n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (ivec-svr, boost...)\n",
    "        lDicts.append(dPred)\n",
    "    print('sTypeLabel : ', sTypeLabel)\n",
    "    #label selection\n",
    "    if sTypeLabel=='on_off':\n",
    "        dLabels=dOnOff\n",
    "    elif sTypeLabel=='tremor':\n",
    "        dLabels=dTrem\n",
    "    elif sTypeLabel=='dyskinesia':\n",
    "        dLabels=dDys\n",
    "    else:\n",
    "        print('sTypeLabel undefined')\n",
    "    \n",
    "    print('dLabels')\n",
    "    print(dLabels)\n",
    "    \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "                vParID.append(float(np.asarray(dID[k]))) #participant ID\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    print('mPredictions and vLabels')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(vLabels))\n",
    "    # Random forest training - regression\n",
    "    \n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "    return mPredictions, vLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_fusion(lFilesPred, sFileLabels, iEstimators, sTypeLabel, nudge, rLR, iMD,iRS):\n",
    "\n",
    "    mPredictions, vLabels = read_files(lFilesPred, sFileLabels, sTypeLabel)\n",
    "    \n",
    "    clf=GradientBoostingRegressor(n_estimators=iEstimators, learning_rate=rLR, max_depth=iMD,\\\n",
    "                                      random_state=iRS, loss='ls').fit(mPredictions, vLabels)\n",
    "    vNewPred=clf.predict(mPredictions)\n",
    "    vRes1=mPredictions[:,[0]]\n",
    "    vRes2=mPredictions[:,[1]]\n",
    "    \n",
    "    # we will include the testing data here\n",
    "    return (vNewPred, vParID, vLabels, vRes1, vRes2, clf)\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest_predTest(lTestPred, clf, sDirOut,sName):\n",
    "    \n",
    "    lDicts=[] #Will contain the two test predictions\n",
    "    lmesID=[]\n",
    "    iNumFiles=len(lTestPred)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "\n",
    "    for sFilePred in lTestPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (ivec-svr, boost...)\n",
    "        lDicts.append(dPred)\n",
    "      \n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            lmesID.append(k)\n",
    "            #vParID.append(float(np.asarray(dID[k]))) #participant ID\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            for j in range(1, iNumFiles):\n",
    "                fPred=lDicts[j].get(k)\n",
    "            if fPred:\n",
    "                vPredIter[0,j]=float(np.asarray(fPred))\n",
    "            else:\n",
    "                print(['Unkwnown key:' + k])\n",
    "                vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "\n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    \n",
    "    vTestPred=clf.predict(mPredictions)\n",
    "    df = pd.DataFrame({'measurement_id': lmesID, sName:vTestPred})\n",
    "    df.to_csv(sDirOut+'submissionCisPD'+sName+'.csv', index=False)\n",
    "    return(lmesID, vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyskinesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sFilePred1='/export/b15/nchen/BeatPD/cispd.kfold_prediction_on_off.csv'\n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sFilePred2='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sTypeLabel='on_off'\n",
    "n_estimators=300\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=15\n",
    "nudge=100\n",
    "sFileLabels=sFilePred1\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1,\\\n",
    "vRes2, clf = RandomForest_fusion (lFilesPred, sFileLabels, n_estimators, sTypeLabel, nudge, rLR, iMD,iRS)\n",
    "\n",
    "print('Overall MSE Classif. 1 : ', get_final_score(vTrueLabels,np.array(vParID).astype(int), vRes1))\n",
    "print('Overall MSE Classif. 2 : ', get_final_score(vTrueLabels, vParID, vRes2))\n",
    "print('Overall MSE Fusion : ', get_final_score(vPredCross, vParIDCross,vTrueCross))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30/exp/ivec_450/resiVecSVR_Fold/On_off_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/'\n",
    "sName='on_off'\n",
    "#lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "#print(vTestPred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tremor - Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsfresh predictions file \n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_tremor.csv'\n",
    "\n",
    "# SVR predictions file \n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_450/resiVecSVR_Fold_all/objs_450_kernel_linear_c_0.02_eps_0.1.csv'\n",
    "\n",
    "# subchallenge \n",
    "sTypeLabel='tremor'\n",
    "\n",
    "# RandomForest hyperparameter \n",
    "n_estimators=5\n",
    "\n",
    "# Labels\n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1, vRes2, clf = RandomForest_fusion(lFilesPred,\n",
    "                                                                           sFileLabels,\n",
    "                                                                           n_estimators,\n",
    "                                                                           sTypeLabel)\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/submission/cis-pd.tremor.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_450/resiVecSVR_Fold/Tremor_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/submissionFiles/'\n",
    "sName='tremor'\n",
    "lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "print(vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyskinesia - Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sFilePred1='/export/b15/nchen/BeatPD/cispd.kfold_prediction_dyskinesia.csv'\n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_dyskinesia.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold_all/objs_500_kernel_linear_c_0.002_eps_0.1.csv'\n",
    "sTypeLabel='dyskinesia'\n",
    "n_estimators=5\n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1, vRes2, clf = RandomForest_fusion (lFilesPred, sFileLabels, n_estimators, sTypeLabel)\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/submission/cis-pd.dyskinesia.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold/Dyskinesia_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/submissionFiles/'\n",
    "sName='z_dyskinesia'\n",
    "lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "print(vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pca_everyone_svr_bpd import *\n",
    "\n",
    "sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Training_Fold0/ivector.scp\"\n",
    "sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Testing_Fold0/ivector.scp\"\n",
    "iComponents=50\n",
    "\n",
    "vTraiPCA, vLTrai, vTraiSubjectId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pca_knn_bpd2 import *\n",
    "\n",
    "sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Training_Fold0/ivector.scp\"\n",
    "sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Testing_Fold0/ivector.scp\"\n",
    "iComponents=50\n",
    "\n",
    "vTraiPCA, vLTrai, vTraiSubjectId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "uniq_subjectid = np.unique(vTraiSubjectId)\n",
    "enc = OneHotEncoder(handle_unknown='ignore').fit(uniq_subjectid.reshape(-1,1))\n",
    "print(uniq_subjectid.reshape(-1,1).shape)\n",
    "print(enc)\n",
    "temp = enc.transform([[1004]]).toarray()\n",
    "print(temp.shape)\n",
    "temp2 = np.repeat(temp,61,axis=0)\n",
    "temp2.shape\n",
    "#temp3 = np.random.rand(61,50)\n",
    "#temp4 = np.concatenate((temp3,temp2),axis=1)\n",
    "#print(temp4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pca_knn_bpd2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions for Per Patient SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tremor Best Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [\"0\",\"1\",\"2\",\"3\",\"4\"]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_550/ivectors_Training_Fold\"+fold+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_550/ivectors_Testing_Fold\"+fold+\"/ivector.scp\"\n",
    "\n",
    "    sOut=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_550/resiVecPerPatientSVR_Fold\"+fold\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    for iComponent in [250]:#[50, 100, 150, 200, 250, 350, 450, 500, 550]:\n",
    "\n",
    "        for fCValue in [20.0]:#[2e-13, 2e-07, 0.002, 0.2, 20.0]:\n",
    "            vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponent)\n",
    "\n",
    "            pca_knn_bpd2(sFileTrai, sFileTest, sOut,\n",
    "                         iComponent,\n",
    "                         iNeighbors,\n",
    "                         sKernel='linear',\n",
    "                         fCValue=fCValue,\n",
    "                         fEpsilon='0.1',\n",
    "                         bLabelNormalization=False,\n",
    "                         bPatientPredictionsPkl=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dysk Best Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [\"0\",\"1\",\"2\",\"3\",\"4\"]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_orig_auto60_400fl/exp/ivec_650/ivectors_Training_Fold\"+fold+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_orig_auto60_400fl/exp/ivec_650/ivectors_Testing_Fold\"+fold+\"/ivector.scp\"\n",
    "\n",
    "    sOut=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_orig_auto60_400fl/exp/ivec_650/resiVecPerPatientSVR_Fold\"+fold\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    for iComponent in [100]:#[50, 100, 150, 200, 250, 350, 450, 500, 550]:\n",
    "\n",
    "        for fCValue in [20.0]:#[2e-13, 2e-07, 0.002, 0.2, 20.0]:\n",
    "            vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponent)\n",
    "\n",
    "            pca_knn_bpd2(sFileTrai, sFileTest, sOut,\n",
    "                         iComponent,\n",
    "                         iNeighbors,\n",
    "                         sKernel='linear',\n",
    "                         fCValue=fCValue,\n",
    "                         fEpsilon='0.1',\n",
    "                         bLabelNormalization=False,\n",
    "                         bPatientPredictionsPkl=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Mean Normalization SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold in [\"0\",\"1\",\"2\",\"3\",\"4\"]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Training_Fold\"+fold+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Testing_Fold\"+fold+\"/ivector.scp\"\n",
    "\n",
    "\n",
    "    sOut=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/resiVecSVR_Fold\"+fold\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "\n",
    "    iComponents=500\n",
    "    pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.002, fEpsilon='0.1',\n",
    "                 bLabelNormalization=True)\n",
    "\n",
    "\n",
    "    # iComponents=400\n",
    "    # pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.02, fEpsilon='0.01',\n",
    "    #              bLabelNormalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Patient - With Mean Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "for fold in [\"0\",\"1\",\"2\",\"3\",\"4\"]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Training_Fold\"+fold+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Testing_Fold\"+fold+\"/ivector.scp\"\n",
    "\n",
    "\n",
    "    sOut=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/resiVecSVR_Fold\"+fold\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "\n",
    "    iComponents=500\n",
    "    pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.002, fEpsilon='0.1',\n",
    "                 bLabelNormalization=True)\n",
    "\n",
    "\n",
    "    # iComponents=400\n",
    "    # pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.02, fEpsilon='0.01',\n",
    "    #              bLabelNormalization=True)\n",
    "    \n",
    "# sFilePath=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/\"\n",
    "# #sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "# bKnn=False\n",
    "# bSVR=True\n",
    "# bEveryoneSVR=False\n",
    "# bPerSubject=False \n",
    "# sDatabase=None\n",
    "# sSubchallenge=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.get_final_scores_accuracy import get_final_scores_SVR \n",
    "from local.get_final_scores_accuracy import get_final_scores_SVR_lowest_mse_for_subjectid\n",
    "\n",
    "sFilePath=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/\"\n",
    "#sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "bKnn=False\n",
    "bSVR=True\n",
    "bEveryoneSVR=False\n",
    "bPerSubject=True \n",
    "sDatabase='CIS'\n",
    "sSubchallenge='dysk'\n",
    "\n",
    "get_final_scores_SVR_lowest_mse_for_subjectid(sFilePath, bKnn, bSVR, bEveryoneSVR, bPerSubject, sDatabase, sSubchallenge)\n",
    "\n",
    "# get_final_scores_SVR(sFilePath, bKnn, bSVR, bEveryoneSVR, bPerSubject, sDatabase, sSubchallenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test WITHOUT Mean Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold in [\"0\",\"1\",\"2\",\"3\",\"4\"]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Training_Fold\"+fold+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Testing_Fold\"+fold+\"/ivector.scp\"\n",
    "\n",
    "    sOut=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/without_mean_norm/resiVecSVR_Fold\"+fold\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    iComponents=500\n",
    "    vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "\n",
    "    pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.002, fEpsilon='0.1',\n",
    "                 bLabelNormalization=False)\n",
    "\n",
    "    # iComponents=400\n",
    "    # pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.02, fEpsilon='0.01',\n",
    "    #              bLabelNormalization=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sFilePath=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/without_mean_norm/\"\n",
    "#sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "bKnn=False\n",
    "bSVR=True\n",
    "bEveryoneSVR=False\n",
    "bPerSubject=True \n",
    "sDatabase='CIS'\n",
    "sSubchallenge='dysk'\n",
    "\n",
    "get_final_scores_SVR_lowest_mse_for_subjectid(sFilePath, bKnn, bSVR, bEveryoneSVR, bPerSubject, sDatabase, sSubchallenge)\n",
    "\n",
    "\n",
    "#get_final_scores_SVR(sFilePath, bKnn, bSVR, bEveryoneSVR, bPerSubject, sDatabase, sSubchallenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from local.get_final_scores_accuracy import get_final_scores_SVR \n",
    "\n",
    "sFilePath=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/without_mean_norm/\"\n",
    "#sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "bKnn=False\n",
    "bSVR=True\n",
    "bEveryoneSVR=False\n",
    "bPerSubject=False \n",
    "sDatabase=None\n",
    "sSubchallenge=None\n",
    "\n",
    "get_final_scores_SVR(sFilePath, bKnn, bSVR, bEveryoneSVR, bPerSubject, sDatabase, sSubchallenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR testing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Training_Fold0/ivector.scp\"\n",
    "sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_500/ivectors_Testing_Fold0/ivector.scp\"\n",
    "iComponents=400\n",
    "\n",
    "sOut=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/ResiVecSVR_Fold0\"\n",
    "\n",
    "iNeighbors=None\n",
    "\n",
    "vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "\n",
    "pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.02, fEpsilon='0.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pca_knn_bpd import *\n",
    "\n",
    "sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_400/\"\n",
    "\n",
    "sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/ivectors_Training_Fold0/ivector.scp\"\n",
    "sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/ivectors_Testing_Fold0/ivector.scp\" \n",
    "\n",
    "sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_400/ivectors_Training_Fold0/ivector.scp\"\n",
    "sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_400/ivectors_Testing_Fold0/ivector.scp\" \n",
    "\n",
    "\n",
    "iComponents=50\n",
    "\n",
    "vTraiPCA, vLTrai, vTraiSubjectId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "print(vTraiPCA.shape)\n",
    "\n",
    "# /home/mpgill/BeatPD/BeatPD-CLSP-JHU/pca_everyone_svr_bpd.py \n",
    "\n",
    "# sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Training_Fold0/ivector.scp\"\n",
    "# sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_autoenc/exp/ivec_100/ivectors_Testing_Fold0/ivector.scp\"\n",
    "\n",
    "\n",
    "sOut=\"/home/mpgill/test/\"\n",
    "sKernel='linear' \n",
    "fCValue=0.00000000200000 \n",
    "fEpsilon=0.1\n",
    "iNeighbors=None\n",
    "\n",
    "pca_knn_bpd(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.02, fEpsilon='0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from get_final_scores_accuracy import get_final_scores_SVR \n",
    "\n",
    "sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_400/\"\n",
    "#sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "bKnn=False\n",
    "bSVR=True\n",
    "bEveryoneSVR=False\n",
    "\n",
    "get_final_scores_SVR(sFilePath, bKnn, bSVR, bEveryoneSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from get_final_scores_accuracy import get_final_scores_SVR_lowest_mse_for_subjectid \n",
    "\n",
    "#sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_400/\"\n",
    "sFilePath=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto60_400fl/exp/ivec_400/\"\n",
    "bKnn=False\n",
    "bSVR=True\n",
    "bEveryoneSVR=False\n",
    "\n",
    "#get_final_scores_SVR(sFilePath, bKnn, bSVR, bEveryoneSVR)\n",
    "\n",
    "get_final_scores_SVR_lowest_mse_for_subjectid(sFilePath, bKnn, bSVR, bEveryoneSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut = ['100001_test_5163afe8-a6b0-4ea4-b2ba-9b4501dd5912_10040',\n",
    " '100002_test_9152519b-4b57-43be-963c-dd7218495001_10040',\n",
    " '100003_test_c7312d73-cb34-4025-b8b8-5299b4033e2f_10040',\n",
    " '100004_test_cc730391-146b-420f-9255-c3185061f178_10040',\n",
    " '100005_test_cc7b822c-e310-46f0-a8ea-98c95fdb67a1_10041',\n",
    " '100006_test_5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a_10041',\n",
    " '100007_test_19a3e9ea-fce1-40b7-9457-2618970beb7b_10041',\n",
    " '100008_test_e2973da8-1250-4a7c-98d5-b165570a8aeb_10041',\n",
    " '100009_test_dc90dc36-b4e5-43ec-b3e8-47c39c763c71_10041']\n",
    "\n",
    "salut2= ['100001_test_5163afe8-a6b0-4ea4-b2ba-9b4501dd5912_hbv0401',\n",
    " '100002_test_9152519b-4b57-43be-963c-dd7218495001_hbv0401',\n",
    " '100003_test_c7312d73-cb34-4025-b8b8-5299b4033e2f_hbv0401',\n",
    " '100004_test_cc730391-146b-420f-9255-c3185061f178_hbv0401',\n",
    " '100005_test_cc7b822c-e310-46f0-a8ea-98c95fdb67a1_hbv0411',\n",
    " '100006_test_5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a_hbv0411',\n",
    " '100007_test_19a3e9ea-fce1-40b7-9457-2618970beb7b_hbv0411',\n",
    " '100008_test_e2973da8-1250-4a7c-98d5-b165570a8aeb_hbv0412',\n",
    " '100009_test_dc90dc36-b4e5-43ec-b3e8-47c39c763c71_hbv0412']\n",
    "\n",
    "\n",
    "sPattern=r'(?<=[_])(1[0-9]{3}(?<=\\d)(?!=$)|hbv[0-9]{3})'\n",
    "\n",
    "vTraiSubjectId = [re.findall(sPattern, fileName)[0] for fileName in salut]\n",
    "\n",
    "# vTraiSubjectId = np.array(([x[-5:-1] for x in np.array(salut)]))\n",
    "print(vTraiSubjectId)\n",
    "\n",
    "vTraiSubjectId2 = [re.findall(sPattern, fileName)[0] for fileName in salut2]\n",
    "print(vTraiSubjectId2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import re\n",
    "\n",
    "\n",
    "# def read_log_results_to_excel(folders, fileName):\n",
    "#     for folder in folders:#'trem_noinact_auto30']:#,'trem_noinact_auto30_320fl','trem_noinact_auto30_240fl','trem_noinact_auto60_400fl']:\n",
    "#         print(folder)\n",
    "#         value = []\n",
    "#         liVecDim = [350,400]#[350,400,450,500,550, 600, 650, 700]\n",
    "#         for ivecDim in liVecDim:\n",
    "#             sFilePath='/export/c08/lmorove1/kaldi/egs/beatPDivec/'+folder+'/exp/ivec_'+str(ivecDim)+'/'\n",
    "\n",
    "#             #config_pattern = re.compile(r\"Test Final score\\s[:| ]\\s*(\\d*.\\d*)\")\n",
    "# #             config_pattern = re.compile(r\"GLOBAL WINNER PARAMETERS(.|\\n)*\\\\KTest Final score\\s[:| ]\\s*(\\d*.\\d*)\")\n",
    "\n",
    "\n",
    "#             textfile = open(sFilePath+fileName)\n",
    "#             filetext = textfile.read()\n",
    "#             textfile.close()\n",
    "# #             print(filetext)\n",
    "#             matches = re.findall(r\"GLOBAL WINNER PARAMETERS(?:.|\\n)*\\\\KTest Final score\\s[:| ]\\s*(\\d*.\\d*)\",\n",
    "#                                  filetext)\n",
    "# #             matches = re.findall(r\"GLOBAL WINNER PARAMETERS(.|\\n)*\\\\KTest Final score\\s[:| ]\\s*(\\d*.\\d*)\",\n",
    "# #                                  filetext)\n",
    "#             print(matches)\n",
    "# #             with open(sFilePath+fileName) as f:\n",
    "# #                 print(f)\n",
    "# #                 match = config_pattern.search(line)\n",
    "# #                 if match:\n",
    "# #                     #print(match.groups()[0])\n",
    "# #                     value.append(match.groups()[0])\n",
    "# #                     #yield line.strip()\n",
    "\n",
    "#         value = pd.DataFrame(value)\n",
    "#         value = value.T\n",
    "#         value.columns = liVecDim\n",
    "#         display(value)\n",
    "\n",
    "# folders=['on_off_noinact_auto30_320fl']\n",
    "# fileName='globalAccuPerPatientSVR_Test.log'\n",
    "# read_log_results_to_excel(folders, fileName)\n",
    "\n",
    "# # folders=['on_off_noinact_auto30_320fl']\n",
    "# # fileName='globalAccuEveryoneSVR_Test.log'\n",
    "# # read_log_results_to_excel(folders, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import re\n",
    "\n",
    "\n",
    "# def read_log_results_to_excel(folders, fileName):\n",
    "#     for folder in folders:#'trem_noinact_auto30']:#,'trem_noinact_auto30_320fl','trem_noinact_auto30_240fl','trem_noinact_auto60_400fl']:\n",
    "#         print(folder)\n",
    "#         value = []\n",
    "#         liVecDim = [350,400,450,500,550, 600, 650, 700]\n",
    "#         for ivecDim in liVecDim:\n",
    "#             sFilePath='/export/c08/lmorove1/kaldi/egs/beatPDivec/'+folder+'/exp/ivec_'+str(ivecDim)+'/'\n",
    "\n",
    "#             #config_pattern = re.compile(r\"Test Final score\\s[:| ]\\s*(\\d*.\\d*)\")\n",
    "#             config_pattern = re.compile(r\"Test Final score\\s[:| ]\\s*(\\d*.\\d*)\")\n",
    "# #             config_pattern = re.compile(r\"GLOBAL WINNER PARAMETERS(?:.|\\n)*\\\\KTest Final score\\s[:| ]\\s*(\\d*.\\d*)\")\n",
    "#             with open(sFilePath+fileName) as f:\n",
    "#                 for line in f:\n",
    "#                     match = config_pattern.search(line)\n",
    "#                     if match:\n",
    "#                         #print(match.groups()[0])\n",
    "#                         value.append(match.groups()[0])\n",
    "#                         #yield line.strip()\n",
    "\n",
    "#         value = pd.DataFrame(value)\n",
    "#         value = value.T\n",
    "#         value.columns = liVecDim\n",
    "#         display(value)\n",
    "\n",
    "# folders=['on_off_noinact_auto30_320fl']\n",
    "# fileName='globalAccuPerPatientSVR_Test.log'\n",
    "# read_log_results_to_excel(folders, fileName)\n",
    "\n",
    "# folders=['on_off_noinact_auto30_320fl']\n",
    "# fileName='globalAccuEveryoneSVR_Test.log'\n",
    "# read_log_results_to_excel(folders, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "\n",
    "def read_log_results_to_excel(folders, fileName):\n",
    "    for folder in folders:#'trem_noinact_auto30']:#,'trem_noinact_auto30_320fl','trem_noinact_auto30_240fl','trem_noinact_auto60_400fl']:\n",
    "        print(folder)\n",
    "        value = []\n",
    "        liVecDim = [350,450,500,550]\n",
    "        for ivecDim in liVecDim:\n",
    "            sFilePath='/export/c08/lmorove1/kaldi/egs/beatPDivec/'+folder+'/exp/ivec_'+str(ivecDim)+'/'\n",
    "            print('Opening : ', sFilePath+fileName)\n",
    "            textfile = open(sFilePath+fileName)\n",
    "            filetext = textfile.read()\n",
    "            textfile.close()\n",
    "            \n",
    "            \n",
    "            result = re.findall(r\"Test Final score\\s[:| ]\\s*(\\d*.\\d*)\",filetext)\n",
    "            print(result[len(result)-1])\n",
    "            value.append(result[len(result)-1])\n",
    "            \n",
    "        value = pd.DataFrame(value)\n",
    "        value = value.T\n",
    "        value.columns = liVecDim\n",
    "        display(value)\n",
    "\n",
    "folders=['on_off_noinact_auto30']\n",
    "fileName='globalAccuPerPatientSVR_Test.log'\n",
    "read_log_results_to_excel(folders, fileName)\n",
    "\n",
    "folders=['on_off_noinact_auto30_320fl']\n",
    "fileName='globalAccuEveryoneSVR_Test.log'\n",
    "read_log_results_to_excel(folders, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove inactivity with max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactivity_max(df_train_label):\n",
    "    last_filtered_value = pd.Series(np.zeros(3), index=[\"X\", \"Y\", \"Z\"])\n",
    "    filtered_value = pd.Series(np.zeros(3), index=[\"X\", \"Y\", \"Z\"])\n",
    "    display(last_filtered_value)\n",
    "    for idx in df_train_label.index:\n",
    "        df_allo = []\n",
    "        df_train_data = pd.read_csv(\n",
    "            path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\"\n",
    "        )\n",
    "\n",
    "        # Get the absolute max value for X, Y, Z\n",
    "        max_values = df_train_data.iloc[:, -3:].abs().max()\n",
    "\n",
    "        # Compute what is 5% of that max\n",
    "        thresold_energy = 5\n",
    "        df_treshold = (max_values * thresold_energy) / 100\n",
    "\n",
    "        # display(df_train_data)\n",
    "        # Candidates are the frames where X, Y, Z are below that treshold (5% of the max)\n",
    "        #         df_candidates = df_train_data[(df_train_data.X.abs() <= df_treshold.X) &\n",
    "        #                                      (df_train_data.Y.abs() <= df_treshold.Y) &\n",
    "        #                                      (df_train_data.Z.abs() <= df_treshold.Z)]\n",
    "        # display(df_candidates)\n",
    "        for idx2 in df_train_data.index:\n",
    "            # print('df_train_data[idx2]')\n",
    "            # display(df_train_data.iloc[idx2,-3:])\n",
    "            last_filtered_value = filtered_value\n",
    "            filtered_value = last_filtered_value + 0.004 * (\n",
    "                df_train_data.iloc[idx2, -3:] - last_filtered_value\n",
    "            )\n",
    "            y = pd.DataFrame(columns=[\"Timestamp\"])\n",
    "            y = pd.concat(\n",
    "                [y, pd.DataFrame([df_train_data.iloc[idx2, 0]], columns=[\"Timestamp\"])],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            #             print('display y :')\n",
    "            #             display(y)\n",
    "            #             print('end display y')\n",
    "\n",
    "            #             print('display filtered value')\n",
    "            #             display(pd.DataFrame(filtered_value).transpose())\n",
    "            #             print('end display filtered value')\n",
    "            df_allo.append(\n",
    "                pd.concat([y, pd.DataFrame(filtered_value).transpose()], axis=1)\n",
    "            )\n",
    "        #             print('display df_allo')\n",
    "        #             display(df_allo)\n",
    "\n",
    "        # FIXME : change the name df_allo\n",
    "        df_allo = pd.DataFrame(df_allo, columns=(\"Timestamp\", \"X\", \"Y\", \"Z\"))\n",
    "\n",
    "        df_allo.plot(x=\"Timestamp\", legend=True, subplots=True, title=\"allo\")\n",
    "        stop()\n",
    "\n",
    "\n",
    "#         v_candidate_x = pd.DataFrame({'Candidate':list(0)})\n",
    "#         v_candidate_x = np.where(df_train_data.X.abs() <= df_treshold.X, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np \n",
    "rot_ang = 45\n",
    "\n",
    "rot = np.random.randint(-rot_ang,rot_ang,size=1)[0]\n",
    "print('rot : ', rot)\n",
    "print([rot]*3)\n",
    "r = R.from_euler('xyz', [rot]*3, degrees=True)\n",
    "print(r)\n",
    "rot_mat = r.as_dcm()\n",
    "print('rot_mat : ', rot_mat)\n",
    "# temp_train_X = np.dot(temp_train_X, rot_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tsfresh experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "all_labels = pd.read_csv('/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv')\n",
    "\n",
    "all_obj = [\"on_off\", \"tremor\", \"dyskinesia\"]\n",
    "obj = \"tremor\"\n",
    "\n",
    "all_labels = all_labels.drop(list(set(all_obj) - set([obj])), axis=1)\n",
    "\n",
    "all_features = pd.read_csv('/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/features/cis-pd.training.csv')\n",
    "all_features_labels = pd.merge(all_features, all_labels, on=[\"measurement_id\"])\n",
    "\n",
    "all_features_labels = all_features_labels.dropna(subset=[obj])\n",
    "\n",
    "# Compute the average for a speaker of all the features and add those new features to all_features_label\n",
    "avg = all_features_labels.groupby('subject_id').mean().reset_index().add_prefix('sp_').rename(columns={'sp_subject_id':'subject_id'})\n",
    "all_features_labels = pd.merge(all_features_labels, avg, on='subject_id')\n",
    "\n",
    "# Performing global normalization, removing the mean for the features and the labels\n",
    "remove = []\n",
    "for i in all_features_labels.columns:\n",
    "    # if it doesn't start with sp and its sp_ is in  all_features_labels\n",
    "    if not i.startswith('sp_') and 'sp_' + i in all_features_labels.columns:\n",
    "        # We remove the sp_ column\n",
    "        remove.append('sp_' + i)\n",
    "        # We replace the feature with their value minus the mean of the subject \n",
    "        all_features_labels[i] = all_features_labels[i] - all_features_labels['sp_' + i]\n",
    "# We drop the sp_ columns which were only useful to substract the mean\n",
    "all_features_labels = all_features_labels.drop(remove, axis=1)\n",
    "\n",
    "all_features_labels = pd.merge(all_features_labels, pd.read_csv('/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/data/order.csv'), how='inner', on=[\"measurement_id\"])\n",
    "weight = all_features_labels.groupby(['subject_id', 'fold_id']).count().reset_index()[[\"subject_id\", \"fold_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "all_features_labels = pd.merge(all_features_labels, weight, on=['subject_id', 'fold_id'])\n",
    "subject_id = pd.get_dummies(all_features_labels.subject_id, columns='subject_id', prefix='spk_')\n",
    "all_features_labels = pd.concat([all_features_labels, subject_id], axis=1)\n",
    "\n",
    "all_features_labels[\"tremor\"] = all_features_labels[\"tremor\"].astype(int)\n",
    "display(all_features_labels[\"tremor\"])\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=all_features_labels, target=\"tremor\", features=[col for col in all_features_labels.columns if col != \"tremor\"])\n",
    "\n",
    "# Use predefined cv \n",
    "foldid = np.array(all_features_labels['fold_id']).astype(int)\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "cv = PredefinedSplit(foldid)\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()\n",
    "\n",
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_labels = pd.read_csv('/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obj = [\"on_off\", \"tremor\", \"dyskinesia\"]\n",
    "obj = \"tremor\"\n",
    "\n",
    "all_labels = all_labels.drop(list(set(all_obj) - set([obj])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_csv('/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/features/cis-pd.training.csv')\n",
    "all_features_labels = pd.merge(all_features, all_labels, on=[\"measurement_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_labels = all_features_labels.dropna(subset=[obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average for a speaker of all the features and add those new features to all_features_label\n",
    "avg = all_features_labels.groupby('subject_id').mean().reset_index().add_prefix('sp_').rename(columns={'sp_subject_id':'subject_id'})\n",
    "all_features_labels = pd.merge(all_features_labels, avg, on='subject_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing global normalization, removing the mean for the features and the labels\n",
    "remove = []\n",
    "for i in all_features_labels.columns:\n",
    "    # if it doesn't start with sp and its sp_ is in  all_features_labels\n",
    "    if not i.startswith('sp_') and 'sp_' + i in all_features_labels.columns:\n",
    "        # We remove the sp_ column\n",
    "        remove.append('sp_' + i)\n",
    "        # We replace the feature with their value minus the mean of the subject \n",
    "        all_features_labels[i] = all_features_labels[i] - all_features_labels['sp_' + i]\n",
    "# We drop the sp_ columns which were only useful to substract the mean\n",
    "all_features_labels = all_features_labels.drop(remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_labels = pd.merge(all_features_labels, pd.read_csv('/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/data/order.csv'), how='inner', on=[\"measurement_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = all_features_labels.groupby(['subject_id', 'fold_id']).count().reset_index()[[\"subject_id\", \"fold_id\", obj]].rename(columns={obj: 'spcount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_features_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_labels = pd.merge(all_features_labels, weight, on=['subject_id', 'fold_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = pd.get_dummies(all_features_labels.subject_id, columns='subject_id', prefix='spk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_labels = pd.concat([all_features_labels, subject_id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_labels.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "Y = np.array(all_features_labels[obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features_labels[\"tremor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array(all_features_labels['spcount']) ** -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features_labels['spcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features_labels.keys().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldid = np.array(all_features_labels['fold_id']).astype(int)\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "cv = PredefinedSplit(foldid)\n",
    "\n",
    "# X contains all the features \n",
    "X = all_features_labels.drop([obj, 'subject_id', 'measurement_id', 'spcount', 'fold_id'], axis=1).astype(pd.np.float32).values\n",
    "print(X.shape)\n",
    "print(foldid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# xgboost\n",
    "clf = xgb.XGBRegressor()\n",
    "\n",
    "best_params = {'subsample': 1.0, 'silent': False, 'gamma': 1.0, 'reg_lambda': 100.0, 'min_child_weight': 0.5, 'objective': 'reg:squarederror', 'learning_rate': 0.3, 'max_depth': 2, 'colsample_bytree': 0.8, 'n_estimators': 100, 'colsample_bylevel': 0.5}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "baselines = []\n",
    "\n",
    "preds = []\n",
    "\n",
    "lambda_value = None\n",
    "random_forest = None\n",
    "all_spks = all_features_labels['subject_id'].unique()\n",
    "\n",
    "columns_to_exclude = (all_features_labels.columns[(all_features_labels.dtypes.values != np.dtype('float64'))]).to_list()\n",
    "columns_to_exclude.remove('fold_id')\n",
    "\n",
    "for i in range(5):\n",
    "    ##test = pd.read_csv(sys.argv[i]).squeeze()\n",
    "    ##idx = all_features_labels['measurement_id'].isin(test)\n",
    "\n",
    "    # Filter all_features_labels to only the measurements of the current fold\n",
    "    idx = all_features_labels['fold_id'] == i\n",
    "\n",
    "    ##tr_w = all_features_labels[~idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##tr = pd.merge(all_features_labels[~idx], tr_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are not from the current fold \n",
    "    tr = all_features_labels[~idx].drop(['fold_id'], axis=1)\n",
    "\n",
    "    # Data augmentation with a lambda\n",
    "    if lambda_value is not None:\n",
    "        for spk in all_spks: \n",
    "            # Filter training data for that speaker \n",
    "            tr_subject = tr.loc[tr['subject_id'] == spk]\n",
    "\n",
    "            # FIXME: The mean number of recordings changes per fold so to make it easier \n",
    "            # I'm just gonna use the mean for the data augmented values\n",
    "            mean_spcount = int(tr_subject['spcount'].mean())\n",
    "\n",
    "            # Apply the lambda on the training features except the columns that are not float\n",
    "            modDfObj1 = tr_subject[tr_subject.columns.difference(columns_to_exclude)].apply(lambda x: x * lambda_value, axis=1, result_type='broadcast')\n",
    "            modDfObj2 = tr_subject[tr_subject.columns.difference(columns_to_exclude)].apply(lambda x: x * (1-lambda_value), axis=1, result_type='broadcast')\n",
    "            \n",
    "            df_data_aug = []\n",
    "            # First loop to go over the rows\n",
    "            for index, measurement1 in modDfObj1.iterrows():\n",
    "                # Second rows to go over the loop except the same two rows\n",
    "                for index2, measurement2 in modDfObj2.iterrows():\n",
    "                    if index >= index2:\n",
    "                        continue\n",
    "                    df_data_aug.append(measurement1.add(measurement2).to_list())\n",
    "            df_data_aug = pd.DataFrame(df_data_aug, columns=modDfObj1.columns)\n",
    "            \n",
    "            # Add again the columns we just removed \n",
    "            #modDfObj1 = pd.concat([modDfObj1, tr_subject[columns_to_exclude]], axis=1)\n",
    "            subjects_columns_title = [x for x in columns_to_exclude if x.startswith(\"spk_\")]\n",
    "            # Select the first row of spk_ elements \n",
    "            subject_row = tr_subject.iloc[0,tr_subject.columns.str.startswith(\"spk_\")]\n",
    "            subject_row = subject_row.append(pd.Series(mean_spcount, index=[\"spcount\"]))\n",
    "            # Duplicate that first row for the number of elements we need\n",
    "            # full_subjects = pd.concat([subject_row]*len(df_data_aug), ignore_index=True)\n",
    "            #FIXME NEEDED?\n",
    "            # full_subjects = pd.DataFrame(full_subjects, columns=subjects_columns_title)\n",
    "\n",
    "            full_subjects = pd.concat([pd.DataFrame(subject_row).T]*len(df_data_aug), ignore_index=True)\n",
    "            df_data_aug = pd.concat([df_data_aug, full_subjects], axis=1)\n",
    "            #df_data_aug = pd.concat([df_data_aug, full_subjects], axis=1)\n",
    "\n",
    "            # Append the augmented dataframe to the original dataframe\n",
    "            tr = pd.concat([tr, df_data_aug], ignore_index=True)\n",
    "            print('After spk ', str(spk), ' tr shape is : ', tr.shape)\n",
    "#         tr.to_csv(\"mdl/tr_cis-pd_{0}_fold_{1}_lamb_{2}.csv\".format(obj, i, lambda_value), index=False)\n",
    "    # else:\n",
    "        # print(tr.keys())\n",
    "        # If we are using lambda data augmentation, these columns were already removed \n",
    "        # tr = tr.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "    print('obj is : ', obj)\n",
    "    train_y = tr[obj].astype(pd.np.float32) # training labels \n",
    "    train_weight = tr['spcount'] ** -0.5 # training weight\n",
    "    tr = tr.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "\n",
    "\n",
    "    ##te_w = all_features_labels[idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##te = pd.merge(all_features_labels[idx], te_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are used in the training of this fold, so we keep [idx] instead of [~idx]\n",
    "    te = all_features_labels[idx].drop(['fold_id'], axis=1)\n",
    "    # print('te !!! : ', te)\n",
    "\n",
    "#     print('te[spcount] : ', te['spcount'])\n",
    "    test_weight = te['spcount'] ** -0.5 # test weight \n",
    "#     print('test_weigth : ', test_weight)\n",
    "    test_y = te[obj].astype(pd.np.float32) # testing labels\n",
    "    sub = te['subject_id']\n",
    "    sid = te.subject_id\n",
    "    test_measurement_id = te.measurement_id\n",
    "    te = te.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "\n",
    "    if random_forest:\n",
    "        # Random Forest Regressor \n",
    "        print('Using Random Forest Regressor')\n",
    "        clf = RandomForestRegressor(**best_params)\n",
    "        clf.fit(tr, train_y, sample_weight=train_weight)\n",
    "    else:\n",
    "        # XGBoost \n",
    "        print('Using XGBOOST')\n",
    "        clf = xgb.XGBRegressor(**best_params)\n",
    "        #clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "        # Fit for the xgboost \n",
    "        clf.fit(\n",
    "            tr, train_y,\n",
    "            sample_weight=train_weight,\n",
    "            eval_set=[(tr, train_y), (te, test_y)],\n",
    "            #eval_metric=',\n",
    "            sample_weight_eval_set=[train_weight, test_weight],\n",
    "            verbose=0,\n",
    "            early_stopping_rounds=100\n",
    "        )\n",
    "#     print(' AVG !!! ')\n",
    "#     print(avg.keys())\n",
    "#     print(avg.sp_tremor)\n",
    "#     print('end avg')\n",
    "    pred = clf.predict(te).clip(0, 4)\n",
    "    # print('pred : ', pred)\n",
    "    mse = (pred - test_y) ** 2\n",
    "    #mse = test_y.to_numpy() ** 2\n",
    "    mse2 = test_y ** 2\n",
    "#     display(te)\n",
    "    ret = pd.concat([sub, mse], axis=1)\n",
    "#     display(ret)\n",
    "    #ret.to_csv('tmp.csv')\n",
    "    # Mean MSE Per subject ID \n",
    "#     print('ret.groupby(subject_id) : ', ret.groupby('subject_id'))\n",
    "#     display(ret.groupby('subject_id').sum()[obj])\n",
    "#     print(ret)\n",
    "    mse_marie = (ret.groupby('subject_id').sum())[obj].to_numpy()\n",
    "    \n",
    "    # Number of files per subject_id\n",
    "    cnt_marie = (ret.groupby('subject_id').count())[obj].to_numpy()\n",
    "    print('mse_marie : ', mse_marie)\n",
    "    print('cnt_marie : ', cnt_marie)\n",
    "#     cnt = cnt ** 0.5\n",
    "    msek_per_fold = (1/cnt_marie) * mse_marie\n",
    "    print('msek_per_fold : ', msek_per_fold)\n",
    "    \n",
    "    res = pd.DataFrame(data={'measurement_id': test_measurement_id, 'subject_id': sid, obj: pred})\n",
    "\n",
    "    # We merge the preds with the avg on subject_id, the goal is to keep as label the standardized one\n",
    "    res = pd.merge(res, avg, on='subject_id')\n",
    "    \n",
    "    # Add the sp_obj value to tremor \n",
    "    res[obj] += res['sp_' + obj]\n",
    "    # Res now only contains the measurement_id and the standardized label\n",
    "    res = res[[\"measurement_id\", obj]]\n",
    "\n",
    "    preds.append(res)\n",
    "\n",
    "    print('mse : ', mse)\n",
    "#     print('test_weigth : ', test_weight)\n",
    "#     print('before squeeze : ', ((mse * test_weight).sum() / test_weight.sum()))\n",
    "#     print('after squeeze : ', ((mse * test_weight).sum() / test_weight.sum()).squeeze())\n",
    "    results.append(((mse * test_weight).sum() / test_weight.sum()).squeeze())\n",
    "    baselines.append(((mse2 * test_weight).sum() / test_weight.sum()).squeeze())\n",
    "preds = pd.concat(preds)\n",
    "print('preds ', preds)\n",
    "    \n",
    "print('results : ', results)\n",
    "#     raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(preds)\n",
    "df_preds = pd.concat(preds)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = all_labels[[\"measurement_id\", obj, 'subject_id']]\n",
    "true_labels = true_labels.dropna(subset=[obj])\n",
    "true_labels = true_labels.rename(columns={obj: 'true_'+obj})\n",
    "preds_true_labels = pd.merge(df_preds, true_labels, on='measurement_id')\n",
    "# print(all_labels[['subject_id']])\n",
    "# preds_true_labels = pd.merge(preds_true_labels, all_labels[['subject_id']], on='measurement_id')\n",
    "display(preds_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spks = preds_true_labels['subject_id'].unique()\n",
    "print(all_spks)\n",
    "msek_subject = []\n",
    "for spk in all_spks: \n",
    "    spk_preds_true_label = preds_true_labels[preds_true_labels['subject_id'] == spk]\n",
    "    msek = ((spk_preds_true_label['true_'+obj] - spk_preds_true_label[obj]) ** 2).sum() * (1/len(spk_preds_true_label))\n",
    "    print(spk , ' : ', msek)\n",
    "    msek_subject.append(msek)\n",
    "\n",
    "print('msek mean')\n",
    "print(sum(msek_subject) / 13)\n",
    "display((pd.DataFrame(msek_subject)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msek_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true_labels.groupby('subject_id').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.isnull().sum())\n",
    "clf.fit(\n",
    "        tr, train_y,\n",
    "        sample_weight=train_weight,\n",
    "        eval_set=[(tr, train_y), (te, test_y)],\n",
    "        #eval_metric=',\n",
    "        sample_weight_eval_set=[train_weight, test_weight],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.describe())\n",
    "print(test_y.describe())\n",
    "tr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(te).clip(0, 4)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_value = 1\n",
    "\n",
    "all_spks = all_features_labels['subject_id'].unique()\n",
    "\n",
    "columns_to_exclude = (all_features_labels.columns[(all_features_labels.dtypes.values != np.dtype('float64'))]).to_list()\n",
    "columns_to_exclude.remove('fold_id')\n",
    "\n",
    "for i in range(5):\n",
    "    ##test = pd.read_csv(sys.argv[i]).squeeze()\n",
    "    ##idx = all_features_labels['measurement_id'].isin(test)\n",
    "\n",
    "    # Filter all_features_labels to only the measurements of the current fold\n",
    "    idx = all_features_labels['fold_id'] == i\n",
    "\n",
    "    ##tr_w = all_features_labels[~idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##tr = pd.merge(all_features_labels[~idx], tr_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are not from the current fold\n",
    "    tr = all_features_labels[~idx].drop(['fold_id'], axis=1)\n",
    "    \n",
    "        # Data augmentation with a lambda\n",
    "    if 5 == 6:\n",
    "        print('Loading model : ', \"mdl/tr_cis-pd_{0}_fold_{1}_lamb_{2}.csv\".format(obj, i, lambda_value))\n",
    "        if sys.argv[5] == \"load_mdl\":\n",
    "            tr = pd.read_csv(\"mdl/tr_cis-pd_{0}_fold_{1}_lamb_{2}.csv\".format(obj, i, lambda_value), index_col=[0])\n",
    "    elif lambda_value is not None:\n",
    "        for spk in all_spks: \n",
    "            # Filter training data for that speaker \n",
    "            tr_subject = tr.loc[tr['subject_id'] == spk]\n",
    "            \n",
    "            # FIXME: The mean number of recordings changes per fold so to make it easier \n",
    "            # I'm just gonna use the mean for the data augmented values\n",
    "            mean_spcount = int(tr_subject['spcount'].mean())\n",
    "            \n",
    "            \n",
    "            # Apply the lambda on the training features except the columns that are not float\n",
    "            modDfObj1 = tr_subject[tr_subject.columns.difference(columns_to_exclude)].apply(lambda x: x * lambda_value, axis=1, result_type='broadcast')\n",
    "            modDfObj2 = tr_subject[tr_subject.columns.difference(columns_to_exclude)].apply(lambda x: x * (1-lambda_value), axis=1, result_type='broadcast')\n",
    "            \n",
    "            df_data_aug = []\n",
    "            # First loop to go over the rows\n",
    "            for index, measurement1 in modDfObj1.iterrows():\n",
    "                # Second rows to go over the loop except the same two rows\n",
    "                for index2, measurement2 in modDfObj2.iterrows():\n",
    "                    if index >= index2:\n",
    "                        continue\n",
    "                    df_data_aug.append(measurement1.add(measurement2).to_list())\n",
    "            df_data_aug = pd.DataFrame(df_data_aug, columns=modDfObj1.columns)\n",
    "            \n",
    "            # Add again the columns we just removed \n",
    "            #modDfObj1 = pd.concat([modDfObj1, tr_subject[columns_to_exclude]], axis=1)\n",
    "            subjects_columns_title = [x for x in columns_to_exclude if x.startswith(\"spk_\")]\n",
    "            # Select the first row of spk_ elements \n",
    "            subject_row = tr_subject.iloc[0,tr_subject.columns.str.startswith(\"spk_\")]\n",
    "            subject_row = subject_row.append(pd.Series(mean_spcount, index=[\"spcount\"]))\n",
    "            \n",
    "            # Duplicate that first row for the number of elements we need\n",
    "            # full_subjects = pd.concat([subject_row]*len(df_data_aug), ignore_index=True)\n",
    "            #FIXME NEEDED?\n",
    "            # full_subjects = pd.DataFrame(full_subjects, columns=subjects_columns_title)\n",
    "\n",
    "            full_subjects = pd.concat([pd.DataFrame(subject_row).T]*len(df_data_aug), ignore_index=True)\n",
    "            \n",
    "            df_data_aug = pd.concat([df_data_aug, full_subjects], axis=1)\n",
    "            #df_data_aug = pd.concat([df_data_aug, full_subjects], axis=1)\n",
    "            \n",
    "            # Append the augmented dataframe to the original dataframe\n",
    "            tr = pd.concat([tr, df_data_aug], ignore_index=True)\n",
    "            \n",
    "            print('After spk ', str(spk), ' tr shape is : ', tr.shape)\n",
    "#             print(tr.isnull().sum())\n",
    "#             raise KeyboardInterrupt\n",
    "#         tr.to_csv(\"mdl/tr_cis-pd_{0}_fold_{1}_lamb_{2}.csv\".format(obj, i, lambda_value), index=False)\n",
    "    else:\n",
    "        # If we are using lambda data augmentation, these columns were already removed \n",
    "        tr = tr.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "\n",
    "    train_y = tr[obj].astype(pd.np.float32) # training labels \n",
    "    train_weight = tr['spcount'] ** -0.5 # training weight\n",
    "    tr = tr.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "    print('train_weight : ', train_weight)\n",
    "\n",
    "    ##te_w = all_features_labels[idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##te = pd.merge(all_features_labels[idx], te_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are used in the training of this fold, so we keep [idx] instead of [~idx]\n",
    "    te = all_features_labels[idx].drop(['fold_id'], axis=1)\n",
    "    print('te !!! : ', te)\n",
    "    test_weight = te['spcount'] ** -0.5 # test weight \n",
    "    test_y = te[obj].astype(pd.np.float32) # testing labels\n",
    "    #sub = te['subject_id']\n",
    "    sid = te.subject_id\n",
    "    test_measurement_id = te.measurement_id\n",
    "    te = te.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "\n",
    "    # XGBoost \n",
    "    clf = xgb.XGBRegressor(**best_params)\n",
    "    #clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # Random Forest Regressor \n",
    "    #clf = RandomForestRegressor(**best_params)\n",
    "    #clf.fit(tr, train_y, sample_weight=train_weight)\n",
    "\n",
    "    # Fit for the xgboost \n",
    "    clf.fit(\n",
    "        tr, train_y,\n",
    "        sample_weight=train_weight,\n",
    "        eval_set=[(tr, train_y), (te, test_y)],\n",
    "        #eval_metric=',\n",
    "        sample_weight_eval_set=[train_weight, test_weight],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    pred = clf.predict(te).clip(0, 4)\n",
    "    print('pred : ', pred)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_row.append(pd.Series(mean_spcount, index=[\"spcount\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.isnull().values.any()\n",
    "# tr.isnull().sum().to_string()\n",
    "# tr.isnull().sum().sum()\n",
    "print(te.isnull().T.any().T.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['spcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_weight.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf)\n",
    "for item in zip(feature_list_transform, xgb.feature_importances_):\n",
    "    print(\"{1:10.4f} - {0}\".format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = model.get_booster()\n",
    "dump = booster.get_dump()[0]\n",
    "assert not ('\\nnan\\n' in dump or '\\n-nan\\n' in dump or '\\ninf\\n' in dump or '\\n-inf\\n' in dump), \"Got non-finite weights from fit: %s\" % str(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_subject.iloc[0,tr_subject.columns.str.startswith(\"spk_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_aug_lambda(measurement1, measurement2, lambda_value):\n",
    "#     modDfObj1 = measurement1.apply(lambda x: x * lambda_value, axis=1)\n",
    "#     modDfObj2 = measurement2.apply(lambda x: x * (1-lambda_value), axis=1)\n",
    "#     mea_new = modDfObj1.add(modDfObj2)\n",
    "#     return mea_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug_lambda(modDfObj1, modDfObj2):\n",
    "    df_data_aug = []\n",
    "\n",
    "    # First loop to go over the rows\n",
    "    for index, measurement1 in modDfObj1.iterrows():\n",
    "        # Second rows to go over the loop except the same two rows\n",
    "        for index2, measurement2 in modDfObj2.iterrows():\n",
    "            if index >= index2:\n",
    "                continue\n",
    "            df_data_aug.append(measurement1.add(measurement2).to_list())\n",
    "    df_data_aug = pd.DataFrame(df_data_aug, columns=modDfObj1.columns)\n",
    "\n",
    "    \n",
    "    return df_data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut1 = pd.DataFrame([['a', 6, 4, 10, 2], ['a', 4, 10, 12, 4]], columns=['subject_id','X','Y','Z','label'])\n",
    "# salut2 = pd.DataFrame([[6, 4, 10, 2], [4, 10, 12, 4], [10, 8, 16, 22], [2, 10, 16, 20]])\n",
    "lambda_value = 0.5\n",
    "\n",
    "modDfObj1 = salut1[salut1.columns.difference(['subject_id'])].apply(lambda x: x * lambda_value, axis=1, result_type='broadcast')\n",
    "modDfObj2 = salut1[salut1.columns.difference(['subject_id'])].apply(lambda x: x * (1-lambda_value), axis=1, result_type='broadcast')\n",
    "display(salut1)\n",
    "display(salut2)\n",
    "display('modDfObj1 : ', modDfObj1)\n",
    "display('modDfObj2 : ', modDfObj2)\n",
    "df_data_aug2 = data_aug_lambda(modDfObj1, modDfObj2)\n",
    "display(df_data_aug2)\n",
    "# df_data_aug2 = pd.concat([df_data_aug2, salut1['subject']], axis=1)\n",
    "subjects_columns_title = [x for x in columns_to_exclude if x.startswith(\"spk_\")]\n",
    "\n",
    "# Select the first row of spk_ elements \n",
    "subjects = salut1.loc[0,salut1.columns.str.startswith(\"subject_id\")]\n",
    "\n",
    "# Duplicate that first row for the number of elements we need\n",
    "full_subjects = pd.concat([subjects]*len(df_data_aug2), ignore_index=True)\n",
    "full_subjects = pd.DataFrame(full_subjects)\n",
    "full_subjects.columns = ['subject_id']\n",
    "# Assign the column name \n",
    "display(full_subjects)\n",
    "print(df_data_aug2.keys())\n",
    "# Merge the data augmented with the spk information\n",
    "df_data_aug2 = pd.concat([df_data_aug2, full_subjects], axis=1)\n",
    "print(df_data_aug2.keys())\n",
    "print(df_data_aug2)\n",
    "result = pd.concat([salut1, df_data_aug2], ignore_index=True)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut1 = pd.DataFrame([['a', 6, 4, 10, 2], ['b', 4, 10, 12, 4], ['c', 10, 8, 16, 22], ['d',2, 10, 16, 20]], columns=['subject','1','2','3','4'])\n",
    "# salut2 = pd.DataFrame([[6, 4, 10, 2], [4, 10, 12, 4], [10, 8, 16, 22], [2, 10, 16, 20]])\n",
    "lambda_value = 0.5\n",
    "\n",
    "modDfObj1 = salut1[salut1.columns.difference(['subject'])].apply(lambda x: x * lambda_value, axis=1, result_type='broadcast')\n",
    "modDfObj2 = salut1[salut1.columns.difference(['subject'])].apply(lambda x: x * (1-lambda_value), axis=1, result_type='broadcast')\n",
    "display(salut1)\n",
    "display(salut2)\n",
    "display('modDfObj1 : ', modDfObj1)\n",
    "display('modDfObj2 : ', modDfObj2)\n",
    "df_data_aug2 = data_aug_lambda(modDfObj1, modDfObj2)\n",
    "display(df_data_aug2)\n",
    "# df_data_aug2 = pd.concat([df_data_aug2, salut1['subject']], axis=1)\n",
    "subjects_columns_title = [x for x in columns_to_exclude if x.startswith(\"spk_\")]\n",
    "\n",
    "# Select the first row of spk_ elements \n",
    "subjects = salut1.loc[0,salut1.columns.str.startswith(\"subject\")]\n",
    "\n",
    "# Duplicate that first row for the number of elements we need\n",
    "full_subjects = pd.concat([subjects]*len(df_data_aug2), ignore_index=True)\n",
    "full_subjects = pd.DataFrame(full_subjects)\n",
    "# full_subjects.columns = subjects_columns_title\n",
    "# Assign the column name \n",
    "display(full_subjects)\n",
    "print(df_data_aug2.keys())\n",
    "# Merge the data augmented with the spk information\n",
    "df_data_aug2 = pd.concat([df_data_aug2, full_subjects], axis=1)\n",
    "print(df_data_aug2.keys())\n",
    "print(df_data_aug2)\n",
    "result = pd.concat([modDfObj1, df_data_aug2], ignore_index=True)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_value = 0.3 \n",
    "\n",
    "for i in range(5):\n",
    "    ##test = pd.read_csv(sys.argv[i]).squeeze()\n",
    "    ##idx = all_features_labels['measurement_id'].isin(test)\n",
    "\n",
    "    # Filter all_features_labels to only the measurements of the current fold\n",
    "    idx = all_features_labels['fold_id'] == i\n",
    "\n",
    "    ##tr_w = all_features_labels[~idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##tr = pd.merge(all_features_labels[~idx], tr_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are not from the current fold \n",
    "    tr = all_features_labels[~idx].drop(['fold_id'], axis=1)\n",
    "    train_weight = tr['spcount'] ** -0.5 # training weight \n",
    "    print(tr)\n",
    "    # Data augmentation with a lambda \n",
    "    if lambda_value is not None: \n",
    "        df2 = df[tr.columns.difference(['subject_id', 'spcount'])]\n",
    "        df2 = df2.mul(lambda_value)\n",
    "        tr.append(tr.mul(lambda_value))\n",
    "        \n",
    "    train_y = tr[obj].astype(pd.np.float32) # training labels \n",
    "    tr = tr.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)\n",
    "\n",
    "    ##te_w = all_features_labels[idx].groupby('subject_id').count().reset_index()[[\"subject_id\", obj]].rename(columns={obj: 'spcount'})\n",
    "    ##te = pd.merge(all_features_labels[idx], te_w, on='subject_id')\n",
    "    \n",
    "    # Drop the measurements that are used in the training of this fold, so we keep [idx] instead of [~idx]\n",
    "    te = all_features_labels[idx].drop(['fold_id'], axis=1)\n",
    "    test_weight = te['spcount'] ** -0.5 # test weight \n",
    "    test_y = te[obj].astype(pd.np.float32) # testing labels\n",
    "    #sub = te['subject_id']\n",
    "    sid = te.subject_id\n",
    "    test_measurement_id = te.measurement_id\n",
    "    te = te.drop([obj, 'subject_id', 'measurement_id', 'spcount'], axis=1).astype(pd.np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64']\n",
    "\n",
    "newdf = tr.select_dtypes(include=numerics)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.keys().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.X2_abs_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.X_abs_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'subject_id':[1,2,3,4], 'spcount':[6,7,8,10], 'feat1':[5.6,2.4,6.7,4.5], 'label':[1.0,5.0,6.0,9.0]} \n",
    "\n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data, columns=['subject_id', 'spcount', 'feat1', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64']\n",
    "\n",
    "newdf = df.select_dtypes(include=numerics)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.columns.difference(['subject_id', 'spcount'])]\n",
    "\n",
    "print(df[['subject_id','spcount']])\n",
    "df2 = df2.mul(lambda_value)\n",
    "print(df2)\n",
    "\n",
    "result = pd.concat([df[['subject_id','spcount']], df2], axis=1, sort=False)\n",
    "display(result)\n",
    "# df3 = pd.merge(df[['subject_id','spcount']], df2)\n",
    "# df3\n",
    "#df.append(df.mul(0.5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allo = pd.concat([df, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeatPD",
   "language": "python",
   "name": "beatpd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
