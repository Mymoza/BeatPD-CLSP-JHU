{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission 2:\n",
    "    - Tremor : Gradient Boosting Regression\n",
    "    - Dyskinesia : Gradient Boosting Regression\n",
    "    \n",
    "Submission 4: \n",
    "    - Dyskinesia : Average of predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from random import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transform_data import *\n",
    "from create_graphs import *\n",
    "from beatPDivec.default_data.v2_auto.local.get_final_scores_accuracy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sDirOut = \"/export/b19/mpgill/BeatPD_predictions_tryingout\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 4 - Average of predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion(lFilesPred, sDirOut, fileName, bRound, sFileLabels, sTypeLabel):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "        # Read file labels (true labels)\n",
    "    print(\"sFileLabels : \", sFileLabels)\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dID = {rows[0]:rows[1] for rows in reader} #participant ID\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dOnOff= {rows[0]:rows[2] for rows in reader} #on-off label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dDys={rows[0]:rows[3] for rows in reader} #dyskinesia label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dTrem={rows[0]:rows[4] for rows in reader} #tremor label\n",
    "        \n",
    "    #label selection\n",
    "    if sTypeLabel=='on_off':\n",
    "        dLabels=dOnOff\n",
    "    elif sTypeLabel=='tremor':\n",
    "        dLabels=dTrem\n",
    "    elif sTypeLabel=='dyskinesia':\n",
    "        dLabels=dDys\n",
    "    else:\n",
    "        print('sTypeLabel undefined')\n",
    "        \n",
    "    iNumFiles=len(lFilesPred)\n",
    "    print('Number of analyzed file inputs: '+ str(iNumFiles))\n",
    "    #mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "    #mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    mPredictions=np.zeros((1,iNumFiles))\n",
    "    lID=[] # measurement_id \n",
    "    lDicts=[] \n",
    "    vLabels = [] # true label\n",
    "    vParID=[] # participant ID\n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            lID.append(k) # measurement_id \n",
    "            vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "            vParID.append(float(np.asarray(dID[k]))) #participant ID\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            # Go through the second and next predictions files\n",
    "            for j in range(1, iNumFiles):\n",
    "                # fPred will contain the prediction of the predictions file we're going through\n",
    "                fPred=lDicts[j].get(k)\n",
    "                if fPred: # if we found a prediction\n",
    "                    # we add it in the array\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "            if bEnter==1:\n",
    "                # if it's the first prediction file, we initialize it\n",
    "                mPredictions=vPredIter.copy() # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                # We add the new predictions as a new column if it's not the first file we're going through\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "\n",
    "#     print('mPredictions and vID')\n",
    "#     print(mPredictions.shape)\n",
    "#     print(len(lID))\n",
    "#     print(mPredictions)\n",
    "    vAverage=np.mean(mPredictions,axis=1)\n",
    "    if bRound==1:\n",
    "        vPrediction=np.round(vAverage)\n",
    "    else:\n",
    "        vPrediction=vAverage\n",
    "    \n",
    "    vRes1=mPredictions[:,[0]]\n",
    "    vRes2=mPredictions[:,[1]]\n",
    "          \n",
    "    # Random forest training - regression\n",
    "    #clf=RandomForestClassifier(n_estimators)\n",
    "    #clf = clf.fit(X, Y)\n",
    "    #clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "    lID, vPrediction=zip(*sorted(zip(lID, vPrediction)))\n",
    "    df = pd.DataFrame({'measurement_id': lID, sTypeLabel:vPrediction})\n",
    "    df.to_csv(sDirOut+'submissionCisPD'+sTypeLabel+'.csv', index=False)\n",
    "    \n",
    "    # we will include the testing data here\n",
    "    #print(mPredictions)\n",
    "#     print(len(vLabels))\n",
    "    return vRes1, vRes2, vAverage, vParID, vLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyskinesia - Submission 4 - Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sFileLabels :  /export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv\n",
      "Number of analyzed file inputs: 2\n",
      "--- MSEscore ---\n",
      "Final score :  0.4830357155225596\n",
      "Overall MSE Classif. 1 - tsfresh:  None\n",
      "--- MSEscore ---\n",
      "Final score :  0.5144468970875267\n",
      "Overall MSE Classif. 2 - ivec:  None\n",
      "--- MSEscore ---\n",
      "Final score :  0.48601343286255055\n",
      "Overall MSE Fusion - average :  None\n"
     ]
    }
   ],
   "source": [
    "# tsfresh predictions file on test kfolds \n",
    "#sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_dyskinesia.csv'\n",
    "# SVR predictions files on test kfolds \n",
    "#sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold_all/objs_500_kernel_linear_c_0.002_eps_0.1.csv'\n",
    "\n",
    "sFilePred1='/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/submission4_preds/kfold_prediction_dyskinesia.csv'\n",
    "sFilePred2='/export/b19/mpgill/kaldi/egs/beatPDivec/dysk_orig_auto60_400fl_scratch/exp/ivec_650/resiVecSVR_Fold/preds_per_patient.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2]\n",
    "\n",
    "# Path to labels on CIS-PD \n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "# Folder where we want to save the csv file with the average results \n",
    "dest_dir=sDirOut \n",
    "\n",
    "# Name of the CSV file to be created with the average \n",
    "fileName =\"dysk_test\"\n",
    "\n",
    "sTypeLabel = \"dyskinesia\"\n",
    "\n",
    "# Flag to round to the nearest integer or not \n",
    "# BUG, FIXME: It doesn't seem like this changes anything? \n",
    "bRound=0\n",
    "\n",
    "\n",
    "# Fusion with average of predictions get_final_score(vPredictions, vParID, vTrueLabels)\n",
    "vRes1, vRes2, vAverage, vParID, vLabels = average_fusion(lFilesPred, dest_dir, fileName, bRound, sFileLabels, sTypeLabel)\n",
    "\n",
    "print('Overall MSE Classif. 1 - tsfresh: ', get_final_score(vRes1, np.array(vParID).astype(int), vLabels))\n",
    "print('Overall MSE Classif. 2 - ivec: ', get_final_score(vRes2, vParID, vLabels))\n",
    "print('Overall MSE Fusion - average : ', get_final_score(vAverage, vParID, vLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sFileLabels :  /export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv\n",
      "Number of analyzed file inputs: 2\n",
      "--- MSEscore ---\n",
      "Final score :  0.4830357155225596\n",
      "Overall MSE Classif. 1 - tsfresh:  None\n",
      "--- MSEscore ---\n",
      "Final score :  0.4810183429568722\n",
      "Overall MSE Classif. 2 - ivec:  None\n",
      "--- MSEscore ---\n",
      "Final score :  0.4700143231441346\n",
      "Overall MSE Fusion - average :  None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tsfresh predictions file on test kfolds \n",
    "#sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_dyskinesia.csv'\n",
    "# SVR predictions files on test kfolds \n",
    "#sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold_all/objs_500_kernel_linear_c_0.002_eps_0.1.csv'\n",
    "\n",
    "sFilePred1='/home/mpgill/BeatPD/BeatPD-CLSP-JHU/tsfresh/submit/submission4_preds/kfold_prediction_dyskinesia.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/dysk_noinact_auto30/exp/ivec_650/resiVecPerPatientSVR_Fold_all_goodparams/preds_per_patient.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2]\n",
    "\n",
    "# Path to labels on CIS-PD \n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "# Folder where we want to save the csv file with the average results \n",
    "dest_dir=sDirOut \n",
    "\n",
    "# Name of the CSV file to be created with the average \n",
    "fileName =\"dysk_test\"\n",
    "\n",
    "sTypeLabel = \"dyskinesia\"\n",
    "\n",
    "# Flag to round to the nearest integer or not \n",
    "# BUG, FIXME: It doesn't seem like this changes anything? \n",
    "bRound=0\n",
    "\n",
    "\n",
    "# Fusion with average of predictions get_final_score(vPredictions, vParID, vTrueLabels)\n",
    "vRes1, vRes2, vAverage, vParID, vLabels = average_fusion(lFilesPred, dest_dir, fileName, bRound, sFileLabels, sTypeLabel)\n",
    "\n",
    "print('Overall MSE Classif. 1 - tsfresh: ', get_final_score(vRes1, np.array(vParID).astype(int), vLabels))\n",
    "print('Overall MSE Classif. 2 - ivec: ', get_final_score(vRes2, vParID, vLabels))\n",
    "print('Overall MSE Fusion - average : ', get_final_score(vAverage, vParID, vLabels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 2 - Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the following code was used in the second submission, but I didn't take the time on making it clear and pretty since it's not in our final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(lFilesPred, sFileLabels, sTypeLabel):\n",
    "    \"\"\"\n",
    "    TODO \n",
    "    \n",
    "    Keyword Arguments: \n",
    "    - lFilesPred: \n",
    "    - sFileLabels: \n",
    "    - sTypeLabels: \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    print(\"sFileLabels : \", sFileLabels)\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dID = {rows[0]:rows[1] for rows in reader} #participant ID\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dOnOff= {rows[0]:rows[2] for rows in reader} #on-off label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dDys={rows[0]:rows[3] for rows in reader} #dyskinesia label\n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dTrem={rows[0]:rows[4] for rows in reader} #tremor label\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFiles=len(lFilesPred)\n",
    "    #mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "    #mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    vParID=[] # participant ID\n",
    "    lDicts=[] \n",
    "\n",
    "\n",
    "    # We loop over the predictions files from the tsfresh and SVR\n",
    "    # lDicts is a list of measurement_id and the predictions obtained \n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (ivec-svr, boost...)\n",
    "        lDicts.append(dPred)\n",
    "    print('sTypeLabel : ', sTypeLabel)\n",
    "    #label selection\n",
    "    if sTypeLabel=='on_off':\n",
    "        dLabels=dOnOff\n",
    "    elif sTypeLabel=='tremor':\n",
    "        dLabels=dTrem\n",
    "    elif sTypeLabel=='dyskinesia':\n",
    "        dLabels=dDys\n",
    "    else:\n",
    "        print('sTypeLabel undefined')\n",
    "    \n",
    "    print('dLabels')\n",
    "    print(dLabels)\n",
    "    \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "                vParID.append(float(np.asarray(dID[k]))) #participant ID\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    print('mPredictions and vLabels')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(vLabels))\n",
    "    # Random forest training - regression\n",
    "    \n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "    return mPredictions, vLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_fusion(lFilesPred, sFileLabels, iEstimators, sTypeLabel, nudge, rLR, iMD,iRS):\n",
    "\n",
    "    mPredictions, vLabels = read_files(lFilesPred, sFileLabels, sTypeLabel)\n",
    "    \n",
    "    clf=GradientBoostingRegressor(n_estimators=iEstimators, learning_rate=rLR, max_depth=iMD,\\\n",
    "                                      random_state=iRS, loss='ls').fit(mPredictions, vLabels)\n",
    "    vNewPred=clf.predict(mPredictions)\n",
    "    vRes1=mPredictions[:,[0]]\n",
    "    vRes2=mPredictions[:,[1]]\n",
    "    \n",
    "    # we will include the testing data here\n",
    "    return (vNewPred, vParID, vLabels, vRes1, vRes2, clf)\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest_predTest(lTestPred, clf, sDirOut,sName):\n",
    "    \n",
    "    lDicts=[] #Will contain the two test predictions\n",
    "    lmesID=[]\n",
    "    iNumFiles=len(lTestPred)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "\n",
    "    for sFilePred in lTestPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (ivec-svr, boost...)\n",
    "        lDicts.append(dPred)\n",
    "      \n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            lmesID.append(k)\n",
    "            #vParID.append(float(np.asarray(dID[k]))) #participant ID\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            for j in range(1, iNumFiles):\n",
    "                fPred=lDicts[j].get(k)\n",
    "            if fPred:\n",
    "                vPredIter[0,j]=float(np.asarray(fPred))\n",
    "            else:\n",
    "                print(['Unkwnown key:' + k])\n",
    "                vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "\n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    \n",
    "    vTestPred=clf.predict(mPredictions)\n",
    "    df = pd.DataFrame({'measurement_id': lmesID, sName:vTestPred})\n",
    "    df.to_csv(sDirOut+'submissionCisPD'+sName+'.csv', index=False)\n",
    "    return(lmesID, vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyskinesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sFilePred1='/export/b15/nchen/BeatPD/cispd.kfold_prediction_on_off.csv'\n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sFilePred2='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sTypeLabel='on_off'\n",
    "n_estimators=300\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=15\n",
    "nudge=100\n",
    "sFileLabels=sFilePred1\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1,\\\n",
    "vRes2, clf = RandomForest_fusion (lFilesPred, sFileLabels, n_estimators, sTypeLabel, nudge, rLR, iMD,iRS)\n",
    "\n",
    "print('Overall MSE Classif. 1 : ', get_final_score(vTrueLabels,np.array(vParID).astype(int), vRes1))\n",
    "print('Overall MSE Classif. 2 : ', get_final_score(vTrueLabels, vParID, vRes2))\n",
    "print('Overall MSE Fusion : ', get_final_score(vPredCross, vParIDCross,vTrueCross))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/new_features/submission/cis-pd.dyskinesia.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30/exp/ivec_450/resiVecSVR_Fold/On_off_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/'\n",
    "sName='on_off'\n",
    "#lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "#print(vTestPred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tremor - Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsfresh predictions file \n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_tremor.csv'\n",
    "\n",
    "# SVR predictions file \n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_450/resiVecSVR_Fold_all/objs_450_kernel_linear_c_0.02_eps_0.1.csv'\n",
    "\n",
    "# subchallenge \n",
    "sTypeLabel='tremor'\n",
    "\n",
    "# RandomForest hyperparameter \n",
    "n_estimators=5\n",
    "\n",
    "# Labels\n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1, vRes2, clf = RandomForest_fusion(lFilesPred,\n",
    "                                                                           sFileLabels,\n",
    "                                                                           n_estimators,\n",
    "                                                                           sTypeLabel)\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/submission/cis-pd.tremor.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_450/resiVecSVR_Fold/Tremor_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/submissionFiles/'\n",
    "sName='tremor'\n",
    "lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "print(vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyskinesia - Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sFilePred1='/export/b15/nchen/BeatPD/cispd.kfold_prediction_dyskinesia.csv'\n",
    "sFilePred1='/export/b15/nchen/BeatPD/new_features/kfold_prediction_dyskinesia.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold_all/objs_500_kernel_linear_c_0.002_eps_0.1.csv'\n",
    "sTypeLabel='dyskinesia'\n",
    "n_estimators=5\n",
    "sFileLabels='/export/b18/sjoshi/BeatPD/data/BeatPD/cis-pd.data_labels/CIS-PD_Training_Data_IDs_Labels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "vPredictions, vParID, vTrueLabels, vRes1, vRes2, clf = RandomForest_fusion (lFilesPred, sFileLabels, n_estimators, sTypeLabel)\n",
    "\n",
    "sTestPred1='/export/b15/nchen/BeatPD/submission/cis-pd.dyskinesia.csv'\n",
    "sTestPred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold/Dyskinesia_testing.csv'\n",
    "lTestPred=[sTestPred1,sTestPred2]\n",
    "\n",
    "sDirOut='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/submissionFiles/'\n",
    "sName='z_dyskinesia'\n",
    "lmesID, vTestPred = randomForest_predTest(lTestPred, clf, sDirOut, sName)\n",
    "print(vTestPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
