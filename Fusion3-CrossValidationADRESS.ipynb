{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from random import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_score(mse_per_subjectid, nb_files_per_subject_id, training_or_test=''):\n",
    "    \"\"\"\n",
    "    Compute the final score for the challenge given the arguments \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - mse_per_subjectid: list of the mse per subject_id \n",
    "    - nb_files_per_subject_id: list of the number of files per subject_id \n",
    "    - training_or_test: string just for the purpose of printing the result \n",
    "    \"\"\"\n",
    "    numerator = np.sum([nb_file * mse for nb_file, mse in zip(np.sqrt(nb_files_per_subject_id), mse_per_subjectid)])\n",
    "    denominator = np.sum(np.sqrt(nb_files_per_subject_id))\n",
    "    #FIXME : Refactor so it's not printing by default \n",
    "    print(training_or_test+'Final score : ', np.divide(numerator, denominator))\n",
    "    return np.divide(numerator, denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_score(vPredictions, vParID, vTrueLabels):\n",
    "    \"\"\"\n",
    "    Compute the final score from the challenge and print the result\n",
    "    Keyword arguments: \n",
    "    - vPredictions: Numpy array containing the predictions \n",
    "    - VParID: list containing the subject_id \n",
    "    - vTrueLabels: list containing the true labels \n",
    "    \"\"\"\n",
    "    mse_per_subjectId = []\n",
    "    nb_files_per_subjectId = []\n",
    "    for subject_id in np.unique(vParID):\n",
    "        #print('--- SUBJECT ID ', subject_id, '---')\n",
    "        vSubjectId = (vParID == subject_id)\n",
    "        #print(vSubjectId)\n",
    "        vPredictions_subjectId = vPredictions[vSubjectId]\n",
    "        vTrueLabels_subjectId = np.array(vTrueLabels)[vSubjectId]\n",
    "        mse_per_subjectId.append(mean_squared_error(vTrueLabels_subjectId, vPredictions_subjectId))\n",
    "        nb_files_per_subjectId.append(len(vPredictions_subjectId))\n",
    "        #print('MSE : ', mean_squared_error(vTrueLabels_subjectId, vPredictions_subjectId))\n",
    "    print('--- MSEscore ---')\n",
    "    final_score(mse_per_subjectId, nb_files_per_subjectId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_fusion_Cross (lFilesPred, sFileLabels, iEstimators, nudge, rLR, iMD,iRS):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    \n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dLabels= {rows[0]:rows[1] for rows in reader} #participantID:label\n",
    "    #print('thisis dLabels-------')\n",
    "    #print(dLabels)\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFiles=len(lFilesPred)\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    lDicts=[] \n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                #print(vPredIter)\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    print('mPredictions and vLabels')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(vLabels))\n",
    "    \n",
    "    vRes1=np.transpose(mPredictions[:,[0]])\n",
    "    vRes2=np.transpose(mPredictions[:,[1]])\n",
    " \n",
    "    # Random forest training - regression\n",
    "    \n",
    "    \n",
    "#clf=RandomForestClassifier(n_estimators)\n",
    "#clf = clf.fit(X, Y)\n",
    "#clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "\n",
    "    \n",
    "    vIndex=np.arange(0, len(vLabels)-1, nudge).tolist()\n",
    "    vPredCross=[];\n",
    "    vTrueCross=[];\n",
    "    \n",
    "    for ind in range(len(vIndex)-1):\n",
    "        #print('New iteration:')\n",
    "        #print(ind)\n",
    "        mPredAux=np.delete(mPredictions, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        vLabelsAux=np.delete(vLabels, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        mPredTest=mPredictions[vIndex[ind]:vIndex[ind+1],:]\n",
    "        clf=GradientBoostingRegressor(n_estimators=iEstimators, learning_rate=rLR, max_depth=iMD,\\\n",
    "                                      random_state=iRS, loss='ls').fit(mPredAux, vLabelsAux)\n",
    "        vLabelSel=vLabels[vIndex[ind]:vIndex[ind+1]] # Contains the selected labels\n",
    "        vNewPred=clf.predict(mPredTest)\n",
    "        vPredCross.extend(vNewPred)\n",
    "        vTrueCross.extend(vLabelSel)\n",
    "        #print(len(vNewPred))\n",
    "        #print(len(vLabelsAux))\n",
    "    \n",
    "   \n",
    "    # we will include the testing data here\n",
    "    return (np.array(vPredCross), np.array(vTrueCross), np.array(vLabels), vRes1, vRes2)\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion_cross(lFilesPred, sFileLabels, nudge, bRound):\n",
    "    \n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dLabels= {rows[0]:rows[1] for rows in reader} #participantID:label\n",
    "    #print('thisis dLabels-------')\n",
    "    #print(dLabels)\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFiles=len(lFilesPred)\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    lDicts=[] \n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                #print(vPredIter)\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    print('mPredictions and vLabels')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(vLabels))\n",
    "    if bRound==1:\n",
    "        mPredictions=np.round(mPredictions)\n",
    "        \n",
    "    \n",
    "    vRes1=np.transpose(mPredictions[:,[0]])\n",
    "    vRes2=np.transpose(mPredictions[:,[1]])\n",
    " \n",
    "    # Random forest training - regression\n",
    "    \n",
    "    \n",
    "#clf=RandomForestClassifier(n_estimators)\n",
    "#clf = clf.fit(X, Y)\n",
    "#clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "\n",
    "    \n",
    "    vIndex=np.arange(0, len(vLabels)-1, nudge).tolist()\n",
    "    vPredCross=[];\n",
    "    vTrueCross=[];\n",
    "    \n",
    "    for ind in range(len(vIndex)-1):\n",
    "        #print('New iteration:')\n",
    "        #print(ind)\n",
    "        mPredAux=np.delete(mPredictions, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        vLabelsAux=np.delete(vLabels, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        mPredTest=mPredictions[vIndex[ind]:vIndex[ind+1],:]\n",
    "        vLabelSel=vLabels[vIndex[ind]:vIndex[ind+1]] # Contains the selected labels\n",
    "        vNewPred=np.mean(mPredTest, axis=1)\n",
    "        vPredCross.extend(vNewPred)\n",
    "        vTrueCross.extend(vLabelSel)\n",
    "        #print(len(vNewPred))\n",
    "        #print(len(vLabelsAux))\n",
    "    \n",
    "   \n",
    "    # we will include the testing data here\n",
    "    return (np.array(vPredCross), np.array(vTrueCross), np.array(vLabels), vRes1, vRes2)\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion_cross_2(lFilesPred, sFileLabels, nudge, bRound):\n",
    "    \n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dLabels= {rows[0]:rows[1] for rows in reader} #participantID:label\n",
    "    #print('thisis dLabels-------')\n",
    "    #print(dLabels)\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFiles=len(lFilesPred)\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    lDicts=[] \n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels.append(float(np.asarray(dLabels[k]))) #true labels\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                #print(vPredIter)\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=30*float(np.asarray(fPred)) \n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    print('mPredictions and vLabels')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(vLabels))\n",
    "    if bRound==1:\n",
    "        mPredictions=np.round(mPredictions)\n",
    "        \n",
    "    \n",
    "    vRes1=np.transpose(mPredictions[:,[0]])\n",
    "    vRes2=np.transpose(mPredictions[:,[1]])\n",
    " \n",
    "    # Random forest training - regression\n",
    "    \n",
    "    \n",
    "#clf=RandomForestClassifier(n_estimators)\n",
    "#clf = clf.fit(X, Y)\n",
    "#clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "\n",
    "    \n",
    "    vIndex=np.arange(0, len(vLabels)-1, nudge).tolist()\n",
    "    vPredCross=[];\n",
    "    vTrueCross=[];\n",
    "    \n",
    "    for ind in range(len(vIndex)-1):\n",
    "        #print('New iteration:')\n",
    "        #print(ind)\n",
    "        mPredAux=np.delete(mPredictions, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        vLabelsAux=np.delete(vLabels, slice(vIndex[ind], vIndex[ind+1]),axis=0)\n",
    "        mPredTest=mPredictions[vIndex[ind]:vIndex[ind+1],:]\n",
    "        vLabelSel=vLabels[vIndex[ind]:vIndex[ind+1]] # Contains the selected labels\n",
    "        vNewPred=np.mean(mPredTest, axis=1)\n",
    "        vPredCross.extend(vNewPred)\n",
    "        vTrueCross.extend(vLabelSel)\n",
    "        #print(len(vNewPred))\n",
    "        #print(len(vLabelsAux))\n",
    "    \n",
    "   \n",
    "    # we will include the testing data here\n",
    "    return (np.array(vPredCross), np.array(vTrueCross), np.array(vLabels), vRes1, vRes2)\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion (lFilesPred, dest_dir, fileName, bRound):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    \n",
    "    iNumFiles=len(lFilesPred)\n",
    "    print('Number of analyzed file inputs: '+ str(iNumFiles))\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    lID=[] #true label\n",
    "    lDicts=[] \n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            lID.append(k)\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            #print(vPredIter)\n",
    "            for j in range(1, iNumFiles):\n",
    "                fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "\n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "\n",
    "    print('mPredictions and vID')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(lID))\n",
    "    print(mPredictions)\n",
    "    vAverage=np.mean(mPredictions,axis=1)\n",
    "    if bRound==1:\n",
    "        vPrediction=np.round(vAverage)\n",
    "    else:\n",
    "        vPrediction=vAverage\n",
    "    \n",
    "    \n",
    "          \n",
    "    # Random forest training - regression\n",
    "    \n",
    "    \n",
    "#clf=RandomForestClassifier(n_estimators)\n",
    "#clf = clf.fit(X, Y)\n",
    "#clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "    lID, vPrediction=zip(*sorted(zip(lID, vPrediction)))\n",
    "    df = pd.DataFrame({'ID': lID, 'Prediction':vPrediction})\n",
    "    np.savetxt(dest_dir+fileName+'.txt', df.values, fmt='%s', delimiter=' ; ')\n",
    "   \n",
    "   \n",
    "    # we will include the testing data here\n",
    "    \n",
    "#print(mPredictions)\n",
    "    return vAverage, lID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion_tocsv (lFilesPred, dest_dir, fileName, bRound):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    \n",
    "    iNumFiles=len(lFilesPred)\n",
    "    print('Number of analyzed file inputs: '+ str(iNumFiles))\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    lID=[] #true label\n",
    "    lDicts=[] \n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            lID.append(k)\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            #print(vPredIter)\n",
    "            for j in range(1, iNumFiles):\n",
    "                fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "\n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "\n",
    "    print('mPredictions and vID')\n",
    "    print(mPredictions.shape)\n",
    "    print(len(lID))\n",
    "    print(mPredictions)\n",
    "    vAverage=np.mean(mPredictions,axis=1)\n",
    "    if bRound==1:\n",
    "        vPrediction=np.round(vAverage)\n",
    "        vPrediction=vPrediction.clip(min=0)\n",
    "    else:\n",
    "        vPrediction=vAverage*30\n",
    "    \n",
    "    lID, vPrediction=zip(*sorted(zip(lID, vPrediction)))\n",
    "          \n",
    "    # Random forest training - regression\n",
    "    \n",
    "    \n",
    "#clf=RandomForestClassifier(n_estimators)\n",
    "#clf = clf.fit(X, Y)\n",
    "#clf.score(X_test, y_test)\n",
    "\n",
    "    #scores = cross_val_score(clf, mPredictions, vLabels, cv=15)\n",
    "    #print('Cross-validation score:')\n",
    "    #print(scores.mean())\n",
    "\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame({'measurement_id': lID, 'prediction':vPrediction})\n",
    "    df.to_csv(dest_dir+fileName+'.csv', index=False)\n",
    "    print(dest_dir+fileName+'.csv')\n",
    "   \n",
    "    # we will include the testing data here\n",
    "    \n",
    "#print(mPredictions)\n",
    "    return vAverage, lID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateaccu(vPred, vTrue):\n",
    "\n",
    "    accu=1-np.mean(np.absolute(np.round(vPred)-vTrue))\n",
    "    print('Accuracy: ' + str(accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMSE(vPred,vTrue):\n",
    "    MSE=math.sqrt(np.mean(np.square(vPred-vTrue)))\n",
    "    print('MSE:'+str(MSE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "Global: \n",
      "Accuracy: 0.7924528301886793\n",
      "Acoustic model: \n",
      "Accuracy: 0.6388888888888888\n",
      "NLP model: \n",
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Using Raghu's acoustic features - DETECTION\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "RandomForest_fusion_Cross (lFilesPred, sFileLabels, iEstimators, nudge, rLR, iMD,iRS)\n",
    "\n",
    "print('Global: ')\n",
    "calculateaccu(vPredCross, vTrueCross)\n",
    "print('Acoustic model: ')\n",
    "calculateaccu(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateaccu(vRes2, vLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "Global: \n",
      "Accuracy: 0.7641509433962264\n",
      "Acoustic model: \n",
      "Accuracy: 0.7314814814814814\n",
      "NLP model: \n",
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Using xvector-plda acoustic features -DETECTION\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/objs_35_.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "RandomForest_fusion_Cross (lFilesPred, sFileLabels, iEstimators, nudge, rLR, iMD,iRS)\n",
    "\n",
    "print('Global: ')\n",
    "calculateaccu(vPredCross, vTrueCross)\n",
    "\n",
    "print('Acoustic model: ')\n",
    "calculateaccu(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateaccu(vRes2, vLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(107, 2)\n",
      "107\n",
      "Global: \n",
      "MSE:6.356175549296717\n",
      "Acoustic model: \n",
      "MSE:6.296548828856566\n",
      "NLP model: \n",
      "MSE:6.521458232233364\n"
     ]
    }
   ],
   "source": [
    "# Using xvector-plda acoustic features - MMSE\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/MMSE_crossValidation.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertMMSE_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueMSE.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "RandomForest_fusion_Cross (lFilesPred, sFileLabels, iEstimators, nudge, rLR, iMD,iRS)\n",
    "\n",
    "print('Global: ')\n",
    "calculateMSE(vPredCross, vTrueCross)\n",
    "\n",
    "print('Acoustic model: ')\n",
    "calculateMSE(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateMSE(30*vRes2, vLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderFiles(lDicts,dLabels, iNumFiles):\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vLabels=[] #true label\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "            if dLabels[k]!='NA':\n",
    "                vLabels=np.append(vLabels,float(np.asarray(dLabels[k]))) #true labels\n",
    "                vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "                #print(vPredIter)\n",
    "                for j in range(1, iNumFiles):\n",
    "                    fPred=lDicts[j].get(k)\n",
    "                if fPred:\n",
    "                    vPredIter[0,j]=float(np.asarray(fPred))\n",
    "                else:\n",
    "                    print(['Unkwnown key:' + k])\n",
    "                    vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "                    \n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    return mPredictions, vLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_fusion_Cross_perfold (lFilesTrai,lFilesPred, sFileLabels, iEstimators, rLR, iMD,iRS):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    \n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dLabels= {rows[0]:rows[1] for rows in reader} #participantID:label\n",
    "    #print('thisis dLabels-------')\n",
    "    #print(dLabels)\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFilesTest=len(lFilesPred)\n",
    "    iNumFilesTrai=len(lFilesTrai)\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    lDicts=[] \n",
    "    lDictsTrai=[]\n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "        \n",
    "    for sFileTrai in lFilesTrai:\n",
    "        with open(sFileTrai, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dTrai = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDictsTrai.append(dTrai)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "\n",
    "    mTrain, vLTrai=orderFiles(lDictsTrai, dLabels, iNumFilesTrai)\n",
    "    mTest, vLTest=orderFiles(lDicts, dLabels, iNumFilesTest)\n",
    "    \n",
    "    print('mTrain and vLabels')\n",
    "    print(mTrain.shape)\n",
    "    print(len(vLTrai))\n",
    "    \n",
    "    vRes1=np.transpose(mTest[:,[0]])\n",
    "    vRes2=np.transpose(mTest[:,[1]])\n",
    " \n",
    "    # Random forest training - regression\n",
    "    \n",
    "\n",
    "    clf=GradientBoostingRegressor(n_estimators=iEstimators, learning_rate=rLR, max_depth=iMD,\\\n",
    "                                  random_state=iRS, loss='ls').fit(mTrain, vLTrai)\n",
    "    \n",
    "    vNewPred=clf.predict(mTest)\n",
    "\n",
    "   \n",
    "    # we will include the testing data here\n",
    "    return (np.array(vNewPred), np.array(vLTest), np.array(vRes1), np.array(vRes2))\n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion per fold DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 1\n",
      "Global: \n",
      "Accuracy: 0.4545454545454546\n",
      "Acoustic model: \n",
      "Accuracy: 0.4545454545454546\n",
      "NLP model: \n",
      "Accuracy: 0.6363636363636364\n",
      "mTrain and vLabels\n",
      "(87, 2)\n",
      "87\n",
      "Fold: 2\n",
      "Global: \n",
      "Accuracy: 0.6363636363636364\n",
      "Acoustic model: \n",
      "Accuracy: 0.6363636363636364\n",
      "NLP model: \n",
      "Accuracy: 0.8181818181818181\n",
      "mTrain and vLabels\n",
      "(87, 2)\n",
      "87\n",
      "Fold: 3\n",
      "Global: \n",
      "Accuracy: 0.8\n",
      "Acoustic model: \n",
      "Accuracy: 0.6\n",
      "NLP model: \n",
      "Accuracy: 0.8\n",
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 4\n",
      "Global: \n",
      "Accuracy: 0.7272727272727273\n",
      "Acoustic model: \n",
      "Accuracy: 0.6363636363636364\n",
      "NLP model: \n",
      "Accuracy: 0.9090909090909091\n",
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 5\n",
      "Global: \n",
      "Accuracy: 0.8181818181818181\n",
      "Acoustic model: \n",
      "Accuracy: 0.6363636363636364\n",
      "NLP model: \n",
      "Accuracy: 0.8181818181818181\n",
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 6\n",
      "Global: \n",
      "Accuracy: 0.7272727272727273\n",
      "Acoustic model: \n",
      "Accuracy: 0.8181818181818181\n",
      "NLP model: \n",
      "Accuracy: 0.6363636363636364\n",
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 7\n",
      "Global: \n",
      "Accuracy: 0.6363636363636364\n",
      "Acoustic model: \n",
      "Accuracy: 0.6363636363636364\n",
      "NLP model: \n",
      "Accuracy: 0.5454545454545454\n",
      "mTrain and vLabels\n",
      "(86, 2)\n",
      "86\n",
      "Fold: 8\n",
      "Global: \n",
      "Accuracy: 0.9090909090909091\n",
      "Acoustic model: \n",
      "Accuracy: 0.4545454545454546\n",
      "NLP model: \n",
      "Accuracy: 0.9090909090909091\n",
      "mTrain and vLabels\n",
      "(87, 2)\n",
      "87\n",
      "Fold: 9\n",
      "Global: \n",
      "Accuracy: 0.7272727272727273\n",
      "Acoustic model: \n",
      "Accuracy: 0.6363636363636364\n",
      "NLP model: \n",
      "Accuracy: 0.7272727272727273\n",
      "mTrain and vLabels\n",
      "(87, 2)\n",
      "87\n",
      "Fold: 10\n",
      "Global: \n",
      "Accuracy: 0.7\n",
      "Acoustic model: \n",
      "Accuracy: 0.6\n",
      "NLP model: \n",
      "Accuracy: 0.7\n",
      "GLOBAL RESULTS:\n",
      "Global: \n",
      "Accuracy: 0.712962962962963\n",
      "Acoustic model: \n",
      "Accuracy: 0.6111111111111112\n",
      "NLP model: \n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Using xvector-finetuned acoustic features +BERT - Detection\n",
    "\n",
    "sFileTrai1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores_crossvalperfoldTrainfold_'\n",
    "sFileTest1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores_crossvalperfoldTestfold_'\n",
    "\n",
    "sFileTrai2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossvalperfoldTrainfold_'\n",
    "sFileTest2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossvalperfoldDevfold_'\n",
    "\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "vGlobalLabels=[]\n",
    "vGlobalPreds=[]\n",
    "\n",
    "vGlobalPreds1=[]\n",
    "\n",
    "vGlobalPreds2=[]\n",
    "\n",
    "for fold in range(1,11):\n",
    "    lFilesTrai=[sFileTrai1+str(fold)+'.csv',sFileTrai2+str(fold)+'.csv']\n",
    "    lFilesTest=[sFileTest1+str(fold)+'.csv',sFileTest2+str(fold)+'.csv']\n",
    "\n",
    "    iEstimators=900\n",
    "    rLR=0.1\n",
    "    iMD=1\n",
    "    iRS=0\n",
    "\n",
    "    vPred, vLabels, vRes1, vRes2=\\\n",
    "    RandomForest_fusion_Cross_perfold (lFilesTrai,lFilesTest, sFileLabels, iEstimators, rLR, iMD,iRS)\n",
    "    \n",
    "    vGlobalPreds.extend(vPred)\n",
    "    vGlobalLabels.extend(vLabels)\n",
    "    \n",
    "    vGlobalPreds1.extend(np.array(vRes1))\n",
    "    vGlobalPreds2.extend(np.array(vRes2))\n",
    "    \n",
    "    print('Fold: '+str(fold))\n",
    "    print('Global: ')\n",
    "    calculateaccu(vPred, vLabels)\n",
    "\n",
    "    print('Acoustic model: ')\n",
    "    calculateaccu(vRes1, vLabels)\n",
    "\n",
    "    print('NLP model: ')\n",
    "    calculateaccu(vRes2, vLabels)\n",
    "    \n",
    "    \n",
    "print('GLOBAL RESULTS:')\n",
    "print('Global: ')\n",
    "calculateaccu(np.array(vGlobalPreds), np.array(vGlobalLabels))\n",
    "\n",
    "print('Acoustic model: ')\n",
    "calculateaccu(np.hstack(vGlobalPreds1), np.array(vGlobalLabels))\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateaccu(np.hstack(vGlobalPreds2), np.array(vGlobalLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "Global: \n",
      "Accuracy: 0.7452830188679245\n",
      "Acoustic model: \n",
      "Accuracy: 0.6388888888888888\n",
      "NLP model: \n",
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Using Raghu's acoustic features - Detection\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores_crossval.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "average_fusion_cross(lFilesPred, sFileLabels, nudge,0)\n",
    "\n",
    "print('Global: ')\n",
    "calculateaccu(vPredCross, vTrueCross)\n",
    "print('Acoustic model: ')\n",
    "calculateaccu(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateaccu(vRes2, vLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "Global: \n",
      "Accuracy: 0.7169811320754718\n",
      "Acoustic model: \n",
      "Accuracy: 0.7314814814814814\n",
      "NLP model: \n",
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Using xVectors-PLDA - Detection\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/kFoldsResults_detection.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "average_fusion_cross(lFilesPred, sFileLabels, nudge,1)\n",
    "\n",
    "print('Global: ')\n",
    "calculateaccu(vPredCross, vTrueCross)\n",
    "print('Acoustic model: ')\n",
    "calculateaccu(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateaccu(vRes2, vLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPredictions and vLabels\n",
      "(107, 2)\n",
      "107\n",
      "Global: \n",
      "MSE:5.930824005894585\n",
      "Acoustic model: \n",
      "MSE:6.296548828856566\n",
      "NLP model: \n",
      "MSE:6.521458232233364\n"
     ]
    }
   ],
   "source": [
    "# Using xVectors-PLDA MMSE\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/MMSE_crossValidation.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertMMSE_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueMSE.csv'\n",
    "\n",
    "lFilesPred=[sFilePred1,sFilePred2];\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPredCross, vTrueCross, vLabels, vRes1, vRes2=\\\n",
    "average_fusion_cross_2(lFilesPred, sFileLabels, nudge,0) # This function multiplies sFIlePred2 x 30\n",
    "\n",
    "print('Global: ')\n",
    "calculateMSE(vPredCross, vTrueCross)\n",
    "\n",
    "print('Acoustic model: ')\n",
    "calculateMSE(vRes1, vLabels)\n",
    "\n",
    "print('NLP model: ')\n",
    "calculateMSE(vRes2, vLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 10\n",
      "mPredictions and vID\n",
      "(48, 10)\n",
      "48\n",
      "[[0.72559565 0.28560138 0.06513522 0.1651601  0.07015276 0.03334882\n",
      "  0.03571316 0.04052589 0.02987922 0.08371879]\n",
      " [0.72559565 0.28560138 0.06513522 0.1651601  0.07015276 0.03334882\n",
      "  0.03571316 0.04052589 0.02987922 0.08371879]\n",
      " [0.79538405 0.8518368  0.94358134 0.93523407 0.89284587 0.86066794\n",
      "  0.88467431 0.87550122 0.74595386 0.77696401]\n",
      " [0.79469365 0.86883652 0.57957286 0.68774277 0.13125151 0.03630467\n",
      "  0.70297796 0.20872954 0.58943719 0.90434134]\n",
      " [0.80023128 0.86913019 0.94007659 0.93650758 0.89865911 0.0793495\n",
      "  0.88406891 0.87186927 0.88059449 0.24052742]\n",
      " [0.79091942 0.87220013 0.94781786 0.9677155  0.89762121 0.28887475\n",
      "  0.88238418 0.8705864  0.88658065 0.63545769]\n",
      " [0.78026366 0.37817809 0.79832673 0.73456442 0.13907486 0.03252541\n",
      "  0.03684756 0.69943172 0.05709572 0.27978647]\n",
      " [0.77085972 0.82998526 0.71294636 0.94995075 0.80935282 0.03326242\n",
      "  0.80169404 0.85270995 0.29835427 0.87070936]\n",
      " [0.79870576 0.87288445 0.94514394 0.96577597 0.89565325 0.86215001\n",
      "  0.88431078 0.87252903 0.88977134 0.931077  ]\n",
      " [0.81490982 0.87405771 0.94276315 0.96511579 0.89754367 0.86210942\n",
      "  0.88062555 0.87058753 0.88555455 0.96770215]\n",
      " [0.63654345 0.20341852 0.08333905 0.10390858 0.0906648  0.03516713\n",
      "  0.03944864 0.0358874  0.02926843 0.07498952]\n",
      " [0.78833175 0.3129417  0.39842424 0.82784098 0.37370285 0.0306693\n",
      "  0.03313615 0.57471246 0.03601962 0.15249273]\n",
      " [0.7747969  0.80209786 0.31191558 0.91911608 0.67008054 0.03440988\n",
      "  0.52200514 0.84250325 0.44026795 0.09358095]\n",
      " [0.81544518 0.87343216 0.94494891 0.96886092 0.89768547 0.85713142\n",
      "  0.88444358 0.87299216 0.87271774 0.9132877 ]\n",
      " [0.78892452 0.41386834 0.61131918 0.92504543 0.20900516 0.0320207\n",
      "  0.03628683 0.69609529 0.03169547 0.76130527]\n",
      " [0.39405951 0.18802901 0.06107502 0.10217499 0.07437023 0.03391612\n",
      "  0.03738251 0.03318495 0.02978508 0.12199956]\n",
      " [0.76732743 0.82531118 0.35934663 0.89211345 0.62665987 0.03368299\n",
      "  0.05894674 0.39412081 0.16833229 0.11555005]\n",
      " [0.79231173 0.75514489 0.77821726 0.90634161 0.18924597 0.03317413\n",
      "  0.039834   0.79864615 0.68817735 0.88442749]\n",
      " [0.81279188 0.8731519  0.94402319 0.96803015 0.89661354 0.85843867\n",
      "  0.88561398 0.87384659 0.88458961 0.88559526]\n",
      " [0.82290417 0.87565005 0.94104713 0.96778357 0.89585549 0.86490554\n",
      "  0.88456994 0.87297994 0.88908261 0.94281578]\n",
      " [0.76629144 0.70936996 0.1217805  0.80665821 0.11180921 0.03526729\n",
      "  0.03903151 0.04057394 0.04507764 0.2400254 ]\n",
      " [0.80590892 0.87021947 0.940808   0.96876484 0.89671671 0.86280096\n",
      "  0.88072443 0.86947566 0.88268137 0.96957517]\n",
      " [0.79805654 0.86778718 0.94503766 0.92541713 0.8939389  0.81892943\n",
      "  0.88415939 0.87274367 0.84825426 0.89733011]\n",
      " [0.81930071 0.87423152 0.9403168  0.95907676 0.89596397 0.86305732\n",
      "  0.88050777 0.87059271 0.88572687 0.96314937]\n",
      " [0.79185492 0.86884248 0.94794399 0.92821318 0.89645791 0.85637194\n",
      "  0.87984335 0.86879545 0.88509721 0.88675702]\n",
      " [0.80333799 0.86697233 0.94555247 0.95804298 0.86850828 0.10673352\n",
      "  0.87987036 0.87330395 0.85971701 0.81804913]\n",
      " [0.6317392  0.14270867 0.25501421 0.89178073 0.09809028 0.03059269\n",
      "  0.03501004 0.03924382 0.0284678  0.41329488]\n",
      " [0.42802095 0.16585584 0.06256554 0.11072496 0.08177526 0.03348862\n",
      "  0.03640663 0.03239864 0.02872337 0.08088818]\n",
      " [0.73924273 0.37736398 0.11649792 0.39408657 0.13456734 0.02957862\n",
      "  0.05189923 0.05546363 0.04994374 0.11558185]\n",
      " [0.81820732 0.87541282 0.94201577 0.97267473 0.89671123 0.86193353\n",
      "  0.88202798 0.8709476  0.88846922 0.84216553]\n",
      " [0.79592294 0.86586285 0.94046062 0.96905392 0.89987916 0.86334336\n",
      "  0.88562363 0.87117261 0.88871861 0.97055584]\n",
      " [0.80265743 0.870947   0.94183463 0.96876967 0.89762032 0.86483288\n",
      "  0.88023996 0.86972123 0.88375705 0.9104957 ]\n",
      " [0.71151513 0.41859797 0.17103297 0.39100695 0.09780678 0.03305586\n",
      "  0.06491337 0.08400483 0.03514438 0.09048385]\n",
      " [0.70638257 0.19802813 0.06196243 0.10659906 0.08587536 0.03403569\n",
      "  0.04031875 0.03410647 0.03177024 0.10121471]\n",
      " [0.66546309 0.22523686 0.2157494  0.76232314 0.11901256 0.02940021\n",
      "  0.03161844 0.03805617 0.04170154 0.25822297]\n",
      " [0.78607523 0.86449128 0.89889085 0.9311679  0.44169188 0.03701015\n",
      "  0.88031995 0.86715901 0.87332618 0.84645605]\n",
      " [0.44808063 0.13010165 0.05489527 0.09705957 0.07565711 0.03589912\n",
      "  0.03953964 0.03554583 0.03369608 0.06466181]\n",
      " [0.77241355 0.86232644 0.51763284 0.88973576 0.87094659 0.55616862\n",
      "  0.87590051 0.8456654  0.8502667  0.88089311]\n",
      " [0.82201087 0.8747102  0.9428795  0.96675897 0.89443046 0.86419672\n",
      "  0.8838045  0.8722648  0.88923258 0.94349343]\n",
      " [0.78906643 0.86571842 0.93345684 0.935835   0.28405294 0.03463129\n",
      "  0.21728304 0.6292389  0.81391072 0.10874174]\n",
      " [0.72842366 0.25436866 0.82645375 0.80635637 0.29775742 0.03389025\n",
      "  0.03908891 0.16831572 0.03196724 0.08816691]\n",
      " [0.79949623 0.86945683 0.9468084  0.96994144 0.75323945 0.77924615\n",
      "  0.88673037 0.8755542  0.75961125 0.75817913]\n",
      " [0.80043209 0.87284541 0.92816335 0.9671368  0.84473354 0.036461\n",
      "  0.87067646 0.79381859 0.75717121 0.92296261]\n",
      " [0.80489933 0.87346452 0.94431132 0.96014899 0.89825684 0.8621043\n",
      "  0.88215965 0.8718732  0.88911235 0.91190761]\n",
      " [0.79230559 0.86189216 0.94863117 0.96124417 0.70005661 0.04871736\n",
      "  0.88419634 0.87112701 0.8749094  0.76746136]\n",
      " [0.73601365 0.73934585 0.06896217 0.63181585 0.10209797 0.0374746\n",
      "  0.04266337 0.060948   0.07971239 0.23483877]\n",
      " [0.73044294 0.25415957 0.09401623 0.49708441 0.10398401 0.03283392\n",
      "  0.03673352 0.0353552  0.03062694 0.07303002]\n",
      " [0.79437512 0.87178767 0.94332403 0.96896392 0.89523375 0.86304039\n",
      "  0.88345867 0.87084836 0.88803458 0.90725124]]\n"
     ]
    }
   ],
   "source": [
    "#Submission round 1. \n",
    "# CLASS PREDICTION\n",
    "# Average of BERT\n",
    "sFilePred='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_round1_'\n",
    "lFilesPred=[]\n",
    "for fold in range(1,11):\n",
    "    lFilesPred.append(sFilePred+str(fold)+'.csv')\n",
    "    \n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Round1Detection'\n",
    "vPred, lID= average_fusion (lFilesPred, dest_dir, fileName, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 10\n",
      "mPredictions and vID\n",
      "(48, 10)\n",
      "48\n",
      "[[0.72559565 0.28560138 0.06513522 0.1651601  0.07015276 0.03334882\n",
      "  0.03571316 0.04052589 0.02987922 0.08371879]\n",
      " [0.72559565 0.28560138 0.06513522 0.1651601  0.07015276 0.03334882\n",
      "  0.03571316 0.04052589 0.02987922 0.08371879]\n",
      " [0.79538405 0.8518368  0.94358134 0.93523407 0.89284587 0.86066794\n",
      "  0.88467431 0.87550122 0.74595386 0.77696401]\n",
      " [0.79469365 0.86883652 0.57957286 0.68774277 0.13125151 0.03630467\n",
      "  0.70297796 0.20872954 0.58943719 0.90434134]\n",
      " [0.80023128 0.86913019 0.94007659 0.93650758 0.89865911 0.0793495\n",
      "  0.88406891 0.87186927 0.88059449 0.24052742]\n",
      " [0.79091942 0.87220013 0.94781786 0.9677155  0.89762121 0.28887475\n",
      "  0.88238418 0.8705864  0.88658065 0.63545769]\n",
      " [0.78026366 0.37817809 0.79832673 0.73456442 0.13907486 0.03252541\n",
      "  0.03684756 0.69943172 0.05709572 0.27978647]\n",
      " [0.77085972 0.82998526 0.71294636 0.94995075 0.80935282 0.03326242\n",
      "  0.80169404 0.85270995 0.29835427 0.87070936]\n",
      " [0.79870576 0.87288445 0.94514394 0.96577597 0.89565325 0.86215001\n",
      "  0.88431078 0.87252903 0.88977134 0.931077  ]\n",
      " [0.81490982 0.87405771 0.94276315 0.96511579 0.89754367 0.86210942\n",
      "  0.88062555 0.87058753 0.88555455 0.96770215]\n",
      " [0.63654345 0.20341852 0.08333905 0.10390858 0.0906648  0.03516713\n",
      "  0.03944864 0.0358874  0.02926843 0.07498952]\n",
      " [0.78833175 0.3129417  0.39842424 0.82784098 0.37370285 0.0306693\n",
      "  0.03313615 0.57471246 0.03601962 0.15249273]\n",
      " [0.7747969  0.80209786 0.31191558 0.91911608 0.67008054 0.03440988\n",
      "  0.52200514 0.84250325 0.44026795 0.09358095]\n",
      " [0.81544518 0.87343216 0.94494891 0.96886092 0.89768547 0.85713142\n",
      "  0.88444358 0.87299216 0.87271774 0.9132877 ]\n",
      " [0.78892452 0.41386834 0.61131918 0.92504543 0.20900516 0.0320207\n",
      "  0.03628683 0.69609529 0.03169547 0.76130527]\n",
      " [0.39405951 0.18802901 0.06107502 0.10217499 0.07437023 0.03391612\n",
      "  0.03738251 0.03318495 0.02978508 0.12199956]\n",
      " [0.76732743 0.82531118 0.35934663 0.89211345 0.62665987 0.03368299\n",
      "  0.05894674 0.39412081 0.16833229 0.11555005]\n",
      " [0.79231173 0.75514489 0.77821726 0.90634161 0.18924597 0.03317413\n",
      "  0.039834   0.79864615 0.68817735 0.88442749]\n",
      " [0.81279188 0.8731519  0.94402319 0.96803015 0.89661354 0.85843867\n",
      "  0.88561398 0.87384659 0.88458961 0.88559526]\n",
      " [0.82290417 0.87565005 0.94104713 0.96778357 0.89585549 0.86490554\n",
      "  0.88456994 0.87297994 0.88908261 0.94281578]\n",
      " [0.76629144 0.70936996 0.1217805  0.80665821 0.11180921 0.03526729\n",
      "  0.03903151 0.04057394 0.04507764 0.2400254 ]\n",
      " [0.80590892 0.87021947 0.940808   0.96876484 0.89671671 0.86280096\n",
      "  0.88072443 0.86947566 0.88268137 0.96957517]\n",
      " [0.79805654 0.86778718 0.94503766 0.92541713 0.8939389  0.81892943\n",
      "  0.88415939 0.87274367 0.84825426 0.89733011]\n",
      " [0.81930071 0.87423152 0.9403168  0.95907676 0.89596397 0.86305732\n",
      "  0.88050777 0.87059271 0.88572687 0.96314937]\n",
      " [0.79185492 0.86884248 0.94794399 0.92821318 0.89645791 0.85637194\n",
      "  0.87984335 0.86879545 0.88509721 0.88675702]\n",
      " [0.80333799 0.86697233 0.94555247 0.95804298 0.86850828 0.10673352\n",
      "  0.87987036 0.87330395 0.85971701 0.81804913]\n",
      " [0.6317392  0.14270867 0.25501421 0.89178073 0.09809028 0.03059269\n",
      "  0.03501004 0.03924382 0.0284678  0.41329488]\n",
      " [0.42802095 0.16585584 0.06256554 0.11072496 0.08177526 0.03348862\n",
      "  0.03640663 0.03239864 0.02872337 0.08088818]\n",
      " [0.73924273 0.37736398 0.11649792 0.39408657 0.13456734 0.02957862\n",
      "  0.05189923 0.05546363 0.04994374 0.11558185]\n",
      " [0.81820732 0.87541282 0.94201577 0.97267473 0.89671123 0.86193353\n",
      "  0.88202798 0.8709476  0.88846922 0.84216553]\n",
      " [0.79592294 0.86586285 0.94046062 0.96905392 0.89987916 0.86334336\n",
      "  0.88562363 0.87117261 0.88871861 0.97055584]\n",
      " [0.80265743 0.870947   0.94183463 0.96876967 0.89762032 0.86483288\n",
      "  0.88023996 0.86972123 0.88375705 0.9104957 ]\n",
      " [0.71151513 0.41859797 0.17103297 0.39100695 0.09780678 0.03305586\n",
      "  0.06491337 0.08400483 0.03514438 0.09048385]\n",
      " [0.70638257 0.19802813 0.06196243 0.10659906 0.08587536 0.03403569\n",
      "  0.04031875 0.03410647 0.03177024 0.10121471]\n",
      " [0.66546309 0.22523686 0.2157494  0.76232314 0.11901256 0.02940021\n",
      "  0.03161844 0.03805617 0.04170154 0.25822297]\n",
      " [0.78607523 0.86449128 0.89889085 0.9311679  0.44169188 0.03701015\n",
      "  0.88031995 0.86715901 0.87332618 0.84645605]\n",
      " [0.44808063 0.13010165 0.05489527 0.09705957 0.07565711 0.03589912\n",
      "  0.03953964 0.03554583 0.03369608 0.06466181]\n",
      " [0.77241355 0.86232644 0.51763284 0.88973576 0.87094659 0.55616862\n",
      "  0.87590051 0.8456654  0.8502667  0.88089311]\n",
      " [0.82201087 0.8747102  0.9428795  0.96675897 0.89443046 0.86419672\n",
      "  0.8838045  0.8722648  0.88923258 0.94349343]\n",
      " [0.78906643 0.86571842 0.93345684 0.935835   0.28405294 0.03463129\n",
      "  0.21728304 0.6292389  0.81391072 0.10874174]\n",
      " [0.72842366 0.25436866 0.82645375 0.80635637 0.29775742 0.03389025\n",
      "  0.03908891 0.16831572 0.03196724 0.08816691]\n",
      " [0.79949623 0.86945683 0.9468084  0.96994144 0.75323945 0.77924615\n",
      "  0.88673037 0.8755542  0.75961125 0.75817913]\n",
      " [0.80043209 0.87284541 0.92816335 0.9671368  0.84473354 0.036461\n",
      "  0.87067646 0.79381859 0.75717121 0.92296261]\n",
      " [0.80489933 0.87346452 0.94431132 0.96014899 0.89825684 0.8621043\n",
      "  0.88215965 0.8718732  0.88911235 0.91190761]\n",
      " [0.79230559 0.86189216 0.94863117 0.96124417 0.70005661 0.04871736\n",
      "  0.88419634 0.87112701 0.8749094  0.76746136]\n",
      " [0.73601365 0.73934585 0.06896217 0.63181585 0.10209797 0.0374746\n",
      "  0.04266337 0.060948   0.07971239 0.23483877]\n",
      " [0.73044294 0.25415957 0.09401623 0.49708441 0.10398401 0.03283392\n",
      "  0.03673352 0.0353552  0.03062694 0.07303002]\n",
      " [0.79437512 0.87178767 0.94332403 0.96896392 0.89523375 0.86304039\n",
      "  0.88345867 0.87084836 0.88803458 0.90725124]]\n",
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Detection_Bert1average.csv\n"
     ]
    }
   ],
   "source": [
    "# CLASS PREDICTION\n",
    "# Average of BERT detection -round 1 into CSV\n",
    "sFilePred='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_round1_'\n",
    "lFilesPred=[]\n",
    "for fold in range(1,11):\n",
    "    lFilesPred.append(sFilePred+str(fold)+'.csv')\n",
    "    \n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Detection_Bert1average'\n",
    "vPred, lID= average_fusion_tocsv (lFilesPred, dest_dir, fileName, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 10\n",
      "mPredictions and vID\n",
      "(48, 10)\n",
      "48\n",
      "[[0.51763761 0.2578373  0.14571771 0.5064835  0.74108922 0.35053664\n",
      "  0.7714172  0.76346982 0.06099356 0.11149926]\n",
      " [0.51763761 0.2578373  0.14571771 0.5064835  0.74108922 0.35053664\n",
      "  0.7714172  0.76346982 0.06099356 0.11149926]\n",
      " [0.23065864 0.2212508  0.16180502 0.71250218 0.53240657 0.46810126\n",
      "  0.35216439 0.40503079 0.08730643 0.30864367]\n",
      " [0.82566488 0.72241318 0.569121   0.69916546 0.67688084 0.63440645\n",
      "  0.75774312 0.82172    0.44276404 0.70732516]\n",
      " [0.50534004 0.36173421 0.38202581 0.30435023 0.11345185 0.50515288\n",
      "  0.36811358 0.54699355 0.12518969 0.4687393 ]\n",
      " [0.58118993 0.8056044  0.81595731 0.53918624 0.38087618 0.5194236\n",
      "  0.22149722 0.78720903 0.39380825 0.58077335]\n",
      " [0.37688807 0.21372975 0.17327426 0.23326358 0.41138721 0.22827107\n",
      "  0.26233089 0.41358587 0.03383163 0.10419046]\n",
      " [0.5976162  0.38408363 0.46803305 0.58773547 0.59004605 0.65957624\n",
      "  0.56131685 0.77182859 0.23941948 0.54479343]\n",
      " [0.97237223 0.9808135  0.96418101 0.96669108 0.8747465  0.78795856\n",
      "  0.39144281 0.93676764 0.60301131 0.88010699]\n",
      " [0.95664722 0.90383697 0.80538386 0.74888754 0.74634111 0.59397221\n",
      "  0.72215867 0.85078341 0.64011687 0.59691876]\n",
      " [0.14779323 0.31852722 0.52459419 0.662287   0.33430484 0.61671871\n",
      "  0.21853821 0.55810511 0.37839949 0.62361115]\n",
      " [0.25908315 0.25681791 0.35937098 0.49024674 0.62511617 0.43716955\n",
      "  0.30509418 0.56985557 0.066978   0.29064402]\n",
      " [0.4448292  0.691567   0.39827868 0.52933717 0.61723208 0.51860869\n",
      "  0.54835272 0.79354483 0.13670737 0.28619656]\n",
      " [0.96516055 0.9511112  0.90595263 0.93672508 0.95182228 0.92540729\n",
      "  0.9595167  0.9715665  0.87803513 0.95051378]\n",
      " [0.18546987 0.37078863 0.54256928 0.59819484 0.29551649 0.44731051\n",
      "  0.08127349 0.4033224  0.10840688 0.2882013 ]\n",
      " [0.73844522 0.8541224  0.76544458 0.77176762 0.72475189 0.80938411\n",
      "  0.58969057 0.87413961 0.48362926 0.6562171 ]\n",
      " [0.75778574 0.73209512 0.83782691 0.60004967 0.57940048 0.62834132\n",
      "  0.34977445 0.85764617 0.34754398 0.63485026]\n",
      " [0.25157768 0.32156032 0.4188585  0.39217013 0.37726879 0.50878447\n",
      "  0.20065801 0.73956233 0.25836331 0.43191916]\n",
      " [0.80269581 0.72281104 0.68470407 0.74185491 0.72169644 0.55778408\n",
      "  0.48617342 0.81469572 0.30620477 0.61347616]\n",
      " [0.91575396 0.84961832 0.82303232 0.86978471 0.8197453  0.65654385\n",
      "  0.74492317 0.92454302 0.61538547 0.7920382 ]\n",
      " [0.21208212 0.26912999 0.34547797 0.4060798  0.32230312 0.63216853\n",
      "  0.15411703 0.67302948 0.18938766 0.30889004]\n",
      " [0.5975318  0.31512761 0.25753254 0.59399402 0.76346594 0.472177\n",
      "  0.71263671 0.73613119 0.12794882 0.26268005]\n",
      " [0.24716651 0.15050837 0.29173404 0.77160835 0.71178669 0.42310408\n",
      "  0.77335697 0.82464981 0.05809568 0.57110834]\n",
      " [0.75631517 0.33294919 0.47014961 0.78426892 0.69369358 0.64771837\n",
      "  0.390477   0.89300424 0.23652646 0.81921113]\n",
      " [0.16907939 0.09701432 0.24702542 0.27101809 0.28214505 0.310956\n",
      "  0.04354056 0.54547459 0.08484324 0.29548761]\n",
      " [0.75791466 0.80204314 0.81349891 0.88998342 0.56557375 0.56630445\n",
      "  0.09090987 0.88195938 0.61093217 0.72077435]\n",
      " [0.22829004 0.14614563 0.28929806 0.25481555 0.21431687 0.19803631\n",
      "  0.10354506 0.4452087  0.07378611 0.23590776]\n",
      " [0.23350444 0.37542436 0.48472992 0.33506963 0.40874654 0.36159715\n",
      "  0.18248075 0.65686309 0.09230257 0.2207299 ]\n",
      " [0.59213775 0.70206726 0.77145255 0.64908803 0.64734602 0.63188356\n",
      "  0.63582885 0.81048054 0.25851822 0.52629077]\n",
      " [0.96272135 0.95533049 0.97286755 0.98415029 0.9116376  0.86976385\n",
      "  0.56682384 0.9651593  0.87242132 0.94885898]\n",
      " [0.47847319 0.3045857  0.45768887 0.20480213 0.25253832 0.08226085\n",
      "  0.24542144 0.46266091 0.05465977 0.21227172]\n",
      " [0.56306332 0.46586928 0.58058506 0.74130613 0.49912256 0.65282643\n",
      "  0.37781125 0.78332245 0.39805332 0.67028856]\n",
      " [0.40099922 0.49823567 0.5399946  0.52032167 0.44116646 0.46061358\n",
      "  0.16955087 0.67862076 0.06497665 0.4490546 ]\n",
      " [0.35243088 0.42223114 0.49882433 0.53116459 0.49286902 0.23171441\n",
      "  0.18944526 0.56592923 0.0710378  0.33810315]\n",
      " [0.26012444 0.35609668 0.29792321 0.35740387 0.42701584 0.58915126\n",
      "  0.20020299 0.64282876 0.12371378 0.28495869]\n",
      " [0.7934944  0.68535346 0.45859703 0.59807885 0.68543023 0.49812064\n",
      "  0.52803242 0.82366544 0.18334569 0.34576645]\n",
      " [0.68032491 0.39619339 0.32191789 0.51894385 0.6050216  0.28128308\n",
      "  0.49992946 0.57197976 0.07642498 0.24695916]\n",
      " [0.92195308 0.88457763 0.88866723 0.92183274 0.74234647 0.63159013\n",
      "  0.24311839 0.92158574 0.50470471 0.81162167]\n",
      " [0.16696373 0.09297662 0.41180542 0.23477355 0.14806312 0.12438843\n",
      "  0.17110212 0.23819289 0.03430678 0.20656905]\n",
      " [0.0459679  0.07999479 0.11268168 0.15458819 0.07583372 0.21036088\n",
      "  0.04232552 0.32564235 0.05898054 0.1871822 ]\n",
      " [0.04405514 0.04892531 0.09881489 0.10636821 0.08815308 0.11959384\n",
      "  0.03875147 0.1685285  0.02050346 0.08662949]\n",
      " [0.46877721 0.34121996 0.33719629 0.5735265  0.57246596 0.52199072\n",
      "  0.62236321 0.7587238  0.19670214 0.50101572]\n",
      " [0.61624992 0.61543173 0.6314159  0.69184887 0.66889489 0.41128919\n",
      "  0.4935078  0.81838608 0.19746356 0.51464421]\n",
      " [0.64922732 0.49935818 0.60342067 0.46733987 0.312356   0.35856506\n",
      "  0.36359847 0.46791616 0.15473354 0.4720448 ]\n",
      " [0.71078891 0.6717633  0.79313308 0.74470717 0.60779148 0.56922179\n",
      "  0.62461644 0.80262303 0.33687112 0.62769842]\n",
      " [0.83613479 0.66867834 0.75778943 0.81288868 0.81741601 0.65118772\n",
      "  0.74073744 0.9078657  0.31274188 0.76908094]\n",
      " [0.21595125 0.32939962 0.45272779 0.27103221 0.29226103 0.31902871\n",
      "  0.13361292 0.43397337 0.06407968 0.22638604]\n",
      " [0.78507465 0.77136445 0.71961153 0.57506472 0.57786185 0.64272821\n",
      "  0.32559901 0.85993582 0.372879   0.68942422]]\n",
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Detection_Acoustic4average.csv\n"
     ]
    }
   ],
   "source": [
    "# CLASS PREDICTION acoustic model - average\n",
    "# Average of acoustic Model detection -round 4 into CSV\n",
    "sFilePred='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores_round4_'\n",
    "lFilesPred=[]\n",
    "for fold in range(1,11):\n",
    "    lFilesPred.append(sFilePred+str(fold)+'.csv')\n",
    "    \n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Detection_Acoustic4average'\n",
    "vPred, lID= average_fusion_tocsv (lFilesPred, dest_dir, fileName, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 10\n",
      "mPredictions and vID\n",
      "(48, 10)\n",
      "48\n",
      "[[23.60571563 23.46631408 28.7753123  21.74768686 24.67330635 24.62428808\n",
      "  23.05798531 22.08063483 23.8766849  22.74387538]\n",
      " [23.60571563 23.46631408 28.7753123  21.74768686 24.67330635 24.62428808\n",
      "  23.05798531 22.08063483 23.8766849  22.74387538]\n",
      " [24.06462371 24.09753263 28.55808198 22.72558987 23.79175186 24.84918237\n",
      "  21.5843457  22.6585865  22.61762023 23.11316013]\n",
      " [23.17144454 23.04545581 25.82623422 18.72650564 20.50527871 22.04661369\n",
      "  20.73980749 19.14469063 18.96748245 22.25191891]\n",
      " [23.3160764  23.20010662 27.01225877 19.48866963 22.45022178 23.60229671\n",
      "  22.20326543 20.05918801 19.65840518 22.43344903]\n",
      " [23.48778427 23.3510685  26.58626139 20.39819062 22.10777342 23.43059242\n",
      "  21.48945451 20.85258365 20.53010523 22.52137721]\n",
      " [24.10005033 24.00746047 29.35370564 22.0120883  24.57393587 24.64343727\n",
      "  22.39683867 22.18738317 23.73419881 22.83809066]\n",
      " [23.66023242 23.44177008 28.80832851 21.55219316 24.26579297 24.27590847\n",
      "  22.85587549 21.66037917 22.89114296 22.66313732]\n",
      " [23.11847627 22.7546382  23.14789474 17.79807329 19.36294019 21.57652438\n",
      "  20.38498163 18.61295879 16.06864929 22.08106041]\n",
      " [22.63993084 22.56201267 21.05170369 15.7182008  16.0941267  19.63528454\n",
      "  18.26430917 16.17127776 12.89973825 21.98648036]\n",
      " [23.58342826 23.27563584 28.43475044 20.86837292 23.669191   24.27527368\n",
      "  22.98598588 20.98246694 21.8069762  22.40922153]\n",
      " [23.7808764  23.4457773  28.66368055 21.63860857 24.74912524 24.70097601\n",
      "  23.21788967 21.82421029 23.02616894 22.58690178]\n",
      " [23.5017693  23.25667441 27.69752026 20.01998127 22.66658843 23.57702494\n",
      "  22.54906118 20.56868076 20.15994251 22.29085743]\n",
      " [22.97967732 22.73300886 23.00125122 16.66354001 17.29835272 20.37239492\n",
      "  19.39519107 16.89802766 13.90409768 21.99740589]\n",
      " [23.82793307 23.61414492 27.98341155 21.77172482 23.76069367 24.16630805\n",
      "  22.85526216 21.35092378 21.86352074 22.5760138 ]\n",
      " [23.78282905 23.5324198  28.55568409 20.81877708 23.50991964 24.09710169\n",
      "  22.7792573  21.25448942 21.98969007 22.515589  ]\n",
      " [23.73369277 23.46031129 29.04209018 22.04193592 24.27422225 24.18664813\n",
      "  23.14716339 22.1616894  23.14261615 22.68151224]\n",
      " [23.39020371 23.0663377  27.3175925  18.64436388 21.71879768 23.25802088\n",
      "  22.04808176 19.57767069 19.22896743 22.23697901]\n",
      " [22.90601134 22.75022864 23.46241415 16.21231019 17.74289846 20.57348549\n",
      "  19.74969506 16.91396892 14.91954625 21.9380182 ]\n",
      " [22.64204979 22.57917166 20.78723609 14.78076786 15.24115205 19.04942751\n",
      "  18.05505216 15.80983758 12.3561734  21.83401644]\n",
      " [23.43416154 23.09527159 27.78450072 19.70241129 22.89725661 23.7791276\n",
      "  22.64286518 20.52165091 20.6721586  22.25576878]\n",
      " [23.37671578 23.19206893 26.54610336 20.30811667 21.71719551 22.85077751\n",
      "  21.20243847 20.49286008 20.13360679 22.54999995]\n",
      " [23.49619925 23.30943167 28.50543737 20.78039646 23.34905684 23.99483263\n",
      "  22.46984482 21.3659817  21.85436726 22.64940619]\n",
      " [22.71794558 22.65837908 21.11075342 15.54966152 15.76624453 19.09378946\n",
      "  18.26281428 16.18923068 12.55371362 21.98427737]\n",
      " [23.57676566 23.38079095 27.00099885 20.75047731 22.3586905  23.50356281\n",
      "  21.40464127 20.8341068  20.76638818 22.54623771]\n",
      " [23.40366125 23.0758971  25.55314958 19.18677807 21.38575137 22.4714452\n",
      "  21.40221477 19.98824537 18.5527879  22.28050947]\n",
      " [24.07486439 23.97223413 30.43983579 22.66939402 25.46868682 25.45675993\n",
      "  24.00476217 22.76008487 24.37591374 22.83629179]\n",
      " [23.62960517 23.35995913 28.81831884 20.01496732 23.62780988 24.13338125\n",
      "  22.90181816 21.07118011 21.82350397 22.35835075]\n",
      " [23.66344035 23.36924672 28.43364179 20.25216401 23.63645554 24.11742568\n",
      "  23.067348   21.04818463 21.23707831 22.30039895]\n",
      " [22.71978199 22.69317627 20.43078482 13.7580657  14.50240463 18.41489732\n",
      "  17.6092279  15.01279771 11.67800993 21.82892203]\n",
      " [23.62837136 23.50387573 28.99760664 21.33548677 24.47452247 24.44731772\n",
      "  22.46428013 21.37294471 23.05389404 22.71785617]\n",
      " [23.32314134 23.27177525 25.90426147 19.91976857 22.02138305 22.99055278\n",
      "  21.59169674 20.23748696 20.29416561 22.44004548]\n",
      " [24.15740132 23.88837934 29.94532764 22.99893737 25.37935317 25.49871683\n",
      "  23.38061213 22.9491806  24.5012337  23.06716025]\n",
      " [23.42049837 23.11954379 27.57613242 19.48741794 22.49013841 23.50934744\n",
      "  22.39453912 20.04095435 19.53392208 22.2097671 ]\n",
      " [23.5370636  23.17339361 28.26554954 19.48600352 22.30104268 23.32754552\n",
      "  22.08997428 19.80192661 19.66716886 22.32747316]\n",
      " [23.1485939  23.0386734  26.06606305 18.79579604 21.45658135 23.10571074\n",
      "  21.24150753 19.65389371 19.21849608 22.29700685]\n",
      " [23.75610888 23.41279864 27.99367726 20.60130358 23.2858783  24.16615605\n",
      "  22.76434243 20.72622478 21.38480723 22.33727038]\n",
      " [23.68163645 23.44506204 28.59832048 21.63123965 24.06479537 24.16547835\n",
      "  22.84881413 21.70764148 23.06851745 22.72429526]\n",
      " [22.75624394 22.63309121 20.71805656 14.96259391 14.34334964 18.03767323\n",
      "  17.07688808 14.76798624 10.87190866 21.89118862]\n",
      " [23.48315477 23.18909526 26.69081032 19.87558365 22.69821346 23.5206145\n",
      "  22.45855987 20.71889162 20.72380185 22.31778681]\n",
      " [23.55453193 23.24406803 28.10562551 19.07833457 21.68884635 23.23765397\n",
      "  21.67583942 19.85009372 19.51953113 22.21839309]\n",
      " [23.09020579 22.91265249 24.02753413 16.39122427 18.61160338 21.67209685\n",
      "  20.08363008 17.2068733  15.62874556 21.95226789]\n",
      " [22.99167573 22.80914783 23.77974451 16.62960827 18.02150309 20.92448473\n",
      "  19.58525598 17.31921494 14.71966714 21.99079871]\n",
      " [22.83036411 22.67027378 21.49220109 15.85919023 16.36692166 20.59207141\n",
      "  19.32597399 15.86074054 12.14895487 22.10420787]\n",
      " [23.21029723 23.02204549 24.46664929 17.505548   19.09988701 21.76629245\n",
      "  20.2233696  18.11955929 17.39394844 22.07618773]\n",
      " [23.18365037 22.91896462 26.23890817 18.20757508 20.28656781 22.55476713\n",
      "  21.89188063 18.57263267 17.65089512 22.03377128]\n",
      " [23.60115409 23.30270112 27.94044614 20.25039196 23.33914876 23.98093522\n",
      "  22.56387413 20.99323153 20.45881391 22.33288229]\n",
      " [23.36978674 23.17556977 25.82272589 20.09969473 21.68126822 22.48036981\n",
      "  20.76369703 20.27436197 20.25335491 22.54780769]]\n"
     ]
    }
   ],
   "source": [
    "#Submission round 1. \n",
    "# MMSE\n",
    "# Average of BERT\n",
    "sFilePred='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertMMSE_round1_'\n",
    "lFilesPred=[]\n",
    "for fold in range(1,11):\n",
    "    lFilesPred.append(sFilePred+str(fold)+'.csv')\n",
    "    \n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Round1MMSE'\n",
    "vPred, lID= average_fusion (lFilesPred, dest_dir, fileName, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 20\n",
      "mPredictions and vID\n",
      "(48, 20)\n",
      "48\n",
      "[[23.60571563 20.97770694 23.46631408 20.97770694 28.7753123  20.97770694\n",
      "  21.74768686 20.97770694 24.67330635 20.97770694 24.62428808 20.97770694\n",
      "  23.05798531 20.97770694 22.08063483 20.97770694 23.8766849  20.97770694\n",
      "  22.74387538 20.97770694]\n",
      " [23.60571563 20.97770694 23.46631408 20.97770694 28.7753123  20.97770694\n",
      "  21.74768686 20.97770694 24.67330635 20.97770694 24.62428808 20.97770694\n",
      "  23.05798531 20.97770694 22.08063483 20.97770694 23.8766849  20.97770694\n",
      "  22.74387538 20.97770694]\n",
      " [24.06462371 33.30118939 24.09753263 33.30118939 28.55808198 33.30118939\n",
      "  22.72558987 33.30118939 23.79175186 33.30118939 24.84918237 33.30118939\n",
      "  21.5843457  33.30118939 22.6585865  33.30118939 22.61762023 33.30118939\n",
      "  23.11316013 33.30118939]\n",
      " [23.17144454 21.58944575 23.04545581 21.58944575 25.82623422 21.58944575\n",
      "  18.72650564 21.58944575 20.50527871 21.58944575 22.04661369 21.58944575\n",
      "  20.73980749 21.58944575 19.14469063 21.58944575 18.96748245 21.58944575\n",
      "  22.25191891 21.58944575]\n",
      " [23.3160764  25.04373755 23.20010662 25.04373755 27.01225877 25.04373755\n",
      "  19.48866963 25.04373755 22.45022178 25.04373755 23.60229671 25.04373755\n",
      "  22.20326543 25.04373755 20.05918801 25.04373755 19.65840518 25.04373755\n",
      "  22.43344903 25.04373755]\n",
      " [23.48778427 24.46814765 23.3510685  24.46814765 26.58626139 24.46814765\n",
      "  20.39819062 24.46814765 22.10777342 24.46814765 23.43059242 24.46814765\n",
      "  21.48945451 24.46814765 20.85258365 24.46814765 20.53010523 24.46814765\n",
      "  22.52137721 24.46814765]\n",
      " [24.10005033 27.9617009  24.00746047 27.9617009  29.35370564 27.9617009\n",
      "  22.0120883  27.9617009  24.57393587 27.9617009  24.64343727 27.9617009\n",
      "  22.39683867 27.9617009  22.18738317 27.9617009  23.73419881 27.9617009\n",
      "  22.83809066 27.9617009 ]\n",
      " [23.66023242 27.09034778 23.44177008 27.09034778 28.80832851 27.09034778\n",
      "  21.55219316 27.09034778 24.26579297 27.09034778 24.27590847 27.09034778\n",
      "  22.85587549 27.09034778 21.66037917 27.09034778 22.89114296 27.09034778\n",
      "  22.66313732 27.09034778]\n",
      " [23.11847627 15.24870867 22.7546382  15.24870867 23.14789474 15.24870867\n",
      "  17.79807329 15.24870867 19.36294019 15.24870867 21.57652438 15.24870867\n",
      "  20.38498163 15.24870867 18.61295879 15.24870867 16.06864929 15.24870867\n",
      "  22.08106041 15.24870867]\n",
      " [22.63993084 19.49097644 22.56201267 19.49097644 21.05170369 19.49097644\n",
      "  15.7182008  19.49097644 16.0941267  19.49097644 19.63528454 19.49097644\n",
      "  18.26430917 19.49097644 16.17127776 19.49097644 12.89973825 19.49097644\n",
      "  21.98648036 19.49097644]\n",
      " [23.58342826 28.34100024 23.27563584 28.34100024 28.43475044 28.34100024\n",
      "  20.86837292 28.34100024 23.669191   28.34100024 24.27527368 28.34100024\n",
      "  22.98598588 28.34100024 20.98246694 28.34100024 21.8069762  28.34100024\n",
      "  22.40922153 28.34100024]\n",
      " [23.7808764  22.65349796 23.4457773  22.65349796 28.66368055 22.65349796\n",
      "  21.63860857 22.65349796 24.74912524 22.65349796 24.70097601 22.65349796\n",
      "  23.21788967 22.65349796 21.82421029 22.65349796 23.02616894 22.65349796\n",
      "  22.58690178 22.65349796]\n",
      " [23.5017693  21.68201865 23.25667441 21.68201865 27.69752026 21.68201865\n",
      "  20.01998127 21.68201865 22.66658843 21.68201865 23.57702494 21.68201865\n",
      "  22.54906118 21.68201865 20.56868076 21.68201865 20.15994251 21.68201865\n",
      "  22.29085743 21.68201865]\n",
      " [22.97967732 24.09592243 22.73300886 24.09592243 23.00125122 24.09592243\n",
      "  16.66354001 24.09592243 17.29835272 24.09592243 20.37239492 24.09592243\n",
      "  19.39519107 24.09592243 16.89802766 24.09592243 13.90409768 24.09592243\n",
      "  21.99740589 24.09592243]\n",
      " [23.82793307 19.60256114 23.61414492 19.60256114 27.98341155 19.60256114\n",
      "  21.77172482 19.60256114 23.76069367 19.60256114 24.16630805 19.60256114\n",
      "  22.85526216 19.60256114 21.35092378 19.60256114 21.86352074 19.60256114\n",
      "  22.5760138  19.60256114]\n",
      " [23.78282905 22.46750418 23.5324198  22.46750418 28.55568409 22.46750418\n",
      "  20.81877708 22.46750418 23.50991964 22.46750418 24.09710169 22.46750418\n",
      "  22.7792573  22.46750418 21.25448942 22.46750418 21.98969007 22.46750418\n",
      "  22.515589   22.46750418]\n",
      " [23.73369277 22.26000193 23.46031129 22.26000193 29.04209018 22.26000193\n",
      "  22.04193592 22.26000193 24.27422225 22.26000193 24.18664813 22.26000193\n",
      "  23.14716339 22.26000193 22.1616894  22.26000193 23.14261615 22.26000193\n",
      "  22.68151224 22.26000193]\n",
      " [23.39020371 24.23047222 23.0663377  24.23047222 27.3175925  24.23047222\n",
      "  18.64436388 24.23047222 21.71879768 24.23047222 23.25802088 24.23047222\n",
      "  22.04808176 24.23047222 19.57767069 24.23047222 19.22896743 24.23047222\n",
      "  22.23697901 24.23047222]\n",
      " [22.90601134 26.47771927 22.75022864 26.47771927 23.46241415 26.47771927\n",
      "  16.21231019 26.47771927 17.74289846 26.47771927 20.57348549 26.47771927\n",
      "  19.74969506 26.47771927 16.91396892 26.47771927 14.91954625 26.47771927\n",
      "  21.9380182  26.47771927]\n",
      " [22.64204979 18.05916174 22.57917166 18.05916174 20.78723609 18.05916174\n",
      "  14.78076786 18.05916174 15.24115205 18.05916174 19.04942751 18.05916174\n",
      "  18.05505216 18.05916174 15.80983758 18.05916174 12.3561734  18.05916174\n",
      "  21.83401644 18.05916174]\n",
      " [23.43416154 26.86931922 23.09527159 26.86931922 27.78450072 26.86931922\n",
      "  19.70241129 26.86931922 22.89725661 26.86931922 23.7791276  26.86931922\n",
      "  22.64286518 26.86931922 20.52165091 26.86931922 20.6721586  26.86931922\n",
      "  22.25576878 26.86931922]\n",
      " [23.37671578 23.32687409 23.19206893 23.32687409 26.54610336 23.32687409\n",
      "  20.30811667 23.32687409 21.71719551 23.32687409 22.85077751 23.32687409\n",
      "  21.20243847 23.32687409 20.49286008 23.32687409 20.13360679 23.32687409\n",
      "  22.54999995 23.32687409]\n",
      " [23.49619925 18.00773143 23.30943167 18.00773143 28.50543737 18.00773143\n",
      "  20.78039646 18.00773143 23.34905684 18.00773143 23.99483263 18.00773143\n",
      "  22.46984482 18.00773143 21.3659817  18.00773143 21.85436726 18.00773143\n",
      "  22.64940619 18.00773143]\n",
      " [22.71794558 27.6872044  22.65837908 27.6872044  21.11075342 27.6872044\n",
      "  15.54966152 27.6872044  15.76624453 27.6872044  19.09378946 27.6872044\n",
      "  18.26281428 27.6872044  16.18923068 27.6872044  12.55371362 27.6872044\n",
      "  21.98427737 27.6872044 ]\n",
      " [23.57676566 24.00154626 23.38079095 24.00154626 27.00099885 24.00154626\n",
      "  20.75047731 24.00154626 22.3586905  24.00154626 23.50356281 24.00154626\n",
      "  21.40464127 24.00154626 20.8341068  24.00154626 20.76638818 24.00154626\n",
      "  22.54623771 24.00154626]\n",
      " [23.40366125 17.72093339 23.0758971  17.72093339 25.55314958 17.72093339\n",
      "  19.18677807 17.72093339 21.38575137 17.72093339 22.4714452  17.72093339\n",
      "  21.40221477 17.72093339 19.98824537 17.72093339 18.5527879  17.72093339\n",
      "  22.28050947 17.72093339]\n",
      " [24.07486439 33.07592843 23.97223413 33.07592843 30.43983579 33.07592843\n",
      "  22.66939402 33.07592843 25.46868682 33.07592843 25.45675993 33.07592843\n",
      "  24.00476217 33.07592843 22.76008487 33.07592843 24.37591374 33.07592843\n",
      "  22.83629179 33.07592843]\n",
      " [23.62960517 24.7905829  23.35995913 24.7905829  28.81831884 24.7905829\n",
      "  20.01496732 24.7905829  23.62780988 24.7905829  24.13338125 24.7905829\n",
      "  22.90181816 24.7905829  21.07118011 24.7905829  21.82350397 24.7905829\n",
      "  22.35835075 24.7905829 ]\n",
      " [23.66344035 17.51037784 23.36924672 17.51037784 28.43364179 17.51037784\n",
      "  20.25216401 17.51037784 23.63645554 17.51037784 24.11742568 17.51037784\n",
      "  23.067348   17.51037784 21.04818463 17.51037784 21.23707831 17.51037784\n",
      "  22.30039895 17.51037784]\n",
      " [22.71978199 16.81143692 22.69317627 16.81143692 20.43078482 16.81143692\n",
      "  13.7580657  16.81143692 14.50240463 16.81143692 18.41489732 16.81143692\n",
      "  17.6092279  16.81143692 15.01279771 16.81143692 11.67800993 16.81143692\n",
      "  21.82892203 16.81143692]\n",
      " [23.62837136 23.75501592 23.50387573 23.75501592 28.99760664 23.75501592\n",
      "  21.33548677 23.75501592 24.47452247 23.75501592 24.44731772 23.75501592\n",
      "  22.46428013 23.75501592 21.37294471 23.75501592 23.05389404 23.75501592\n",
      "  22.71785617 23.75501592]\n",
      " [23.32314134 12.45265998 23.27177525 12.45265998 25.90426147 12.45265998\n",
      "  19.91976857 12.45265998 22.02138305 12.45265998 22.99055278 12.45265998\n",
      "  21.59169674 12.45265998 20.23748696 12.45265998 20.29416561 12.45265998\n",
      "  22.44004548 12.45265998]\n",
      " [24.15740132 23.22581832 23.88837934 23.22581832 29.94532764 23.22581832\n",
      "  22.99893737 23.22581832 25.37935317 23.22581832 25.49871683 23.22581832\n",
      "  23.38061213 23.22581832 22.9491806  23.22581832 24.5012337  23.22581832\n",
      "  23.06716025 23.22581832]\n",
      " [23.42049837 21.3064932  23.11954379 21.3064932  27.57613242 21.3064932\n",
      "  19.48741794 21.3064932  22.49013841 21.3064932  23.50934744 21.3064932\n",
      "  22.39453912 21.3064932  20.04095435 21.3064932  19.53392208 21.3064932\n",
      "  22.2097671  21.3064932 ]\n",
      " [23.5370636  34.4256507  23.17339361 34.4256507  28.26554954 34.4256507\n",
      "  19.48600352 34.4256507  22.30104268 34.4256507  23.32754552 34.4256507\n",
      "  22.08997428 34.4256507  19.80192661 34.4256507  19.66716886 34.4256507\n",
      "  22.32747316 34.4256507 ]\n",
      " [23.1485939  23.37928842 23.0386734  23.37928842 26.06606305 23.37928842\n",
      "  18.79579604 23.37928842 21.45658135 23.37928842 23.10571074 23.37928842\n",
      "  21.24150753 23.37928842 19.65389371 23.37928842 19.21849608 23.37928842\n",
      "  22.29700685 23.37928842]\n",
      " [23.75610888 29.03551999 23.41279864 29.03551999 27.99367726 29.03551999\n",
      "  20.60130358 29.03551999 23.2858783  29.03551999 24.16615605 29.03551999\n",
      "  22.76434243 29.03551999 20.72622478 29.03551999 21.38480723 29.03551999\n",
      "  22.33727038 29.03551999]\n",
      " [23.68163645 11.82708587 23.44506204 11.82708587 28.59832048 11.82708587\n",
      "  21.63123965 11.82708587 24.06479537 11.82708587 24.16547835 11.82708587\n",
      "  22.84881413 11.82708587 21.70764148 11.82708587 23.06851745 11.82708587\n",
      "  22.72429526 11.82708587]\n",
      " [22.75624394 32.02078488 22.63309121 32.02078488 20.71805656 32.02078488\n",
      "  14.96259391 32.02078488 14.34334964 32.02078488 18.03767323 32.02078488\n",
      "  17.07688808 32.02078488 14.76798624 32.02078488 10.87190866 32.02078488\n",
      "  21.89118862 32.02078488]\n",
      " [23.48315477 21.09898303 23.18909526 21.09898303 26.69081032 21.09898303\n",
      "  19.87558365 21.09898303 22.69821346 21.09898303 23.5206145  21.09898303\n",
      "  22.45855987 21.09898303 20.71889162 21.09898303 20.72380185 21.09898303\n",
      "  22.31778681 21.09898303]\n",
      " [23.55453193 30.55550986 23.24406803 30.55550986 28.10562551 30.55550986\n",
      "  19.07833457 30.55550986 21.68884635 30.55550986 23.23765397 30.55550986\n",
      "  21.67583942 30.55550986 19.85009372 30.55550986 19.51953113 30.55550986\n",
      "  22.21839309 30.55550986]\n",
      " [23.09020579 28.96669139 22.91265249 28.96669139 24.02753413 28.96669139\n",
      "  16.39122427 28.96669139 18.61160338 28.96669139 21.67209685 28.96669139\n",
      "  20.08363008 28.96669139 17.2068733  28.96669139 15.62874556 28.96669139\n",
      "  21.95226789 28.96669139]\n",
      " [22.99167573 22.22510997 22.80914783 22.22510997 23.77974451 22.22510997\n",
      "  16.62960827 22.22510997 18.02150309 22.22510997 20.92448473 22.22510997\n",
      "  19.58525598 22.22510997 17.31921494 22.22510997 14.71966714 22.22510997\n",
      "  21.99079871 22.22510997]\n",
      " [22.83036411 25.88108332 22.67027378 25.88108332 21.49220109 25.88108332\n",
      "  15.85919023 25.88108332 16.36692166 25.88108332 20.59207141 25.88108332\n",
      "  19.32597399 25.88108332 15.86074054 25.88108332 12.14895487 25.88108332\n",
      "  22.10420787 25.88108332]\n",
      " [23.21029723 25.61767052 23.02204549 25.61767052 24.46664929 25.61767052\n",
      "  17.505548   25.61767052 19.09988701 25.61767052 21.76629245 25.61767052\n",
      "  20.2233696  25.61767052 18.11955929 25.61767052 17.39394844 25.61767052\n",
      "  22.07618773 25.61767052]\n",
      " [23.18365037 27.66180692 22.91896462 27.66180692 26.23890817 27.66180692\n",
      "  18.20757508 27.66180692 20.28656781 27.66180692 22.55476713 27.66180692\n",
      "  21.89188063 27.66180692 18.57263267 27.66180692 17.65089512 27.66180692\n",
      "  22.03377128 27.66180692]\n",
      " [23.60115409 28.2936405  23.30270112 28.2936405  27.94044614 28.2936405\n",
      "  20.25039196 28.2936405  23.33914876 28.2936405  23.98093522 28.2936405\n",
      "  22.56387413 28.2936405  20.99323153 28.2936405  20.45881391 28.2936405\n",
      "  22.33288229 28.2936405 ]\n",
      " [23.36978674 21.5010854  23.17556977 21.5010854  25.82272589 21.5010854\n",
      "  20.09969473 21.5010854  21.68126822 21.5010854  22.48036981 21.5010854\n",
      "  20.76369703 21.5010854  20.27436197 21.5010854  20.25335491 21.5010854\n",
      "  22.54780769 21.5010854 ]]\n"
     ]
    }
   ],
   "source": [
    "# Submission Round 3\n",
    "# MMSE average of BERT and x-vectors PLDA\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/finalMMSE-xvectorsplda.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertMMSE_round1_'\n",
    "lFilesPred=[]\n",
    "for fold in range(1,11):\n",
    "    lFilesPred.append(sFilePred2+str(fold)+'.csv')\n",
    "    lFilesPred.append(sFilePred1)\n",
    "    \n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Round3MMSE'\n",
    "vPred, lID= average_fusion(lFilesPred, dest_dir, fileName, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analyzed file inputs: 9\n",
      "mPredictions and vID\n",
      "(48, 9)\n",
      "48\n",
      "[[28.7753123  21.74768686 24.67330635 24.62428808 23.05798531 22.08063483\n",
      "  23.8766849  22.74387538 20.97770694]\n",
      " [28.7753123  21.74768686 24.67330635 24.62428808 23.05798531 22.08063483\n",
      "  23.8766849  22.74387538 20.97770694]\n",
      " [28.55808198 22.72558987 23.79175186 24.84918237 21.5843457  22.6585865\n",
      "  22.61762023 23.11316013 33.30118939]\n",
      " [25.82623422 18.72650564 20.50527871 22.04661369 20.73980749 19.14469063\n",
      "  18.96748245 22.25191891 21.58944575]\n",
      " [27.01225877 19.48866963 22.45022178 23.60229671 22.20326543 20.05918801\n",
      "  19.65840518 22.43344903 25.04373755]\n",
      " [26.58626139 20.39819062 22.10777342 23.43059242 21.48945451 20.85258365\n",
      "  20.53010523 22.52137721 24.46814765]\n",
      " [29.35370564 22.0120883  24.57393587 24.64343727 22.39683867 22.18738317\n",
      "  23.73419881 22.83809066 27.9617009 ]\n",
      " [28.80832851 21.55219316 24.26579297 24.27590847 22.85587549 21.66037917\n",
      "  22.89114296 22.66313732 27.09034778]\n",
      " [23.14789474 17.79807329 19.36294019 21.57652438 20.38498163 18.61295879\n",
      "  16.06864929 22.08106041 15.24870867]\n",
      " [21.05170369 15.7182008  16.0941267  19.63528454 18.26430917 16.17127776\n",
      "  12.89973825 21.98648036 19.49097644]\n",
      " [28.43475044 20.86837292 23.669191   24.27527368 22.98598588 20.98246694\n",
      "  21.8069762  22.40922153 28.34100024]\n",
      " [28.66368055 21.63860857 24.74912524 24.70097601 23.21788967 21.82421029\n",
      "  23.02616894 22.58690178 22.65349796]\n",
      " [27.69752026 20.01998127 22.66658843 23.57702494 22.54906118 20.56868076\n",
      "  20.15994251 22.29085743 21.68201865]\n",
      " [23.00125122 16.66354001 17.29835272 20.37239492 19.39519107 16.89802766\n",
      "  13.90409768 21.99740589 24.09592243]\n",
      " [27.98341155 21.77172482 23.76069367 24.16630805 22.85526216 21.35092378\n",
      "  21.86352074 22.5760138  19.60256114]\n",
      " [28.55568409 20.81877708 23.50991964 24.09710169 22.7792573  21.25448942\n",
      "  21.98969007 22.515589   22.46750418]\n",
      " [29.04209018 22.04193592 24.27422225 24.18664813 23.14716339 22.1616894\n",
      "  23.14261615 22.68151224 22.26000193]\n",
      " [27.3175925  18.64436388 21.71879768 23.25802088 22.04808176 19.57767069\n",
      "  19.22896743 22.23697901 24.23047222]\n",
      " [23.46241415 16.21231019 17.74289846 20.57348549 19.74969506 16.91396892\n",
      "  14.91954625 21.9380182  26.47771927]\n",
      " [20.78723609 14.78076786 15.24115205 19.04942751 18.05505216 15.80983758\n",
      "  12.3561734  21.83401644 18.05916174]\n",
      " [27.78450072 19.70241129 22.89725661 23.7791276  22.64286518 20.52165091\n",
      "  20.6721586  22.25576878 26.86931922]\n",
      " [26.54610336 20.30811667 21.71719551 22.85077751 21.20243847 20.49286008\n",
      "  20.13360679 22.54999995 23.32687409]\n",
      " [28.50543737 20.78039646 23.34905684 23.99483263 22.46984482 21.3659817\n",
      "  21.85436726 22.64940619 18.00773143]\n",
      " [21.11075342 15.54966152 15.76624453 19.09378946 18.26281428 16.18923068\n",
      "  12.55371362 21.98427737 27.6872044 ]\n",
      " [27.00099885 20.75047731 22.3586905  23.50356281 21.40464127 20.8341068\n",
      "  20.76638818 22.54623771 24.00154626]\n",
      " [25.55314958 19.18677807 21.38575137 22.4714452  21.40221477 19.98824537\n",
      "  18.5527879  22.28050947 17.72093339]\n",
      " [30.43983579 22.66939402 25.46868682 25.45675993 24.00476217 22.76008487\n",
      "  24.37591374 22.83629179 33.07592843]\n",
      " [28.81831884 20.01496732 23.62780988 24.13338125 22.90181816 21.07118011\n",
      "  21.82350397 22.35835075 24.7905829 ]\n",
      " [28.43364179 20.25216401 23.63645554 24.11742568 23.067348   21.04818463\n",
      "  21.23707831 22.30039895 17.51037784]\n",
      " [20.43078482 13.7580657  14.50240463 18.41489732 17.6092279  15.01279771\n",
      "  11.67800993 21.82892203 16.81143692]\n",
      " [28.99760664 21.33548677 24.47452247 24.44731772 22.46428013 21.37294471\n",
      "  23.05389404 22.71785617 23.75501592]\n",
      " [25.90426147 19.91976857 22.02138305 22.99055278 21.59169674 20.23748696\n",
      "  20.29416561 22.44004548 12.45265998]\n",
      " [29.94532764 22.99893737 25.37935317 25.49871683 23.38061213 22.9491806\n",
      "  24.5012337  23.06716025 23.22581832]\n",
      " [27.57613242 19.48741794 22.49013841 23.50934744 22.39453912 20.04095435\n",
      "  19.53392208 22.2097671  21.3064932 ]\n",
      " [28.26554954 19.48600352 22.30104268 23.32754552 22.08997428 19.80192661\n",
      "  19.66716886 22.32747316 34.4256507 ]\n",
      " [26.06606305 18.79579604 21.45658135 23.10571074 21.24150753 19.65389371\n",
      "  19.21849608 22.29700685 23.37928842]\n",
      " [27.99367726 20.60130358 23.2858783  24.16615605 22.76434243 20.72622478\n",
      "  21.38480723 22.33727038 29.03551999]\n",
      " [28.59832048 21.63123965 24.06479537 24.16547835 22.84881413 21.70764148\n",
      "  23.06851745 22.72429526 11.82708587]\n",
      " [20.71805656 14.96259391 14.34334964 18.03767323 17.07688808 14.76798624\n",
      "  10.87190866 21.89118862 32.02078488]\n",
      " [26.69081032 19.87558365 22.69821346 23.5206145  22.45855987 20.71889162\n",
      "  20.72380185 22.31778681 21.09898303]\n",
      " [28.10562551 19.07833457 21.68884635 23.23765397 21.67583942 19.85009372\n",
      "  19.51953113 22.21839309 30.55550986]\n",
      " [24.02753413 16.39122427 18.61160338 21.67209685 20.08363008 17.2068733\n",
      "  15.62874556 21.95226789 28.96669139]\n",
      " [23.77974451 16.62960827 18.02150309 20.92448473 19.58525598 17.31921494\n",
      "  14.71966714 21.99079871 22.22510997]\n",
      " [21.49220109 15.85919023 16.36692166 20.59207141 19.32597399 15.86074054\n",
      "  12.14895487 22.10420787 25.88108332]\n",
      " [24.46664929 17.505548   19.09988701 21.76629245 20.2233696  18.11955929\n",
      "  17.39394844 22.07618773 25.61767052]\n",
      " [26.23890817 18.20757508 20.28656781 22.55476713 21.89188063 18.57263267\n",
      "  17.65089512 22.03377128 27.66180692]\n",
      " [27.94044614 20.25039196 23.33914876 23.98093522 22.56387413 20.99323153\n",
      "  20.45881391 22.33288229 28.2936405 ]\n",
      " [25.82272589 20.09969473 21.68126822 22.48036981 20.76369703 20.27436197\n",
      "  20.25335491 22.54780769 21.5010854 ]]\n"
     ]
    }
   ],
   "source": [
    "# Submission Round 4\n",
    "# MMSE average of BERT and x-vectors PLDA\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/finalMMSE-xvectorsplda.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertMMSE_round1_'\n",
    "lFilesPred=[]\n",
    "for fold in range(3,11):\n",
    "    lFilesPred.append(sFilePred2+str(fold)+'.csv')\n",
    "    \n",
    "lFilesPred.append(sFilePred1)\n",
    "\n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "fileName='Round4MMSE'\n",
    "vPred, lID= average_fusion (lFilesPred, dest_dir, fileName, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderFiles_final(lDicts, iNumFiles):\n",
    "    vPredIter=np.zeros((1,iNumFiles))\n",
    "    vID=[] #true label\n",
    "    bEnter=1\n",
    "    for k in lDicts[0]: #first dictionary will be the lead\n",
    "        if k!='measurement_id':\n",
    "            #print(k)\n",
    "            #print(dID[k])\n",
    "\n",
    "            vPredIter[0,0]=float(np.asarray(lDicts[0][k])) #first predicted value\n",
    "            #print(vPredIter)\n",
    "            for j in range(1, iNumFiles):\n",
    "                fPred=lDicts[j].get(k)\n",
    "            if fPred:\n",
    "                vID.append(k)\n",
    "                vPredIter[0,j]=float(np.asarray(fPred))\n",
    "            else:\n",
    "                print(['Unkwnown key:' + k])\n",
    "                vPredIter[0,j]=float(np.asarray(lDicts[0][k]))\n",
    "\n",
    "            if bEnter==1:\n",
    "                mPredictions=vPredIter # mPredictions initialization.\n",
    "                bEnter=0\n",
    "            else:\n",
    "                mPredictions=np.append(mPredictions,vPredIter,axis=0)\n",
    "         \n",
    "    return mPredictions, vID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_fusion_FINAL (lFilesTrai,lFilesPred, sFileLabels, iEstimators, rLR, iMD,iRS, dest_dir,sNameOut):\n",
    "    \n",
    "    # Read file labels (true labels)\n",
    "    \n",
    "    with open(sFileLabels, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        dLabels= {rows[0]:rows[1] for rows in reader} #participantID:label\n",
    "    #print('thisis dLabels-------')\n",
    "    #print(dLabels)\n",
    "    \n",
    "    # Training-testing data\n",
    "    iNumFilesTest=len(lFilesPred)\n",
    "    iNumFilesTrai=len(lFilesTrai)\n",
    "#mPredictions=[] #np.zeros((1,iNumFiles))\n",
    "#mPredictions=np.asarray(mPredictions)\n",
    "    lDicts=[] \n",
    "    lDictsTrai=[]\n",
    "\n",
    "    for sFilePred in lFilesPred:\n",
    "        with open(sFilePred, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dPred = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDicts.append(dPred)\n",
    "        \n",
    "    for sFileTrai in lFilesTrai:\n",
    "        with open(sFileTrai, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            dTrai = {rows[0]:rows[1] for rows in reader} #Prediction from the different classifiers (acoustic, w-embed)\n",
    "        lDictsTrai.append(dTrai)\n",
    "   \n",
    "    #creation of the matrix containing prediction from all classifiers\n",
    "\n",
    "    mTrain, vLTrai=orderFiles(lDictsTrai, dLabels, iNumFilesTrai)\n",
    "    mTest, vIDTest=orderFiles_final(lDicts, iNumFilesTest)\n",
    "    \n",
    "    print('mTrain and vLabels')\n",
    "    print(mTrain.shape)\n",
    "    print(len(vLTrai))\n",
    "    \n",
    "    vRes1=np.transpose(mTest[:,[0]])\n",
    "    vRes2=np.transpose(mTest[:,[1]])\n",
    " \n",
    "    # Random forest training - regression\n",
    "    \n",
    "\n",
    "    clf=GradientBoostingRegressor(n_estimators=iEstimators, learning_rate=rLR, max_depth=iMD,\\\n",
    "                                  random_state=iRS, loss='ls').fit(mTrain, vLTrai)\n",
    "    \n",
    "    vNewPred=clf.predict(mTest)\n",
    "    \n",
    "    vIDTest, vNewPred=zip(*sorted(zip(vIDTest, vNewPred)))\n",
    "          \n",
    "   \n",
    "    df = pd.DataFrame({'measurement_id': vIDTest, 'prediction':np.round(np.array(vNewPred))})\n",
    "    np.savetxt(dest_dir+sNameOut+'.txt', df.values, fmt='%s', delimiter=' ; ')\n",
    "    print(dest_dir+sNameOut+'.txt')\n",
    "    # we will include the testing data here\n",
    "    return (np.round(np.array(vNewPred)), vIDTest, np.array(vRes1), np.array(vRes2))\n",
    "       \n",
    "    \n",
    "#print(mPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mTrain and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Round3Detection.txt\n"
     ]
    }
   ],
   "source": [
    "# Submission Round 3, DETECTION: fusion of xvectorsplda + Bert\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/kFoldsResults_detection.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "sFileFinal1='/export/c08/lmorove1/kaldi/egs/xVecAD/v1/exp/3ann/resBestxVecFold_all/FinalxvectorsDetection.csv'\n",
    "\n",
    "sFileFinal2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Detection_Bert1average.csv'\n",
    "\n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "sNameOut='Round3Detection'\n",
    "lFilesTrai=[sFilePred1,sFilePred2];\n",
    "\n",
    "lFilesFinal=[sFileFinal1,sFileFinal2]\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPred, vID, vRes1, vRes2=\\\n",
    "RandomForest_fusion_FINAL (lFilesTrai,lFilesFinal,sFileLabels, iEstimators, rLR, iMD,iRS,dest_dir, sNameOut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mTrain and vLabels\n",
      "(108, 2)\n",
      "108\n",
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Round4Detection.txt\n"
     ]
    }
   ],
   "source": [
    "# Submission Round 4, DETECTION: fusion of xvectorfine tuned + Bert\n",
    "sFilePred1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/AcousticScores_crossval.csv'\n",
    "sFilePred2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/BertScores_crossval.csv'\n",
    "sFileLabels='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/TrueLabels.csv'\n",
    "\n",
    "sFileFinal1='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Detection_Acoustic4average.csv'\n",
    "\n",
    "sFileFinal2='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Detection_Bert1average.csv'\n",
    "\n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/'\n",
    "sNameOut='Round4Detection'\n",
    "lFilesTrai=[sFilePred1,sFilePred2];\n",
    "\n",
    "lFilesFinal=[sFileFinal1,sFileFinal2]\n",
    "\n",
    "nudge=1\n",
    "iEstimators=900\n",
    "rLR=0.1\n",
    "iMD=1\n",
    "iRS=0\n",
    "\n",
    "vPred, vID, vRes1, vRes2=\\\n",
    "RandomForest_fusion_FINAL (lFilesTrai,lFilesFinal,sFileLabels, iEstimators, rLR, iMD,iRS,dest_dir, sNameOut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID   ; Prediction\n",
      "\n",
      "S160 ; 1.0\n",
      "\n",
      "S161 ; 1.0\n",
      "\n",
      "S162 ; 1.0\n",
      "\n",
      "S163 ; 1.0\n",
      "\n",
      "S164 ; 0.0\n",
      "\n",
      "S165 ; 0.0\n",
      "\n",
      "S166 ; 1.0\n",
      "\n",
      "S167 ; 0.0\n",
      "\n",
      "S168 ; 1.0\n",
      "\n",
      "S169 ; 1.0\n",
      "\n",
      "S170 ; 0.0\n",
      "\n",
      "S171 ; 0.0\n",
      "\n",
      "S172 ; 1.0\n",
      "\n",
      "S173 ; 0.0\n",
      "\n",
      "S174 ; 1.0\n",
      "\n",
      "S175 ; 0.0\n",
      "\n",
      "S176 ; 0.0\n",
      "\n",
      "S177 ; 1.0\n",
      "\n",
      "S178 ; 1.0\n",
      "\n",
      "S179 ; 0.0\n",
      "\n",
      "S180 ; 1.0\n",
      "\n",
      "S181 ; 0.0\n",
      "\n",
      "S182 ; 0.0\n",
      "\n",
      "S183 ; 1.0\n",
      "\n",
      "S184 ; 0.0\n",
      "\n",
      "S185 ; 1.0\n",
      "\n",
      "S186 ; 1.0\n",
      "\n",
      "S187 ; 0.0\n",
      "\n",
      "S188 ; 0.0\n",
      "\n",
      "S189 ; 0.0\n",
      "\n",
      "S190 ; 0.0\n",
      "\n",
      "S191 ; 0.0\n",
      "\n",
      "S192 ; 0.0\n",
      "\n",
      "S193 ; 0.0\n",
      "\n",
      "S194 ; 0.0\n",
      "\n",
      "S195 ; 0.0\n",
      "\n",
      "S196 ; 1.0\n",
      "\n",
      "S197 ; 0.0\n",
      "\n",
      "S198 ; 0.0\n",
      "\n",
      "S199 ; 1.0\n",
      "\n",
      "S200 ; 0.0\n",
      "\n",
      "S201 ; 0.0\n",
      "\n",
      "S202 ; 0.0\n",
      "\n",
      "S203 ; 0.0\n",
      "\n",
      "S204 ; 1.0\n",
      "\n",
      "S205 ; 0.0\n",
      "\n",
      "S206 ; 1.0\n",
      "\n",
      "S207 ; 0.0\n",
      "\n",
      "ID   ; Prediction\n",
      "\n",
      "S160 ; 1.0\n",
      "\n",
      "S161 ; 1.0\n",
      "\n",
      "S162 ; 1.0\n",
      "\n",
      "S163 ; 0.0\n",
      "\n",
      "S164 ; 0.0\n",
      "\n",
      "S165 ; 0.0\n",
      "\n",
      "S166 ; 1.0\n",
      "\n",
      "S167 ; 1.0\n",
      "\n",
      "S168 ; 1.0\n",
      "\n",
      "S169 ; 0.0\n",
      "\n",
      "S170 ; 1.0\n",
      "\n",
      "S171 ; 0.0\n",
      "\n",
      "S172 ; 1.0\n",
      "\n",
      "S173 ; 0.0\n",
      "\n",
      "S174 ; 1.0\n",
      "\n",
      "S175 ; 1.0\n",
      "\n",
      "S176 ; 1.0\n",
      "\n",
      "S177 ; 0.0\n",
      "\n",
      "S178 ; 0.0\n",
      "\n",
      "S179 ; 0.0\n",
      "\n",
      "S180 ; 0.0\n",
      "\n",
      "S181 ; 0.0\n",
      "\n",
      "S182 ; 0.0\n",
      "\n",
      "S183 ; 0.0\n",
      "\n",
      "S184 ; 0.0\n",
      "\n",
      "S185 ; 0.0\n",
      "\n",
      "S186 ; 1.0\n",
      "\n",
      "S187 ; 0.0\n",
      "\n",
      "S188 ; 0.0\n",
      "\n",
      "S189 ; 0.0\n",
      "\n",
      "S190 ; 0.0\n",
      "\n",
      "S191 ; 0.0\n",
      "\n",
      "S192 ; 1.0\n",
      "\n",
      "S193 ; 1.0\n",
      "\n",
      "S194 ; 0.0\n",
      "\n",
      "S195 ; 0.0\n",
      "\n",
      "S196 ; 0.0\n",
      "\n",
      "S197 ; 0.0\n",
      "\n",
      "S198 ; 1.0\n",
      "\n",
      "S199 ; 0.0\n",
      "\n",
      "S200 ; 1.0\n",
      "\n",
      "S201 ; 1.0\n",
      "\n",
      "S202 ; 0.0\n",
      "\n",
      "S203 ; 0.0\n",
      "\n",
      "S204 ; 1.0\n",
      "\n",
      "S205 ; 0.0\n",
      "\n",
      "S206 ; 0.0\n",
      "\n",
      "S207 ; 0.0\n",
      "\n",
      "ID   ; Prediction\n",
      "\n",
      "S160 ; 1.0\n",
      "\n",
      "S161 ; 1.0\n",
      "\n",
      "S162 ; 1.0\n",
      "\n",
      "S163 ; 1.0\n",
      "\n",
      "S164 ; 0.0\n",
      "\n",
      "S165 ; 0.0\n",
      "\n",
      "S166 ; 1.0\n",
      "\n",
      "S167 ; 0.0\n",
      "\n",
      "S168 ; 1.0\n",
      "\n",
      "S169 ; 1.0\n",
      "\n",
      "S170 ; 0.0\n",
      "\n",
      "S171 ; 0.0\n",
      "\n",
      "S172 ; 1.0\n",
      "\n",
      "S173 ; 0.0\n",
      "\n",
      "S174 ; 1.0\n",
      "\n",
      "S175 ; 0.0\n",
      "\n",
      "S176 ; 0.0\n",
      "\n",
      "S177 ; 1.0\n",
      "\n",
      "S178 ; 1.0\n",
      "\n",
      "S179 ; 0.0\n",
      "\n",
      "S180 ; 1.0\n",
      "\n",
      "S181 ; 0.0\n",
      "\n",
      "S182 ; 0.0\n",
      "\n",
      "S183 ; 1.0\n",
      "\n",
      "S184 ; 0.0\n",
      "\n",
      "S185 ; 0.0\n",
      "\n",
      "S186 ; 1.0\n",
      "\n",
      "S187 ; 0.0\n",
      "\n",
      "S188 ; 0.0\n",
      "\n",
      "S189 ; 0.0\n",
      "\n",
      "S190 ; 0.0\n",
      "\n",
      "S191 ; 0.0\n",
      "\n",
      "S192 ; 0.0\n",
      "\n",
      "S193 ; 0.0\n",
      "\n",
      "S194 ; 0.0\n",
      "\n",
      "S195 ; 0.0\n",
      "\n",
      "S196 ; 1.0\n",
      "\n",
      "S197 ; 0.0\n",
      "\n",
      "S198 ; 0.0\n",
      "\n",
      "S199 ; 1.0\n",
      "\n",
      "S200 ; 0.0\n",
      "\n",
      "S201 ; 0.0\n",
      "\n",
      "S202 ; 0.0\n",
      "\n",
      "S203 ; 0.0\n",
      "\n",
      "S204 ; 1.0\n",
      "\n",
      "S205 ; 0.0\n",
      "\n",
      "S206 ; 1.0\n",
      "\n",
      "S207 ; 0.0\n",
      "\n",
      "ID   ; Prediction\n",
      "\n",
      "S160 ; 1.0\n",
      "\n",
      "S161 ; 1.0\n",
      "\n",
      "S162 ; 1.0\n",
      "\n",
      "S163 ; 1.0\n",
      "\n",
      "S164 ; 0.0\n",
      "\n",
      "S165 ; 0.0\n",
      "\n",
      "S166 ; 1.0\n",
      "\n",
      "S167 ; 0.0\n",
      "\n",
      "S168 ; 1.0\n",
      "\n",
      "S169 ; 1.0\n",
      "\n",
      "S170 ; 0.0\n",
      "\n",
      "S171 ; 0.0\n",
      "\n",
      "S172 ; 1.0\n",
      "\n",
      "S173 ; 0.0\n",
      "\n",
      "S174 ; 1.0\n",
      "\n",
      "S175 ; 0.0\n",
      "\n",
      "S176 ; 0.0\n",
      "\n",
      "S177 ; 1.0\n",
      "\n",
      "S178 ; 1.0\n",
      "\n",
      "S179 ; 0.0\n",
      "\n",
      "S180 ; 1.0\n",
      "\n",
      "S181 ; 0.0\n",
      "\n",
      "S182 ; 0.0\n",
      "\n",
      "S183 ; 1.0\n",
      "\n",
      "S184 ; 0.0\n",
      "\n",
      "S185 ; 1.0\n",
      "\n",
      "S186 ; 1.0\n",
      "\n",
      "S187 ; 0.0\n",
      "\n",
      "S188 ; 0.0\n",
      "\n",
      "S189 ; 0.0\n",
      "\n",
      "S190 ; 0.0\n",
      "\n",
      "S191 ; 0.0\n",
      "\n",
      "S192 ; 0.0\n",
      "\n",
      "S193 ; 0.0\n",
      "\n",
      "S194 ; 0.0\n",
      "\n",
      "S195 ; 0.0\n",
      "\n",
      "S196 ; 1.0\n",
      "\n",
      "S197 ; 0.0\n",
      "\n",
      "S198 ; 0.0\n",
      "\n",
      "S199 ; 1.0\n",
      "\n",
      "S200 ; 0.0\n",
      "\n",
      "S201 ; 0.0\n",
      "\n",
      "S202 ; 0.0\n",
      "\n",
      "S203 ; 0.0\n",
      "\n",
      "S204 ; 1.0\n",
      "\n",
      "S205 ; 0.0\n",
      "\n",
      "S206 ; 1.0\n",
      "\n",
      "S207 ; 0.0\n",
      "\n",
      "ID   ; Prediction\n",
      "\n",
      "S160 ; 1.0\n",
      "\n",
      "S161 ; 1.0\n",
      "\n",
      "S162 ; 0.0\n",
      "\n",
      "S163 ; 1.0\n",
      "\n",
      "S164 ; 1.0\n",
      "\n",
      "S165 ; 0.0\n",
      "\n",
      "S166 ; 1.0\n",
      "\n",
      "S167 ; 0.0\n",
      "\n",
      "S168 ; 1.0\n",
      "\n",
      "S169 ; 0.0\n",
      "\n",
      "S170 ; 0.0\n",
      "\n",
      "S171 ; 0.0\n",
      "\n",
      "S172 ; 1.0\n",
      "\n",
      "S173 ; 1.0\n",
      "\n",
      "S174 ; 1.0\n",
      "\n",
      "S175 ; 1.0\n",
      "\n",
      "S176 ; 1.0\n",
      "\n",
      "S177 ; 1.0\n",
      "\n",
      "S178 ; 1.0\n",
      "\n",
      "S179 ; 0.0\n",
      "\n",
      "S180 ; 1.0\n",
      "\n",
      "S181 ; 0.0\n",
      "\n",
      "S182 ; 0.0\n",
      "\n",
      "S183 ; 1.0\n",
      "\n",
      "S184 ; 0.0\n",
      "\n",
      "S185 ; 1.0\n",
      "\n",
      "S186 ; 1.0\n",
      "\n",
      "S187 ; 1.0\n",
      "\n",
      "S188 ; 0.0\n",
      "\n",
      "S189 ; 0.0\n",
      "\n",
      "S190 ; 0.0\n",
      "\n",
      "S191 ; 1.0\n",
      "\n",
      "S192 ; 1.0\n",
      "\n",
      "S193 ; 1.0\n",
      "\n",
      "S194 ; 1.0\n",
      "\n",
      "S195 ; 1.0\n",
      "\n",
      "S196 ; 1.0\n",
      "\n",
      "S197 ; 1.0\n",
      "\n",
      "S198 ; 0.0\n",
      "\n",
      "S199 ; 0.0\n",
      "\n",
      "S200 ; 1.0\n",
      "\n",
      "S201 ; 0.0\n",
      "\n",
      "S202 ; 0.0\n",
      "\n",
      "S203 ; 0.0\n",
      "\n",
      "S204 ; 1.0\n",
      "\n",
      "S205 ; 0.0\n",
      "\n",
      "S206 ; 1.0\n",
      "\n",
      "S207 ; 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sFile='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/Old_sent1/Detection_'\n",
    "rang=range(1,6)\n",
    "dest_dir='/export/c08/lmorove1/kaldi/egs/beatPDivec/jupyternotebooks/Adress/DataResults/newDetection/'\n",
    "\n",
    "for i in rang:\n",
    "    \n",
    "    sInfile=sFile+str(i)+'.txt'\n",
    "    filename='test_results-classif-'+str(i)\n",
    "    lID=[]\n",
    "    vLabel=[]\n",
    "\n",
    "    with open(sInfile,'r') as foo:\n",
    "        for each_line in foo:\n",
    "            print(each_line)\n",
    "            lines = each_line.split(\";\")\n",
    "\n",
    "            lID.append(lines[0].strip())\n",
    "            #print(lines[0])\n",
    "            #print(lines[2].strip())\n",
    "            if lines[0]!='ID   ':\n",
    "                newLabel=str(1-float(lines[1].strip()))\n",
    "            else:\n",
    "                newLabel=lines[1].strip()\n",
    "            #print(newLabel)\n",
    "            vLabel.append(newLabel)\n",
    "\n",
    "    lID, vPrediction=zip(*sorted(zip(lID, vLabel)))\n",
    "    df = pd.DataFrame({'ID': lID, 'Prediction':vLabel})\n",
    "    np.savetxt(dest_dir+filename+'.txt', df.values, fmt='%s', delimiter=' ; ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
