{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains and Tests PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3.7\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"/export/c10/lmorove1/PythonLibs/plda\")\n",
    "import plda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kaldi_io\n",
    "import argparse\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/v1\n",
      "cmd.sh\t conf  exp    mfcc     pca_pldapy.ipynb  runFor.sh  run.sh~  steps\n",
      "cmd.sh~  data  local  path.sh  README.txt\t run.sh     sid      utils\n",
      "/export/c08/lmorove1/kaldi/egs/beatPDivec/v1\n",
      "cmd.sh\t conf  exp    mfcc     pca_pldapy.ipynb  runFor.sh  run.sh~  steps\n",
      "cmd.sh~  data  local  path.sh  README.txt\t run.sh     sid      utils\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/export/c08/lmorove1/kaldi/egs/beatPDivec/v1/'\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(DATA_PATH)\n",
    "!pwd && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(sFileTrai, sFileTest, iComponents):\n",
    "# os.chdir(\"/export/c10/lmorove1/kaldi/egs/xVecPD/v2_NeuroConc16k\")\n",
    "# sFileTrai=\"/export/c10/lmorove1/kaldi/egs/xVecPD/v2_NeuroConc16k/exp/sre18nn/xvectors_Training_Fold1/xvector.scp\"\n",
    "# sOut = Folder where to store results \n",
    "# iComponents = nb of classes (nb of measurements_id? or nb of subject_ids?)\n",
    "    dIvecTrai = { key:mat for key,mat in kaldi_io.read_vec_flt_scp(sFileTrai) }\n",
    "    vTrai= pd.DataFrame((list(dIvecTrai.values())))\n",
    "    vLTrai = np.array([x[-1] for x in np.array(list(dIvecTrai.keys()))])\n",
    "    \n",
    "    # FIXME : For realPD, we need more than -5 (CIS-PD subject_id is 4 characters long)\n",
    "    # FIXME REAL-PD it's not only int \n",
    "    vTraiSubjectId = np.array(([int(x[-5:-1]) for x in np.array(list(dIvecTrai.keys()))]))\n",
    "\n",
    "    dIvecTest = { key:mat for key,mat in kaldi_io.read_vec_flt_scp(sFileTest) }\n",
    "    vTest=np.array(list(dIvecTest.values()), dtype=float)\n",
    "    vLTest=np.array([x[-1] for x in np.array(list(dIvecTest.keys()))])\n",
    "    vTestSubjectId = np.array([int(x[-5:-1]) for x in np.array(list(dIvecTest.keys()))])\n",
    "\n",
    "    print('before transform : ', vTrai.shape)\n",
    "    print('before transform : ', vTest.shape)\n",
    "\n",
    "    if isinstance(iComponents, str):\n",
    "            iComponents=int(iComponents)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=iComponents, svd_solver='randomized', whiten=True)\n",
    "    pca.fit(vTrai)\n",
    "\n",
    "\n",
    "    vTraiPCA=pca.transform(vTrai)\n",
    "    vTestPCA=pca.transform(vTest)\n",
    "\n",
    "    print('after transform : ', vTraiPCA.shape)\n",
    "    print('after transform : ', vTestPCA.shape)\n",
    "    return vTraiPCA, vLTrai, vTraiSubjectId, vTestPCA, vLTest, vTestSubjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "sFileTrai = '/export/c08/lmorove1/kaldi/egs/beatPDivec/v1/exp/ivectors_Training_Fold0/ivector.scp'\n",
    "sFileTest = '/export/c08/lmorove1/kaldi/egs/beatPDivec/v1/exp/ivectors_Testing_Fold0/ivector.scp'\n",
    "iComponents = 50 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform :  (1403, 300)\n",
      "before transform :  (364, 300)\n",
      "after transform :  (1403, 50)\n",
      "after transform :  (364, 50)\n"
     ]
    }
   ],
   "source": [
    "vTraiPCA, vLTrai, vTraiSubjectId, vTestPCA, vLTest, vTestSubjectId = pca(sFileTrai, sFileTest, iComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# To compute the final score as per the challenge\n",
    "mse_training_per_subjectid=[]\n",
    "mse_test_per_subjectid=[]\n",
    "train_nb_files_per_subjectid=[]\n",
    "test_nb_files_per_subjectid=[]\n",
    "\n",
    "# To compute the mean accuracy\n",
    "glob_trai_pred=[]\n",
    "glob_test_pred=[]\n",
    "glob_trai_true=[]\n",
    "glob_test_true=[]\n",
    "    \n",
    "for subject_id in np.unique(vTraiSubjectId):\n",
    "    # GridSearchCV\n",
    "#     parameters = {'n_neighbors':[1,3,6,10,15]}\n",
    "\n",
    "    k_range = list(range(1, 15))\n",
    "#     param_grid = dict(n_neighbors=k_range)\n",
    "#     print(param_grid)\n",
    "\n",
    "    # instantiate the grid\n",
    "#     grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "    # fit the grid with data\n",
    "#     grid.fit(vTraiPCA_subjectid, vLTrai_subjectid)\n",
    "\n",
    "    # view the complete results (list of named tuples)\n",
    "#     print(grid.cv_results_['mean_test_score'])\n",
    "\n",
    "    print('----- ' + str(subject_id) + '----- ')\n",
    "    knn = KNeighborsClassifier(n_neighbors=6)\n",
    "    \n",
    "    # Filter vTraiPCA and vLTraiPCA for one subject_id\n",
    "    indices_subject_id = np.where(vTraiSubjectId == subject_id) # HAPPY\n",
    "    vTraiPCA_subjectid = vTraiPCA[indices_subject_id]\n",
    "    vLTrai_subjectid = vLTrai[indices_subject_id]\n",
    "    \n",
    "    # Filter vTestPCA and vLTestPCA for one subject_id\n",
    "    indices_subject_id = np.where(vTestSubjectId == subject_id)\n",
    "    vTestPCA_subjectid = vTestPCA[indices_subject_id]\n",
    "    vLTest_subjectid = vLTest[indices_subject_id]\n",
    "\n",
    "    knn.fit(vTraiPCA_subjectid, vLTrai_subjectid)\n",
    "    \n",
    "#     y_labels = knn.predict(vTraiPCA_subjectid)\n",
    "#     display(y_labels)\n",
    "\n",
    "    print('Training accuracy: ', knn.score(vTraiPCA_subjectid, vLTrai_subjectid))\n",
    "    print('Testing accuracy: ', knn.score(vTestPCA_subjectid, vLTest_subjectid))\n",
    "    \n",
    "    # Predicting on the training and test data \n",
    "    predictionsTrai = knn.predict(vTraiPCA_subjectid)\n",
    "    predictions = knn.predict(vTestPCA_subjectid)\n",
    "    \n",
    "    # Converting all strings to int for MSE \n",
    "    vLTrai_subjectid = [int(i) for i in vLTrai_subjectid]\n",
    "    predictionsTrai = [int(i) for i in predictionsTrai]\n",
    "    vLTest_subjectid = [int(i) for i in vLTest_subjectid]\n",
    "    predictions = [int(i) for i in predictions]\n",
    " \n",
    "    # Computing the accuracy \n",
    "    glob_trai_pred=np.append(glob_trai_pred,predictionsTrai,axis=0)\n",
    "    glob_test_pred=np.append(glob_test_pred,predictions,axis=0)\n",
    "    glob_trai_true=np.append(glob_trai_true,vLTrai_subjectid,axis=0)\n",
    "    glob_test_true=np.append(glob_test_true,vLTest_subjectid,axis=0)\n",
    "    \n",
    "    a = [a - b for a, b in zip(vLTrai_subjectid, predictionsTrai)]\n",
    "    print('abs substract : ', np.abs(a))\n",
    "    \n",
    "    # Building a list of the MSEk \n",
    "    mse_training_per_subjectid = np.append(mse_training_per_subjectid,\n",
    "                                           (mean_squared_error(vLTrai_subjectid, predictionsTrai) /  len(vLTrai_subjectid)))\n",
    "    mse_test_per_subjectid = np.append(mse_test_per_subjectid,\n",
    "                                        (mean_squared_error(vLTest_subjectid, predictions) / len(vLTest_subjectid)))\n",
    "    train_nb_files_per_subjectid.append(len(vLTrai_subjectid))\n",
    "    test_nb_files_per_subjectid.append(len(vLTest_subjectid))\n",
    "\n",
    "#     do_confusion_matrix(vLTest_subjectid, predictions)\n",
    "\n",
    "print('Global training accuracy: {}'.format((glob_trai_true == glob_trai_pred).mean()))\n",
    "print('Global testing accuracy: {}'.format((glob_test_true == glob_test_pred).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 1004----- \n",
      "Training accuracy:  0.38461538461538464\n",
      "Testing accuracy:  0.11764705882352941\n",
      "abs substract :  [0 1 0 0 3 0 0 2 2 1 1 0 0 0 1 3 1 0 2 3 3 1 0 0 1 1 1 1 0 1 3 0 1 1 2 1 1\n",
      " 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 3 0 0 1 0 2 0 4 1 0]\n",
      "----- 1006----- \n",
      "Training accuracy:  0.7586206896551724\n",
      "Testing accuracy:  0.625\n",
      "abs substract :  [0 0 0 0 0 0 0 0 1 1 0 1 0 0 2 0 0 1 0 0 0 1 0 0 0 0 1 0 0]\n",
      "----- 1007----- \n",
      "Training accuracy:  0.5972222222222222\n",
      "Testing accuracy:  0.5166666666666667\n",
      "abs substract :  [2 0 0 0 1 1 0 4 0 0 1 4 0 2 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 2 0 0 2 0 0 0\n",
      " 3 1 2 2 0 1 0 1 0 0 2 0 0 2 0 2 0 0 2 4 0 1 1 1 0 0 0 0 1 4 0 2 0 0 0 0 0\n",
      " 0 0 0 0 0 3 0 0 0 1 0 4 1 0 0 0 0 0 0 1 2 0 0 0 0 0 0 1 2 3 0 0 2 0 3 0 0\n",
      " 4 3 0 0 3 1 2 1 0 4 1 0 1 0 2 0 0 0 0 0 0 0 4 0 0 1 2 4 0 1 1 1 0 0 0 0 4\n",
      " 3 0 1 0 0 0 0 0 0 4 2 1 0 0 0 0 4 0 2 0 1 0 0 1 0 3 0 0 0 0 0 3 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 0 3 1 0 2 0 2 3 0 0 1 1 2 0 0 2 0 0 1 1 4 0 0 1]\n",
      "----- 1019----- \n",
      "Training accuracy:  0.4722222222222222\n",
      "Testing accuracy:  0.8888888888888888\n",
      "abs substract :  [0 2 0 3 0 4 0 0 1 3 0 0 0 1 2 2 0 0 3 2 0 3 2 3 2 1 0 4 0 0 1 0 0 2 0 3]\n",
      "----- 1020----- \n",
      "Training accuracy:  0.7628205128205128\n",
      "Testing accuracy:  0.9743589743589743\n",
      "abs substract :  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 2 0 4 0 2 0 4 1 0 0 4 0 0 0 0 0 0 0 0 0 2 4 1 2 0 0 0 0 2 0 4 0 0 0 2\n",
      " 0 0 2 0 0 1 1 0 4 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 2 0 0 2 0 0 0 0 4 0 0 0 0 4 0 0 0 0 2 1 0 2 0 0 2\n",
      " 1 0 0 0 0 0 1 0]\n",
      "----- 1023----- \n",
      "Training accuracy:  0.47619047619047616\n",
      "Testing accuracy:  0.13636363636363635\n",
      "abs substract :  [0 1 0 0 2 0 2 2 1 2 0 1 2 1 1 1 3 0 0 0 0 2 1 1 0 1 0 0 2 2 0 0 0 0 0 0 0\n",
      " 3 3 0 3 0 0 2 0 0 0 2 1 0 1 1 0 0 2 2 1 1 0 0 3 0 0 3 2 1 3 4 0 0 2 0 0 1\n",
      " 1 2 1 0 1 0 0 2 0 2]\n",
      "----- 1032----- \n",
      "Training accuracy:  0.48226950354609927\n",
      "Testing accuracy:  0.3055555555555556\n",
      "abs substract :  [0 2 1 2 1 1 0 0 1 0 1 1 2 0 0 2 1 1 1 0 0 1 1 0 1 0 0 0 0 2 2 0 0 1 0 2 0\n",
      " 2 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 2 0 2 0 2 0 1 0 1 0 3 0 3 1 0 2 1 2 1 2\n",
      " 1 1 0 0 0 0 0 0 0 1 1 2 2 1 2 0 1 1 2 0 0 3 0 0 0 0 2 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 2 0 1 0 2 1 0 0 3 2 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 2]\n",
      "----- 1034----- \n",
      "Training accuracy:  0.59375\n",
      "Testing accuracy:  0.25\n",
      "abs substract :  [0 0 0 0 0 2 0 0 2 2 0 0 2 0 0 1 0 1 0 0 0 3 0 0 2 1 2 0 1 3 0 2]\n",
      "----- 1038----- \n",
      "Training accuracy:  0.6787878787878788\n",
      "Testing accuracy:  0.7619047619047619\n",
      "abs substract :  [0 0 0 0 4 0 0 0 2 2 0 0 0 4 0 0 0 4 0 2 4 0 0 4 0 0 4 0 0 0 2 4 0 4 4 0 2\n",
      " 0 0 0 0 4 0 0 0 0 0 0 0 4 0 0 4 0 2 0 0 0 0 0 0 0 0 4 0 2 0 0 4 0 4 0 0 0\n",
      " 0 0 0 0 0 2 0 2 0 0 4 0 0 0 0 0 0 0 0 4 0 4 0 0 0 2 0 4 0 0 0 0 0 0 0 0 4\n",
      " 4 0 0 0 0 4 2 2 0 2 4 0 0 2 4 0 0 4 4 4 2 0 4 0 2 0 0 3 2 4 4 0 0 4 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 4 0 4 0 4 0 0 0]\n",
      "----- 1039----- \n",
      "Training accuracy:  0.5769230769230769\n",
      "Testing accuracy:  0.34615384615384615\n",
      "abs substract :  [0 0 0 1 1 1 0 0 0 0 0 3 0 0 2 0 0 0 0 1 0 0 4 1 0 4 0 0 1 0 0 0 3 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 2 4 0 0 0 0 1 1 1 0 0 0 1 0 1 0 2 0 1 0 0 1 1 1 2 0 1 1\n",
      " 0 2 2 1 0 1 0 0 4 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 3 1 0 0 1 0]\n",
      "----- 1043----- \n",
      "Training accuracy:  0.48148148148148145\n",
      "Testing accuracy:  0.5714285714285714\n",
      "abs substract :  [2 0 0 2 1 0 0 0 3 1 1 0 1 0 0 2 2 3 0 0 3 2 0 1 3 0 0]\n",
      "----- 1044----- \n",
      "Training accuracy:  0.6842105263157895\n",
      "Testing accuracy:  0.8666666666666667\n",
      "abs substract :  [0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0]\n",
      "----- 1048----- \n",
      "Training accuracy:  0.5833333333333334\n",
      "Testing accuracy:  0.3684210526315789\n",
      "abs substract :  [2 1 0 2 0 0 1 0 0 0 0 0 1 1 1 1 1 0 2 2 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 0 2 0 3 0 0 1 0 1 1 0 2 2 2 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0]\n",
      "----- 1049----- \n",
      "Training accuracy:  0.5538461538461539\n",
      "Testing accuracy:  0.6470588235294118\n",
      "abs substract :  [2 0 0 2 2 0 0 1 1 0 0 0 1 0 2 0 3 0 2 0 0 2 0 0 1 0 0 0 0 0 0 0 1 3 1 0 0\n",
      " 1 0 1 0 3 1 0 1 2 3 1 0 0 0 2 0 2 0 1 1 0 0 0 0 1 1 2 0]\n",
      "----- 1051----- \n",
      "Training accuracy:  0.7207792207792207\n",
      "Testing accuracy:  0.6666666666666666\n",
      "abs substract :  [1 1 3 2 0 0 0 0 1 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 3 0 0 0\n",
      " 4 0 0 0 0 0 1 0 0 0 0 0 0 0 3 1 0 3 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 3 2 0 0 2 0 0 0 0 3 0 2 0 0 0 0 0 0 3 0 0 0 0 3 0 0 0 0 0 1 0 2 2 2 0 1 0\n",
      " 0 0 0 4 0 0 0 0 1 4 0 0 0 0 2 0 0 0 0 0 3 2 0 2 3 2 4 2 0 3 0 0 0 3 0 0 0\n",
      " 4 0 0 0 0 0]\n",
      "Global training accuracy: 0.6072701354240913\n",
      "Global testing accuracy: 0.554945054945055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# To compute the final score as per the challenge\n",
    "mse_training_per_subjectid=[]\n",
    "mse_test_per_subjectid=[]\n",
    "train_nb_files_per_subjectid=[]\n",
    "test_nb_files_per_subjectid=[]\n",
    "\n",
    "# To compute the mean accuracy\n",
    "glob_trai_pred=[]\n",
    "glob_test_pred=[]\n",
    "glob_trai_true=[]\n",
    "glob_test_true=[]\n",
    "    \n",
    "for subject_id in np.unique(vTraiSubjectId):\n",
    "    # GridSearchCV\n",
    "#     parameters = {'n_neighbors':[1,3,6,10,15]}\n",
    "\n",
    "    k_range = list(range(1, 15))\n",
    "#     param_grid = dict(n_neighbors=k_range)\n",
    "#     print(param_grid)\n",
    "\n",
    "    # instantiate the grid\n",
    "#     grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "    # fit the grid with data\n",
    "#     grid.fit(vTraiPCA_subjectid, vLTrai_subjectid)\n",
    "\n",
    "    # view the complete results (list of named tuples)\n",
    "#     print(grid.cv_results_['mean_test_score'])\n",
    "\n",
    "    print('----- ' + str(subject_id) + '----- ')\n",
    "    knn = KNeighborsClassifier(n_neighbors=6)\n",
    "    \n",
    "    # Filter vTraiPCA and vLTraiPCA for one subject_id\n",
    "    indices_subject_id = np.where(vTraiSubjectId == subject_id) # HAPPY\n",
    "    vTraiPCA_subjectid = vTraiPCA[indices_subject_id]\n",
    "    vLTrai_subjectid = vLTrai[indices_subject_id]\n",
    "    \n",
    "    # Filter vTestPCA and vLTestPCA for one subject_id\n",
    "    indices_subject_id = np.where(vTestSubjectId == subject_id)\n",
    "    vTestPCA_subjectid = vTestPCA[indices_subject_id]\n",
    "    vLTest_subjectid = vLTest[indices_subject_id]\n",
    "\n",
    "    knn.fit(vTraiPCA_subjectid, vLTrai_subjectid)\n",
    "    \n",
    "#     y_labels = knn.predict(vTraiPCA_subjectid)\n",
    "#     display(y_labels)\n",
    "\n",
    "    print('Training accuracy: ', knn.score(vTraiPCA_subjectid, vLTrai_subjectid))\n",
    "    print('Testing accuracy: ', knn.score(vTestPCA_subjectid, vLTest_subjectid))\n",
    "    \n",
    "    # Predicting on the training and test data \n",
    "    predictionsTrai = knn.predict(vTraiPCA_subjectid)\n",
    "    predictions = knn.predict(vTestPCA_subjectid)\n",
    "    \n",
    "    # Converting all strings to int for MSE \n",
    "    vLTrai_subjectid = [int(i) for i in vLTrai_subjectid]\n",
    "    predictionsTrai = [int(i) for i in predictionsTrai]\n",
    "    vLTest_subjectid = [int(i) for i in vLTest_subjectid]\n",
    "    predictions = [int(i) for i in predictions]\n",
    " \n",
    "    # Computing the accuracy \n",
    "    glob_trai_pred=np.append(glob_trai_pred,predictionsTrai,axis=0)\n",
    "    glob_test_pred=np.append(glob_test_pred,predictions,axis=0)\n",
    "    glob_trai_true=np.append(glob_trai_true,vLTrai_subjectid,axis=0)\n",
    "    glob_test_true=np.append(glob_test_true,vLTest_subjectid,axis=0)\n",
    "    \n",
    "    a = [a - b for a, b in zip(vLTrai_subjectid, predictionsTrai)]\n",
    "    print('abs substract : ', np.abs(a))\n",
    "    \n",
    "    # Building a list of the MSEk \n",
    "    mse_training_per_subjectid = np.append(mse_training_per_subjectid,\n",
    "                                           (mean_squared_error(vLTrai_subjectid, predictionsTrai) /  len(vLTrai_subjectid)))\n",
    "    mse_test_per_subjectid = np.append(mse_test_per_subjectid,\n",
    "                                        (mean_squared_error(vLTest_subjectid, predictions) / len(vLTest_subjectid)))\n",
    "    train_nb_files_per_subjectid.append(len(vLTrai_subjectid))\n",
    "    test_nb_files_per_subjectid.append(len(vLTest_subjectid))\n",
    "\n",
    "#     do_confusion_matrix(vLTest_subjectid, predictions)\n",
    "\n",
    "print('Global training accuracy: {}'.format((glob_trai_true == glob_trai_pred).mean()))\n",
    "print('Global testing accuracy: {}'.format((glob_test_true == glob_test_pred).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "def final_score(mse_per_subjectid, nb_files_per_subject_id):\n",
    "    numerator = np.sum([a * b for a, b in zip(np.sqrt(nb_files_per_subject_id), mse_per_subjectid)])\n",
    "    denominator = np.sum(np.sqrt(nb_files_per_subject_id))\n",
    "    print('numerator : ', numerator)\n",
    "    print('denominator : ', denominator)\n",
    "    print('Final score : ', np.divide(numerator, denominator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerator :  2.9956883253194277\n",
      "denominator :  138.07717596772696\n",
      "Final score :  0.021695753149091168\n",
      "numerator :  6.065415875730853\n",
      "denominator :  70.2868377625761\n",
      "Final score :  0.08629518795851071\n"
     ]
    }
   ],
   "source": [
    "final_score(mse_training_per_subjectid, train_nb_files_per_subjectid)\n",
    "final_score(mse_test_per_subjectid, test_nb_files_per_subjectid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confusion_matrix(y_test, predictions):\n",
    "    print('y test : ', np.unique(y_test))\n",
    "    LABELS_NEW = np.unique(y_test)\n",
    "    n_classes=np.unique(y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "    print(confusion_matrix)\n",
    "    normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "    print(normalised_confusion_matrix)\n",
    "\n",
    "    # Plot Results:\n",
    "    width = 12\n",
    "    height = 12\n",
    "    plt.figure(figsize=(width, height))\n",
    "    plt.imshow(\n",
    "        normalised_confusion_matrix,\n",
    "        interpolation='nearest',\n",
    "        cmap=plt.cm.rainbow\n",
    "    )\n",
    "    plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(n_classes)\n",
    "    plt.xticks(tick_marks, LABELS_NEW, rotation=90)\n",
    "    plt.yticks(tick_marks, LABELS_NEW)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeatPD",
   "language": "python",
   "name": "beatpd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
