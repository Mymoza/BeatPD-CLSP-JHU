{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to create graphs about the CIS-PD and REAL-PD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Imports for the high pass signal\n",
    "from scipy.signal import butter, freqz, lfilter\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import required modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os.path\n",
    "\n",
    "# To write WAV File\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# To make derivative work on multiple CPUs\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_graphs import *\n",
    "from transform_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot original accelerometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "path_save_accelerometer_plots = \"/export/fs02/mpgill/plots/accelerometer_plots/\"\n",
    "\n",
    "# TODO: explain\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type, data_dir=data_dir)\n",
    "\n",
    "# display(df_train_label)\n",
    "# List of interesting measurement id we want to look at\n",
    "# list_measurement_id=[#'ab5287f4-8261-47ad-8ff2-22b5fe5d246e',\n",
    "#'db2e053a-0fb8-4206-891a-6f079fb14e3a']#,\n",
    "# 'ef5b1267-c212-46c5-aab0-4f4437bc6c67',\n",
    "# '4ec74fb9-7347-435d-83dc-79ad74c3bc49',\n",
    "# '8e8539ad-8841-476b-b15c-888ce3461989',\n",
    "# '22b88456-fe8f-4138-af55-be12afca4b81',\n",
    "# 'ad84583d-e5ae-4926-b077-531a0f7d08a9',\n",
    "# 'eef56825-940a-4c3e-aebb-60838d60869e',\n",
    "# 'e0441156-c4b8-467c-8f4f-3b532d594d8f',\n",
    "# '464ac314-6c4b-4c4a-957c-28a2339150d6']\n",
    "\n",
    "# List of interesting measurement id we want to look at\n",
    "list_measurement_id = [\n",
    "    \"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\",\n",
    "    \"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\",\n",
    "    \"5163afe8-a6b0-4ea4-b2ba-9b4501dd5912\",\n",
    "    \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "    \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "    \"2e3a4c9c-ff01-4a28-bfcf-ce9b7633a39d\",  # no inactivity should be removed\n",
    "    \"3cf49c01-0499-4bad-9167-67691711204a\",  # no inactivity should be removed PAS LA??\n",
    "    \"3d0f965c-9d72-43d1-9369-1ea3acf963cc\",  # PAS LA ???\n",
    "    \"4b269cc2-8f0c-4816-adbf-10c0069b8833\",\n",
    "    \"4bc51b90-bfce-4231-85e1-5de3b4bc0745\",\n",
    "    \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "]  # bit of inactivity in the middle]\n",
    "\n",
    "# list_measurement_id = [\n",
    "#     \"2d852742-10a9-4c56-9f38-779f2cd66879\",\n",
    "#     \"4fc3c295-857f-4920-8fa5-f21bfdc7ab4f\",\n",
    "#     \"db2e053a-0fb8-4206-891a-6f079fb14e3a\",\n",
    "# ]\n",
    "\n",
    "\n",
    "list_measurement_id = [\"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\"]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(\n",
    "    df_train_label=df_train_label, list_measurement_id=list_measurement_id\n",
    ")\n",
    "\n",
    "# Display filtered df_train_label\n",
    "display(df_train_label)\n",
    "\n",
    "# path_no_inactivity_data = remove_inactivity_pct_change(df_train_label)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   filename=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graph high pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass/\"\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   filename=\"hpf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph Orig + Inactivity Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data/\"\n",
    "    \n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   filename=\"orignoinact\",\n",
    "                   mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph HPF + Inactivity Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact/\"\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   filename=\"combhpfnoinact\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_measurement_id = [\"cc7b822c-e310-46f0-a8ea-98c95fdb67a1\"]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(\n",
    "    df_train_label=df_train_label, list_measurement_id=list_measurement_id\n",
    ")\n",
    "\n",
    "path_train_data = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.combhpfnoinact.rotate_5/\"\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   filename=\"combhpfnoinact.rotate_4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which axis is more important? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIS-PD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data type as we have two databases\n",
    "data_type = \"cis\"\n",
    "training_or_ancillary = 'training_data'\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_real_subtype=\"training_data\"\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary,\n",
    "                                                   data_real_subtype)\n",
    "\n",
    "# NOTE: plot_axis_on_top only shows 10 first subject_id \n",
    "plot_axis_on_top(df_train_label, path_train_data, highpass=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation with inactivity removed, after applying a highpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_axis_on_top(df_train_label, path_train_data, highpass=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the kfold distribution V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_real_subtype=\"\"\n",
    "\n",
    "if data_type == \"cis\":\n",
    "    kfold_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.k_fold_v1/\"\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_path = data_path + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "\n",
    "nb_folds = np.array([0,1,2,3,4])\n",
    "nb_folds = np.array([0])\n",
    "\n",
    "pids = np.array([1004,1006,1007,1019,1020,1023,1032,1034,1038,1039,1043,1044,1046,1048,1049,1051])\n",
    "pids = np.array([1038])\n",
    "\n",
    "for temp_pid in pids:\n",
    "    for nb in nb_folds:\n",
    "        for train_or_test in ['train','test']:\n",
    "            file_name = str(temp_pid) + '_'+train_or_test+'_kfold_' + str(nb) + '.csv'\n",
    "            print(file_name)\n",
    "            df_train_label = pd.read_csv(kfold_path+file_name)\n",
    "            \n",
    "            # Compute the occurences of each symptoms for each patient\n",
    "            df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "                df_train_label=df_train_label\n",
    "            )\n",
    "\n",
    "            # Plot the graphs\n",
    "            plot_symptoms_occurences(\n",
    "                df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    "            )\n",
    "\n",
    "            #print(df_train_label.values[:,1:])\n",
    "            #temp_train_X = pd.read_csv(data_path+df_train_label[\"measurement_id\"][idx] + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms - ALL FOLDS - True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_real_subtype=\"\"\n",
    "\n",
    "kfold_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.k_fold_v3/\"\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_path = data_path + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "\n",
    "nb_folds = np.array([0,1,2,3,4])\n",
    "# nb_folds = np.array([0,1,2,3,4])\n",
    "\n",
    "pids = np.array([1004,1006,1007,1019,1020,1023,1032,1034,1038,1039,1043,1044,1046,1048,1049,1051])\n",
    "# pids = np.array([1038])\n",
    "\n",
    "\n",
    "\n",
    "for temp_pid in pids:\n",
    "    for train_or_test in ['train','test']:\n",
    "        \n",
    "        glob_df_train_label = pd.DataFrame()\n",
    "        \n",
    "        for nb in nb_folds:\n",
    "            file_name = str(temp_pid) + '_'+train_or_test+'_kfold_' + str(nb) + '.csv'\n",
    "            print(file_name)\n",
    "            \n",
    "            df_train_label = pd.read_csv(kfold_path+file_name)\n",
    "            glob_df_train_label = glob_df_train_label.append(df_train_label)\n",
    "\n",
    "#         print(glob_df_train_label)\n",
    "        \n",
    "        # Compute the occurences of each symptoms for each patient\n",
    "        df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "            df_train_label=glob_df_train_label\n",
    "        )\n",
    "\n",
    "        # Plot the graphs\n",
    "        plot_symptoms_occurences(\n",
    "            df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occurences, df_train_label_subject_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots of the training labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title, additional_df=[]):\n",
    "    \"\"\"\n",
    "    Plot a bar graph according to the csv file passed in parameters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    - TODO \n",
    "    \"\"\"\n",
    "    df_train_predictions = pd.read_csv(data_path+sFileName)\n",
    "    df_train_predictions = df_train_predictions.fillna(-1)\n",
    "\n",
    "    for add_df in additional_df:\n",
    "        df_train_predictions = df_train_predictions.append(add_df)\n",
    "    df_train_predictions_reorder = df_train_predictions[sSubchallenge].round().value_counts(sort=True)\n",
    "    order = [-1,0,1,2,3,4]\n",
    "    df_train_predictions_reorder = df_train_predictions_reorder.reindex(order)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = df_train_predictions_reorder.plot('bar')\n",
    "\n",
    "    plt.title(plot_title, fontdict = {'fontsize' : 15})\n",
    "    plt.xlabel(\"Label\",fontsize=15)\n",
    "    plt.ylabel(\"Frequency\",fontsize=15)\n",
    "    \n",
    "    add_value_labels(ax)\n",
    "    plt.savefig(fname='/export/fs02/mpgill/plots/{0}.pdf'.format(plot_title.replace(\" \", \"_\")), format='pdf')\n",
    "    plt.savefig(fname='/export/fs02/mpgill/plots/{0}.png'.format(plot_title.replace(\" \", \"_\")), format='png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "training_or_ancillary='training_data'\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "df_train_label_1 = df_train_label[((df_train_label.dyskinesia >= 1.0) | (df_train_label.on_off >= 1.0) | (df_train_label.tremor >= 1.0)) & (df_train_label.on_off != 0)]\n",
    "# \n",
    "df_train_label_2 = df_train_label[((df_train_label.dyskinesia >= 2.0) | (df_train_label.on_off >= 2.0) | (df_train_label.tremor >= 2.0)) & (df_train_label.on_off != 0)]\n",
    "\n",
    "df_train_label_3 = df_train_label[((df_train_label.dyskinesia >= 3.0) | (df_train_label.on_off >= 3.0) | (df_train_label.tremor >= 3.0)) & (df_train_label.on_off != 0)]\n",
    "\n",
    "df_train_label_4 = df_train_label[((df_train_label.dyskinesia >= 4.0) | (df_train_label.on_off >= 4.0) | (df_train_label.tremor >= 4.0)) & (df_train_label.on_off != 0)]\n",
    "df_train_label_5 = df_train_label[((df_train_label.dyskinesia >= 4.0)) & (df_train_label.on_off != 0)]\n",
    "display(df_train_label_3)\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"on_off\"\n",
    "plot_title =\"CIS-PD Training Data Labels - On Off\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title, additional_df=[df_train_label_3])\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"dyskinesia\"\n",
    "plot_title =\"CIS-PD Training Data Labels - Dyskinesia\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title, additional_df=[df_train_label_3])\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"tremor\"\n",
    "plot_title =\"CIS-PD Training Data Labels - tremor\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title, additional_df=[df_train_label_3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"on_off\"\n",
    "plot_title =\"CIS-PD Training Data Labels - On Off\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"dyskinesia\"\n",
    "plot_title =\"CIS-PD Training Data Labels - Dyskinesia\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.data_labels/\"\n",
    "sFileName = \"CIS-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"tremor\"\n",
    "plot_title =\"CIS-PD Training Data Labels - tremor\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/real-pd.data_labels/\"\n",
    "sFileName = \"REAL-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"on_off\"\n",
    "plot_title =\"REAL-PD Training Data Labels - on_off\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/real-pd.data_labels/\"\n",
    "sFileName = \"REAL-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"tremor\"\n",
    "plot_title =\"REAL-PD Training Data Labels - tremor\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/real-pd.data_labels/\"\n",
    "sFileName = \"REAL-PD_Training_Data_IDs_Labels.csv\"\n",
    "sSubchallenge = \"dyskinesia\"\n",
    "plot_title =\"REAL-PD Training Data Labels - dyskinesia\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histo of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pca_knn_bpd2 import *\n",
    "\n",
    "def plot_bar_predictions_(df_predictions, plot_title):\n",
    "    \"\"\"\n",
    "    Plot a bar graph according to the csv file passed in parameters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    - TODO \n",
    "    \"\"\"\n",
    "\n",
    "    df_predictions_reorder = df_predictions.round().value_counts(sort=True)\n",
    "    order = [-1,0,1,2,3,4]\n",
    "    df_predictions_reorder = df_predictions_reorder.reindex(order)\n",
    "    plt.figure(figsize=(5,5), dpi=80)\n",
    "    ax = df_predictions_reorder.plot('bar')\n",
    "\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Label\",fontsize=15)\n",
    "    plt.ylabel(\"Frequency\",fontsize=15)\n",
    "#     plt.figure(figsize=(30,15))\n",
    "#     plt.figure(figsize=(20,10))\n",
    "    add_value_labels(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import pickle\n",
    "\n",
    "pid = \"1004\"\n",
    "\n",
    "glob_test_pred = []\n",
    "\n",
    "for fold in [0,1,2,3,4]:\n",
    "    sFileTrai=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_550/ivectors_Training_Fold\"+str(fold)+\"/ivector.scp\"\n",
    "    sFileTest=\"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30_320fl/exp/ivec_550/ivectors_Testing_Fold\"+str(fold)+\"/ivector.scp\"\n",
    "    iComponents=400\n",
    "\n",
    "    sOut=\"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/ResiVecSVR_Fold\"+str(fold)+\"/\"\n",
    "\n",
    "    iNeighbors=None\n",
    "\n",
    "    vTraiPCA, vLTrai, vTraiSubjectId, vTraiMeasurementId, vTestPCA, vLTest, vTestSubjectId, vTestMeasurementId = pca(sFileTrai, sFileTest, iComponents)\n",
    "\n",
    "    pca_knn_bpd2(sFileTrai, sFileTest, sOut, iComponents, iNeighbors, sKernel='linear', fCValue=0.2, fEpsilon='0.1')\n",
    "\n",
    "\n",
    "    fold_folder = \"/home/mpgill/BeatPD/BeatPD-CLSP-JHU/ResiVecSVR_Fold\"+str(fold)+\"/\"\n",
    "    sFileName = pid+\"_objs_400_kernel_linear_c_0.2_eps_0.1.pkl\"\n",
    "\n",
    "    [predictionsTrai,vLTrai_subjectid,predictions,vLTest_subjectid, vTraiMeasurementId, \\\n",
    "     mse_trai_subjectid, \\\n",
    "     mse_test_subjectid, \\\n",
    "     lTestMeasId_subjectid] = pickle.load(open(fold_folder+sFileName, \"rb\" ) )\n",
    "    \n",
    "    glob_test_pred=np.append(glob_test_pred,predictionsTrai,axis=0)\n",
    "#     print(predictionsTrai.round().astype(int))\n",
    "#     print(vLTrai_subjectid)\n",
    "#     print(\"EQUAL? : \", predictionsTrai.round().astype(int) == vLTrai_subjectid)\n",
    "    \n",
    "    print(predictions)\n",
    "    print(vLTest_subjectid)\n",
    "    print(\"EQUAL? : \", predictions.round().astype(int) == vLTest_subjectid)\n",
    "    \n",
    "    # Plot per fold \n",
    "    plot_bar_predictions_(pd.Series(predictionsTrai), (pid+\"_objs_400_kernel_linear_c_0.2_eps_0.01 - Fold \"+str(fold)+\" - Test Preds\"))\n",
    "\n",
    "plot_bar_predictions_(pd.Series(glob_test_pred), (pid+\"_objs_400_kernel_linear_c_0.2_eps_0.01 - All Folds - Test Preds\"))\n",
    "#     do_confusion_matrix(y_test=vLTest_subjectid, predictions=predictions.round().astype(int))\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plot of Predictions for all folds, all patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/export/c08/lmorove1/kaldi/egs/beatPDivec/on_off_noinact_auto30/exp/ivec_450/resiVecSVR_Fold_all/\"\n",
    "sFileName = \"objs_400_kernel_linear_c_0.2_eps_0.1.csv\"\n",
    "sSubchallenge = \"on_off\"\n",
    "plot_title =\"On/Off Predictions Labels\"\n",
    "\n",
    "plot_bar_labels(data_path, sFileName, sSubchallenge, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train_label.round())\n",
    "\n",
    "data_path = \"/export/c08/lmorove1/kaldi/egs/beatPDivec/trem_noinact_auto30/exp/ivec_450/resiVecSVR_Fold_all/\"\n",
    "sFileName = \"objs_450_kernel_linear_c_0.02_eps_0.1.csv\"\n",
    "df_train_label_trem = pd.read_csv(data_path+sFileName)\n",
    "\n",
    "data_path = \"/export/c08/lmorove1/kaldi/egs/beatPDivec/v1_dysk_auto/exp/ivec_500/resiVecSVR_Fold/\"\n",
    "sFileName = \"Dyskinesia_testing.csv\"\n",
    "df_train_label_dysk = pd.read_csv(data_path+sFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the kfold distribution V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_real_subtype=\"\"\n",
    "\n",
    "if data_type == \"cis\":\n",
    "    kfold_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.k_fold_v2/\"\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_path = data_path + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "\n",
    "nb_folds = np.array([0,1,2,3,4])\n",
    "\n",
    "pids = np.array([1038])\n",
    "#pids = np.array([1004,1006,1007,1019,1020,1023,1032,1034,1038,1039,1043,1044,1046,1048,1049,1051])\n",
    "\n",
    "for temp_pid in pids:\n",
    "    for nb in nb_folds:\n",
    "        for train_or_test in ['train','test']:\n",
    "            file_name = str(temp_pid) + '_'+train_or_test+'_kfold_' + str(nb) + '.csv'\n",
    "            print(file_name)\n",
    "            df_train_label = pd.read_csv(kfold_path+file_name)\n",
    "            # Compute the occurences of each symptoms for each patient\n",
    "\n",
    "            df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "                df_train_label=df_train_label\n",
    "            )\n",
    "\n",
    "            # Plot the graphs\n",
    "            plot_symptoms_occurences(\n",
    "                df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    "            )\n",
    "\n",
    "            #print(df_train_label.values[:,1:])\n",
    "            #temp_train_X = pd.read_csv(data_path+df_train_label[\"measurement_id\"][idx] + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the length of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_type = \"cis\"\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary,\n",
    "                                                   data_real_subtype)\n",
    "len_distribution = []\n",
    "for idx in df_train_label.index:\n",
    "        df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "        len_distribution.append(len(df_train_data))\n",
    "\n",
    "\n",
    "num_bins = 10\n",
    "n, bins, patches = plt.hist(len_distribution, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "print('min : ', min(len_distribution))\n",
    "print('max : ', max(len_distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove activity with pct_change and plot the accelerometer after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_dir = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "path_save_accelerometer_plots = \"/home/sjoshi/codes/python/BeatPD/code/accelerometer_plots/\"\n",
    "training_or_ancillary='training_data'\n",
    "\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary)\n",
    "\n",
    "list_measurement_id = [\"5cf68c8e-0b7a-4b73-ad4f-015c7a20fb5a\"]\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label,\n",
    "                                      list_measurement_id=list_measurement_id)\n",
    "\n",
    "plot_accelerometer(df_train_label=df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots)\n",
    "\n",
    "path_no_inactivity_data = remove_inactivity_pct_change(df_train_label,\n",
    "                                                       data_dir,\n",
    "                                                       path_train_data,\n",
    "                                                       data_type)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(df_train_label=df_train_label,\n",
    "                   data_type=data_type,\n",
    "                   path_train_data=path_train_data,\n",
    "                   path_accelerometer_plots=path_save_accelerometer_plots,\n",
    "                   path_inactivity=path_no_inactivity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to print accelerometers before/after and write a wav file for 1 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "path_save_accelerometer_plots = \"/home/sjoshi/codes/python/BeatPD/code/accelerometer_plots/\"\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary,\n",
    "                                                   data_real_subtype)\n",
    "\n",
    "list_measurement_id = ['db2e053a-0fb8-4206-891a-6f079fb14e3a']\n",
    "\n",
    "\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "\n",
    "# Plot the accelerometer data\n",
    "plot_accelerometer(data_type=data_type, path_accelerometer_plots=path_save_accelerometer_plots)\n",
    "\n",
    "remove_inactivity_highpass(\n",
    "    df_train_label,\n",
    "    energy_threshold=10,\n",
    "    duration_threshold=3000,\n",
    "    plot_frequency_response=True,\n",
    "    plot_accelerometer_after_removal=True,\n",
    "    mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "\n",
    "\n",
    "# Apply filter \n",
    "for idx in df_train_label.index:\n",
    "    df_train_data = apply_mask(df_train_label[\"measurement_id\"][idx],\n",
    "                               mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "    print('len : ', len(df_train_data))\n",
    "    great_title = get_plot_title(idx, df_train_label)\n",
    "    \n",
    "    print('AFTER REMOVAL')\n",
    "    #Plot accelerometer \n",
    "    print('len : ', len(df_train_data))\n",
    "    x_axis_data_type = \"t\" if data_type == \"real\" else \"Timestamp\"\n",
    "    df_train_data.plot(\n",
    "                    x=x_axis_data_type, legend=True, subplots=True, title=great_title\n",
    "                )\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL-PD Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"real\"\n",
    "data_real_subtype = 'smartphone_accelerometer'\n",
    "training_or_ancillary='training_data' #training_data\n",
    "path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary,\n",
    "                                                   data_real_subtype)\n",
    "\n",
    "list_measurement_id=['b50d1b0c-2cd1-45f8-9097-0742e5cbbcc8']\n",
    "\n",
    "# Filter df_train_label according to the measurement_id we are most interested in\n",
    "df_train_label = interesting_patients(df_train_label=df_train_label, list_measurement_id=list_measurement_id)\n",
    "\n",
    "\n",
    "# Compute the occurences of each symptoms for each patient\n",
    "df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "    df_train_label=df_train_label\n",
    ")\n",
    "\n",
    "# Plot the graphs\n",
    "plot_symptoms_occurences(\n",
    "    df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the length of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_type = \"real\"\n",
    "training_or_ancillary='training_data'\n",
    "data_real_subtype='smartphone_accelerometer'\n",
    "\n",
    "for data_real_subtype in ['smartphone_accelerometer','smartwatch_accelerometer','smartwatch_gyroscope']:\n",
    "    path_train_data, df_train_label = define_data_type(data_type,\n",
    "                                                   data_dir,\n",
    "                                                   training_or_ancillary,\n",
    "                                                   data_real_subtype)\n",
    "    len_distribution = []\n",
    "\n",
    "    for idx in df_train_label.index:\n",
    "        try:\n",
    "            df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "            len_distribution.append(len(df_train_data))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    print(data_real_subtype)\n",
    "    num_bins = 10\n",
    "    n, bins, patches = plt.hist(len_distribution, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confusion_matrix(y_test, predictions):\n",
    "    print('y test : ', np.unique(y_test))\n",
    "    LABELS_NEW = np.unique(y_test)\n",
    "    n_classes=np.unique(y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "    print(confusion_matrix)\n",
    "    normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "    print(normalised_confusion_matrix)\n",
    "\n",
    "    # Plot Results:\n",
    "    width = 12\n",
    "    height = 12\n",
    "    plt.figure(figsize=(width, height))\n",
    "    plt.imshow(\n",
    "        normalised_confusion_matrix,\n",
    "        interpolation='nearest',\n",
    "        cmap=plt.cm.rainbow\n",
    "    )\n",
    "    plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(n_classes)\n",
    "    plt.xticks(tick_marks, LABELS_NEW, rotation=90)\n",
    "    plt.yticks(tick_marks, LABELS_NEW)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeatPD",
   "language": "python",
   "name": "beatpd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
