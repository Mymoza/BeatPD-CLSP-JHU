{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Imports for the high pass signal\n",
    "from scipy.signal import butter, freqz, lfilter\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import required modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os.path\n",
    "\n",
    "# To write WAV File\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# To make derivative work on multiple CPUs\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic functions from other notebooks \n",
    "import import_ipynb\n",
    "from analyze_data_cleaned import compute_symptoms_occurences_dataframe\n",
    "from analyze_data_cleaned import plot_symptoms_occurences\n",
    "from analyze_data_cleaned import define_data_type\n",
    "from analyze_data_cleaned import apply_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to be removed once i know how to import these from another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_missing_values(df_train_label):\n",
    "    \"\"\"\n",
    "    Filling NaN values with -1. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    # Replace NaN values with -1.0 because otherwise plotting triggers an error\n",
    "    df_train_label = df_train_label.fillna(value=-1.0)\n",
    "    return df_train_label\n",
    "\n",
    "\n",
    "def compute_symptoms_occurences_dataframe(df_train_label):\n",
    "    \"\"\"\n",
    "    Computes how many times the symptoms are occuring for a single subject_id \n",
    "    \n",
    "    Keyword arguments:\n",
    "    - df_train_label: DataFrame containing the following columns \n",
    "            [measurement_id, subject_id, on_off, tremor, dyskenisia]\n",
    "    \"\"\"\n",
    "    df_train_label = prepro_missing_values(df_train_label=df_train_label)\n",
    "\n",
    "    # Group data by subject_id\n",
    "    df_train_label_subject_id = df_train_label.groupby(\"subject_id\")\n",
    "\n",
    "    df_occurences = []\n",
    "    symptoms = [\"on_off\", \"dyskinesia\", \"tremor\"]\n",
    "\n",
    "    for key, value in df_train_label_subject_id:\n",
    "        for symptom in symptoms:\n",
    "            # Pour un patient, prendre les 3 dernieres colonnes, et pour 1 symptome, calculer le nb d'occurences\n",
    "            counter = (\n",
    "                df_train_label_subject_id.get_group(key)\n",
    "                .iloc[:, -3:][symptom]\n",
    "                .value_counts()\n",
    "            )\n",
    "\n",
    "            for symptom_value, symptom_occurence in counter.items():\n",
    "                df_occurences.append(\n",
    "                    (\n",
    "                        {\n",
    "                            \"subject_id\": key,\n",
    "                            \"symptom\": symptom,\n",
    "                            \"symptom_value\": symptom_value,\n",
    "                            \"occurence\": symptom_occurence,\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    df_occurences = pd.DataFrame(\n",
    "        df_occurences, columns=(\"subject_id\", \"symptom\", \"symptom_value\", \"occurence\")\n",
    "    )\n",
    "\n",
    "    return df_occurences, df_train_label_subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_symptoms_occurences(df_occurences, df_train_label_subject_id):\n",
    "    \"\"\"\n",
    "    This function plots the occurences of symptoms according to subject_id \n",
    "\n",
    "    Keyword Arguments: \n",
    "    - df_occurences: contains the df with occurences computed in compute_symptoms_occurences_dataframe\n",
    "    - df_train_label_subject_id: contains df_train_label grouped by subject_id \n",
    "    \"\"\"\n",
    "\n",
    "    # There will be one graph plotted for each patient, for each of the 3 symptoms\n",
    "    nb_subjects_id = (\n",
    "        df_occurences.subject_id.nunique()\n",
    "    )  # nb of unique patients in the label file\n",
    "    print(\"Nb subject_id : \", nb_subjects_id)\n",
    "    height = 30 if nb_subjects_id > 10 else 5\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nb_subjects_id, ncols=3, figsize=(10, height), sharey=True\n",
    "    )  # 3 cols for the 3 symptoms\n",
    "\n",
    "    # Quick fix to plot the graphs at the right place. Starts at -1 because in the first for loop\n",
    "    # it is incremented\n",
    "    patient = -1\n",
    "    \n",
    "    # Plot for all subject_id 3 bar plots for all the symptoms and their occurences\n",
    "    # Reminder that NaN values (missing values) were replaced with -1 and are shown as such in the plots\n",
    "    symptoms = [\"on_off\", \"dyskinesia\", \"tremor\"]\n",
    "    for key, value in df_train_label_subject_id:\n",
    "        patient = patient + 1  # value used to position the plots (row)\n",
    "        symptom_no = 0  # value only used to position the plots (col)\n",
    "        for symptom in symptoms:\n",
    "\n",
    "            subject_symptom = \" \".join(\n",
    "                [str(key), symptom]\n",
    "            )  # variable used to create a title for each plot\n",
    "\n",
    "            ax = df_train_label_subject_id.get_group(key)[symptom].value_counts().plot(\n",
    "                kind=\"bar\",\n",
    "                x=symptom,\n",
    "                title=subject_symptom,\n",
    "                ax=axes[symptom_no],\n",
    "                sharey=True,\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            plt.tight_layout()\n",
    "            symptom_no = symptom_no + 1\n",
    "            add_value_labels(ax)\n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by \"plot traces per subject\"\n",
    "# Source: https://machinelearningmastery.com/how-to-load-and-explore-a-standard-human-activity-recognition-problem/\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Define the data type as we have two databases\n",
    "data_type = \"cis\"\n",
    "training_or_ancillary = 'training_data'\n",
    "path_train_data, df_train_label = define_data_type(data_type=data_type)\n",
    "    \n",
    "def plot_subjects(df_train_label):\n",
    "    fig, ax = pyplot.subplots(figsize=(30, 30))\n",
    "    for idx in df_train_label.index:\n",
    "        if idx == 10:\n",
    "            break\n",
    "        print('idx : ', str(idx))\n",
    "        pyplot.subplot(10, 1, idx+1)\n",
    "        df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "        pyplot.plot(df_train_data.iloc[:,-4], df_train_data.iloc[:,-1], '-b', label='Z')\n",
    "        pyplot.plot(df_train_data.iloc[:,-4], df_train_data.iloc[:,-3], '-g', label='X')\n",
    "        pyplot.plot(df_train_data.iloc[:,-4], df_train_data.iloc[:,-2], '-m', label='Y')\n",
    "    pyplot.legend()\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "\n",
    "plot_subjects(df_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation with inactivity removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype=\"high\", analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def test(df_train_data):\n",
    "    # Filter requirements.\n",
    "    order = 10\n",
    "    fs = 50.0  # sample rate, Hz\n",
    "    cutoff = 0.5  # 3.667  # desired cutoff frequency of the filter, Hz\n",
    "    \n",
    "    # Get the filter coefficients so we can check its frequency response.\n",
    "    b, a = butter_highpass(cutoff, fs, order)\n",
    "    \n",
    "    X_filtered_data = butter_highpass_filter(df_train_data.iloc[:,-3], cutoff, fs, order)\n",
    "    Y_filtered_data = butter_highpass_filter(df_train_data.iloc[:,-2], cutoff, fs, order)\n",
    "    Z_filtered_data = butter_highpass_filter(df_train_data.iloc[:,-1], cutoff, fs, order)\n",
    "    \n",
    "    return X_filtered_data, Y_filtered_data, Z_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subjects(df_train_label):\n",
    "    fig, ax = pyplot.subplots(figsize=(30, 30))\n",
    "    for idx in df_train_label.index:\n",
    "        if idx == 10:\n",
    "            break\n",
    "        print('idx : ', str(idx))\n",
    "        pyplot.subplot(10, 1, idx+1)\n",
    "        df_train_data = apply_mask(df_train_label[\"measurement_id\"][idx], \n",
    "                                   mask_path='/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.high_pass_mask/')\n",
    "        print(len(df_train_data))\n",
    "        #         df_train_data = pd.read_csv(path_train_data + df_train_label[\"measurement_id\"][idx] + \".csv\")\n",
    "        X_filtered_data, Y_filtered_data, Z_filtered_data = test(df_train_data)\n",
    "        \n",
    "        pyplot.plot(df_train_data.iloc[:,-4], X_filtered_data, '-b', label='Z')\n",
    "        pyplot.plot(df_train_data.iloc[:,-4], Y_filtered_data, '-g', label='X')\n",
    "        pyplot.plot(df_train_data.iloc[:,-4], Z_filtered_data, '-m', label='Y')\n",
    "    pyplot.legend()\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "    \n",
    "plot_subjects(df_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the kfold distribution V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_real_subtype=\"\"\n",
    "\n",
    "if data_type == \"cis\":\n",
    "    kfold_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.k_fold_v1/\"\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_path = data_path + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "\n",
    "nb_folds = np.array([0,1,2,3,4])\n",
    "\n",
    "pids = np.array([1004,1006,1007,1019,1020,1023,1032,1034,1038,1039,1043,1044,1046,1048,1049,1051])\n",
    "\n",
    "for temp_pid in pids:\n",
    "    for nb in nb_folds:\n",
    "        for train_or_test in ['train','test']:\n",
    "            file_name = str(temp_pid) + '_'+train_or_test+'_kfold_' + str(nb) + '.csv'\n",
    "            print(file_name)\n",
    "            df_train_label = pd.read_csv(kfold_path+file_name)\n",
    "            # Compute the occurences of each symptoms for each patient\n",
    "\n",
    "            df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "                df_train_label=df_train_label\n",
    "            )\n",
    "\n",
    "            # Plot the graphs\n",
    "            plot_symptoms_occurences(\n",
    "                df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    "            )\n",
    "\n",
    "            #print(df_train_label.values[:,1:])\n",
    "            #temp_train_X = pd.read_csv(data_path+df_train_label[\"measurement_id\"][idx] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occurences, df_train_label_subject_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the kfold distribution V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_type = \"cis\"\n",
    "data_real_subtype=\"\"\n",
    "\n",
    "if data_type == \"cis\":\n",
    "    kfold_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/cis-pd.training_data.k_fold_v2/\"\n",
    "\n",
    "data_path = \"/home/sjoshi/codes/python/BeatPD/data/BeatPD/\"\n",
    "data_path = data_path + data_type + \"-pd.training_data/\" + data_real_subtype + \"/\"\n",
    "\n",
    "nb_folds = np.array([0,1,2,3,4])\n",
    "\n",
    "# pids = np.array([1038])\n",
    "pids = np.array([1004,1006,1007,1019,1020,1023,1032,1034,1038,1039,1043,1044,1046,1048,1049,1051])\n",
    "\n",
    "for temp_pid in pids:\n",
    "    for nb in nb_folds:\n",
    "        for train_or_test in ['train','test']:\n",
    "            file_name = str(temp_pid) + '_'+train_or_test+'_kfold_' + str(nb) + '.csv'\n",
    "            print(file_name)\n",
    "            df_train_label = pd.read_csv(kfold_path+file_name)\n",
    "            # Compute the occurences of each symptoms for each patient\n",
    "\n",
    "            df_occurences, df_train_label_subject_id = compute_symptoms_occurences_dataframe(\n",
    "                df_train_label=df_train_label\n",
    "            )\n",
    "\n",
    "            # Plot the graphs\n",
    "            plot_symptoms_occurences(\n",
    "                df_occurences=df_occurences, df_train_label_subject_id=df_train_label_subject_id\n",
    "            )\n",
    "\n",
    "            #print(df_train_label.values[:,1:])\n",
    "            #temp_train_X = pd.read_csv(data_path+df_train_label[\"measurement_id\"][idx] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeatPD",
   "language": "python",
   "name": "beatpd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
